[
  {
    "id": "function-vs-closure-rust",
    "slug": "function-vs-closure-rust",
    "title": "Functions or Closures in Rust? Know the Difference!",
    "date": "2025-06-30",
    "excerpt": "Expert technical discussion on functions vs closures in Rust, covering ownership, traits, lifetimes, and performance implications.",
    "content": "Understanding the distinction between functions and closures is fundamental to mastering Rust's ownership system and performance characteristics.\n\n## Key Differences\n\n| Functions | Closures |\n|-----------|----------|\n| Defined at compile time with `fn` | Anonymous, created at runtime |\n| Static dispatch (no runtime overhead) | May involve dynamic dispatch (trait objects) |\n| Cannot capture environment variables | Can capture variables from enclosing scope |\n| Always have a known type | Type is unique and inferred (each closure has its own type) |\n\n## Underlying Mechanics\n\n### Closures Are Structs + Traits\n\nRust models closures as structs that:\n- Store captured variables (as fields)\n- Implement one of the closure traits (`Fn`, `FnMut`, or `FnOnce`)\n\nFor example, this closure:\n```rust\nlet x = 42;\nlet closure = |y| x + y;\n```\n\nIs desugared to something like:\n```rust\nstruct AnonymousClosure {\n    x: i32,  // Captured variable\n}\n\nimpl FnOnce<(i32,)> for AnonymousClosure {\n    type Output = i32;\n    fn call_once(self, y: i32) -> i32 {\n        self.x + y\n    }\n}\n```\n\n### Dynamic Dispatch (Vtables)\n\nWhen closures are trait objects (e.g., `Box<dyn Fn(i32) -> i32>`), Rust uses vtables for dynamic dispatch:\n- **Vtable**: A lookup table storing function pointers, enabling runtime polymorphism\n- **Overhead**: Indirect function calls (~2â€“3x slower than static dispatch)\n\n## When to Use Each\n\nUse **Functions** when:\n- You need zero-cost abstractions (e.g., mathematical operations)\n- No environment capture is required\n\n```rust\nfn add(a: i32, b: i32) -> i32 { a + b }\n```\n\nUse **Closures** when:\n- You need to capture state from the environment\n- Writing short, ad-hoc logic (e.g., callbacks, iterators)\n\n```rust\nlet threshold = 10;\nlet filter = |x: i32| x > threshold;  // Captures `threshold`\n```\n\n## Performance Considerations\n\n| Scenario | Static Dispatch (Closures) | Dynamic Dispatch (dyn Fn) |\n|----------|----------------------------|----------------------------|\n| Speed | Fast (inlined) | Slower (vtable lookup) |\n| Memory | No overhead | Vtable + fat pointer |\n| Use Case | Hot loops, embedded | Heterogeneous callbacks |\n\n## Example: Static vs. Dynamic Dispatch\n\n```rust\n// Static dispatch (compile-time)\nfn static_call<F: Fn(i32) -> i32>(f: F, x: i32) -> i32 {\n    f(x)  // Inlined\n}\n\n// Dynamic dispatch (runtime)\nfn dynamic_call(f: &dyn Fn(i32) -> i32, x: i32) -> i32 {\n    f(x)  // Vtable lookup\n}\n```\n\n## Key Takeaways\n\nâœ… **Functions**: Predictable performance, no captures  \nâœ… **Closures**: Flexible, capture environment, but may involve vtables  \nðŸš€ Prefer static dispatch (`impl Fn`) unless you need trait objects\n\n**Try This:** What happens if a closure captures a mutable reference and is called twice?  \n**Answer:** The borrow checker ensures exclusive accessâ€”it won't compile unless the first call completes!",
    "contentHtml": "<p>Understanding the distinction between functions and closures is fundamental to mastering Rust&#39;s ownership system and performance characteristics.</p>\n<h2>Key Differences</h2>\n<table>\n<thead>\n<tr>\n<th>Functions</th>\n<th>Closures</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Defined at compile time with <code>fn</code></td>\n<td>Anonymous, created at runtime</td>\n</tr>\n<tr>\n<td>Static dispatch (no runtime overhead)</td>\n<td>May involve dynamic dispatch (trait objects)</td>\n</tr>\n<tr>\n<td>Cannot capture environment variables</td>\n<td>Can capture variables from enclosing scope</td>\n</tr>\n<tr>\n<td>Always have a known type</td>\n<td>Type is unique and inferred (each closure has its own type)</td>\n</tr>\n</tbody></table>\n<h2>Underlying Mechanics</h2>\n<h3>Closures Are Structs + Traits</h3>\n<p>Rust models closures as structs that:</p>\n<ul>\n<li>Store captured variables (as fields)</li>\n<li>Implement one of the closure traits (<code>Fn</code>, <code>FnMut</code>, or <code>FnOnce</code>)</li>\n</ul>\n<p>For example, this closure:</p>\n<pre><code class=\"language-rust\">let x = 42;\nlet closure = |y| x + y;\n</code></pre>\n<p>Is desugared to something like:</p>\n<pre><code class=\"language-rust\">struct AnonymousClosure {\n    x: i32,  // Captured variable\n}\n\nimpl FnOnce&lt;(i32,)&gt; for AnonymousClosure {\n    type Output = i32;\n    fn call_once(self, y: i32) -&gt; i32 {\n        self.x + y\n    }\n}\n</code></pre>\n<h3>Dynamic Dispatch (Vtables)</h3>\n<p>When closures are trait objects (e.g., <code>Box&lt;dyn Fn(i32) -&gt; i32&gt;</code>), Rust uses vtables for dynamic dispatch:</p>\n<ul>\n<li><strong>Vtable</strong>: A lookup table storing function pointers, enabling runtime polymorphism</li>\n<li><strong>Overhead</strong>: Indirect function calls (~2â€“3x slower than static dispatch)</li>\n</ul>\n<h2>When to Use Each</h2>\n<p>Use <strong>Functions</strong> when:</p>\n<ul>\n<li>You need zero-cost abstractions (e.g., mathematical operations)</li>\n<li>No environment capture is required</li>\n</ul>\n<pre><code class=\"language-rust\">fn add(a: i32, b: i32) -&gt; i32 { a + b }\n</code></pre>\n<p>Use <strong>Closures</strong> when:</p>\n<ul>\n<li>You need to capture state from the environment</li>\n<li>Writing short, ad-hoc logic (e.g., callbacks, iterators)</li>\n</ul>\n<pre><code class=\"language-rust\">let threshold = 10;\nlet filter = |x: i32| x &gt; threshold;  // Captures `threshold`\n</code></pre>\n<h2>Performance Considerations</h2>\n<table>\n<thead>\n<tr>\n<th>Scenario</th>\n<th>Static Dispatch (Closures)</th>\n<th>Dynamic Dispatch (dyn Fn)</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Speed</td>\n<td>Fast (inlined)</td>\n<td>Slower (vtable lookup)</td>\n</tr>\n<tr>\n<td>Memory</td>\n<td>No overhead</td>\n<td>Vtable + fat pointer</td>\n</tr>\n<tr>\n<td>Use Case</td>\n<td>Hot loops, embedded</td>\n<td>Heterogeneous callbacks</td>\n</tr>\n</tbody></table>\n<h2>Example: Static vs. Dynamic Dispatch</h2>\n<pre><code class=\"language-rust\">// Static dispatch (compile-time)\nfn static_call&lt;F: Fn(i32) -&gt; i32&gt;(f: F, x: i32) -&gt; i32 {\n    f(x)  // Inlined\n}\n\n// Dynamic dispatch (runtime)\nfn dynamic_call(f: &amp;dyn Fn(i32) -&gt; i32, x: i32) -&gt; i32 {\n    f(x)  // Vtable lookup\n}\n</code></pre>\n<h2>Key Takeaways</h2>\n<p>âœ… <strong>Functions</strong>: Predictable performance, no captures<br>âœ… <strong>Closures</strong>: Flexible, capture environment, but may involve vtables<br>ðŸš€ Prefer static dispatch (<code>impl Fn</code>) unless you need trait objects</p>\n<p><strong>Try This:</strong> What happens if a closure captures a mutable reference and is called twice?<br><strong>Answer:</strong> The borrow checker ensures exclusive accessâ€”it won&#39;t compile unless the first call completes!</p>\n",
    "author": "mayo",
    "category": "rust",
    "tags": [
      "rust",
      "functions",
      "closures",
      "traits",
      "ownership"
    ],
    "readingTime": "3 min",
    "seo": {
      "title": "Functions or Closures in Rust? Know the Difference!",
      "description": "Expert technical discussion on functions vs closures in Rust, covering ownership, traits, lifetimes, and performance implications.",
      "keywords": [
        "rust",
        "functions",
        "closures",
        "traits",
        "ownership"
      ]
    },
    "headings": [
      {
        "id": "key-differences",
        "text": "Key Differences",
        "level": 2
      },
      {
        "id": "underlying-mechanics",
        "text": "Underlying Mechanics",
        "level": 2
      },
      {
        "id": "closures-are-structs-traits",
        "text": "Closures Are Structs + Traits",
        "level": 3
      },
      {
        "id": "dynamic-dispatch-vtables",
        "text": "Dynamic Dispatch (Vtables)",
        "level": 3
      },
      {
        "id": "when-to-use-each",
        "text": "When to Use Each",
        "level": 2
      },
      {
        "id": "performance-considerations",
        "text": "Performance Considerations",
        "level": 2
      },
      {
        "id": "example-static-vs-dynamic-dispatch",
        "text": "Example: Static vs. Dynamic Dispatch",
        "level": 2
      },
      {
        "id": "key-takeaways",
        "text": "Key Takeaways",
        "level": 2
      }
    ]
  },
  {
    "id": "memory-layout-optimization-rust",
    "slug": "memory-layout-optimization-rust",
    "title": "Rust's repr: Optimize Struct Memory for Cache Efficiency",
    "date": "2025-06-26",
    "excerpt": "Expert technical discussion on low-level memory optimization in Rust, covering repr attributes, cache efficiency, and performance trade-offs",
    "content": "The `repr` attribute controls struct memory layout, which is critical for low-level optimization in high-throughput systems where cache locality drives performance.\n\n## How They Work\n\n**`repr(C)`**: Enforces C-compatible layout with fields ordered sequentially as declared, adding padding to align each field to its natural alignment (e.g., `u32` aligns to 4 bytes). Ensures predictable interoperability and typically aligns well with CPU cache lines (often 64 bytes).\n\n**`repr(packed)`**: Removes all padding, packing fields tightly together regardless of alignment. Minimizes memory usage but can lead to unaligned memory accesses, which are slower on most architectures.\n\n## Optimization for Cache Locality\n\nWith `repr(C)`, the compiler adds padding to align fields, increasing struct size but ensuring efficient, aligned access:\n\n```rust\n#[repr(C)]\nstruct Data {\n    flag: bool,   // 1 byte + 3 bytes padding (on 32-bit alignment)\n    value: u32,   // 4 bytes\n    counter: u64, // 8 bytes\n}\n// Size: 16 bytes (due to padding for alignment)\n```\n\nHere, `repr(C)` ensures `value` and `counter` are alignedâ€”great for loops accessing `value` repeatedly. Aligned reads are fast and cache-friendly, but padding after `flag` wastes space.\n\nWith `repr(packed)`:\n\n```rust\n#[repr(packed)]\nstruct PackedData {\n    flag: bool,   // 1 byte\n    value: u32,   // 4 bytes, unaligned\n    counter: u64, // 8 bytes, unaligned\n}\n// Size: 13 bytes (no padding)\n```\n\nThis shrinks size to 13 bytes, ideal for tight memory constraints, but unaligned accesses to `value` and `counter` incur significant performance penalties.\n\n## Trade-Offs\n\n| Aspect | `repr(C)` | `repr(packed)` |\n|--------|-----------|----------------|\n| **Performance** | Fast aligned access, cache-efficient | Slower unaligned access penalties |\n| **Memory Usage** | Larger due to padding | Minimal footprint |\n| **Portability** | Safe across platforms | Risk of UB or panics on strict architectures |\n\n- **Performance**: `repr(C)` wins for speedâ€”aligned access is faster and cache-efficient\n- **Memory Usage**: `repr(packed)` reduces footprint, critical for large arrays or tight constraints\n- **Portability**: `repr(C)` is safer; `repr(packed)` risks undefined behavior with unsafe dereferencing\n\n## Example Scenario\n\nReal-time packet parser in a network server processing millions of packets per second:\n\n```rust\n#[repr(C)]\nstruct Packet {\n    header: u8,   // 1 byte + 3 padding\n    id: u32,      // 4 bytes\n    payload: u64, // 8 bytes\n}\n```\n\nWith `repr(C)`, size is 16 bytes, and `id`/`payload` are aligned, speeding up field access in tight loops checking `id`. Cache locality is decent since the struct fits in a 64-byte cache line.\n\nIf using `repr(packed)` (13 bytes), I'd save 3 bytes per packet, but unaligned `id` and `payload` accesses could halve throughput due to penaltiesâ€”unacceptable for this workload.\n\n**Choice**: `repr(C)` for performance-critical code. Consider reordering fields (`payload`, `id`, `header`) to group hot fields together.\n\n**Alternative scenario**: Serializing thousands of tiny structs to disk with infrequent accessâ€”`repr(packed)` might make sense to minimize storage, accepting slower deserialization.\n\n## Advanced Considerations\n\n- Use profiling tools like `perf` to confirm cache miss reductions\n- Consider `#[repr(C, packed)]` for C-compatible but packed layout\n- Field reordering can optimize cache line usage without changing `repr`\n- Test trade-offs on target hardware, especially ARM vs x86_64\n\n## Key Takeaways\n\nâœ… **`repr(C)`**: Choose for performance-critical code where cache efficiency matters  \nâœ… **`repr(packed)`**: Use for memory-constrained scenarios with infrequent access  \nðŸš€ Profile cache performance before and after to validate optimizations\n\n**Try This:** What happens if you access a field in a `repr(packed)` struct through a raw pointer?  \n**Answer:** Unaligned access through raw pointers can cause panics on strict architectures or performance penaltiesâ€”always measure on your target platform!",
    "contentHtml": "<p>The <code>repr</code> attribute controls struct memory layout, which is critical for low-level optimization in high-throughput systems where cache locality drives performance.</p>\n<h2>How They Work</h2>\n<p><strong><code>repr(C)</code></strong>: Enforces C-compatible layout with fields ordered sequentially as declared, adding padding to align each field to its natural alignment (e.g., <code>u32</code> aligns to 4 bytes). Ensures predictable interoperability and typically aligns well with CPU cache lines (often 64 bytes).</p>\n<p><strong><code>repr(packed)</code></strong>: Removes all padding, packing fields tightly together regardless of alignment. Minimizes memory usage but can lead to unaligned memory accesses, which are slower on most architectures.</p>\n<h2>Optimization for Cache Locality</h2>\n<p>With <code>repr(C)</code>, the compiler adds padding to align fields, increasing struct size but ensuring efficient, aligned access:</p>\n<pre><code class=\"language-rust\">#[repr(C)]\nstruct Data {\n    flag: bool,   // 1 byte + 3 bytes padding (on 32-bit alignment)\n    value: u32,   // 4 bytes\n    counter: u64, // 8 bytes\n}\n// Size: 16 bytes (due to padding for alignment)\n</code></pre>\n<p>Here, <code>repr(C)</code> ensures <code>value</code> and <code>counter</code> are alignedâ€”great for loops accessing <code>value</code> repeatedly. Aligned reads are fast and cache-friendly, but padding after <code>flag</code> wastes space.</p>\n<p>With <code>repr(packed)</code>:</p>\n<pre><code class=\"language-rust\">#[repr(packed)]\nstruct PackedData {\n    flag: bool,   // 1 byte\n    value: u32,   // 4 bytes, unaligned\n    counter: u64, // 8 bytes, unaligned\n}\n// Size: 13 bytes (no padding)\n</code></pre>\n<p>This shrinks size to 13 bytes, ideal for tight memory constraints, but unaligned accesses to <code>value</code> and <code>counter</code> incur significant performance penalties.</p>\n<h2>Trade-Offs</h2>\n<table>\n<thead>\n<tr>\n<th>Aspect</th>\n<th><code>repr(C)</code></th>\n<th><code>repr(packed)</code></th>\n</tr>\n</thead>\n<tbody><tr>\n<td><strong>Performance</strong></td>\n<td>Fast aligned access, cache-efficient</td>\n<td>Slower unaligned access penalties</td>\n</tr>\n<tr>\n<td><strong>Memory Usage</strong></td>\n<td>Larger due to padding</td>\n<td>Minimal footprint</td>\n</tr>\n<tr>\n<td><strong>Portability</strong></td>\n<td>Safe across platforms</td>\n<td>Risk of UB or panics on strict architectures</td>\n</tr>\n</tbody></table>\n<ul>\n<li><strong>Performance</strong>: <code>repr(C)</code> wins for speedâ€”aligned access is faster and cache-efficient</li>\n<li><strong>Memory Usage</strong>: <code>repr(packed)</code> reduces footprint, critical for large arrays or tight constraints</li>\n<li><strong>Portability</strong>: <code>repr(C)</code> is safer; <code>repr(packed)</code> risks undefined behavior with unsafe dereferencing</li>\n</ul>\n<h2>Example Scenario</h2>\n<p>Real-time packet parser in a network server processing millions of packets per second:</p>\n<pre><code class=\"language-rust\">#[repr(C)]\nstruct Packet {\n    header: u8,   // 1 byte + 3 padding\n    id: u32,      // 4 bytes\n    payload: u64, // 8 bytes\n}\n</code></pre>\n<p>With <code>repr(C)</code>, size is 16 bytes, and <code>id</code>/<code>payload</code> are aligned, speeding up field access in tight loops checking <code>id</code>. Cache locality is decent since the struct fits in a 64-byte cache line.</p>\n<p>If using <code>repr(packed)</code> (13 bytes), I&#39;d save 3 bytes per packet, but unaligned <code>id</code> and <code>payload</code> accesses could halve throughput due to penaltiesâ€”unacceptable for this workload.</p>\n<p><strong>Choice</strong>: <code>repr(C)</code> for performance-critical code. Consider reordering fields (<code>payload</code>, <code>id</code>, <code>header</code>) to group hot fields together.</p>\n<p><strong>Alternative scenario</strong>: Serializing thousands of tiny structs to disk with infrequent accessâ€”<code>repr(packed)</code> might make sense to minimize storage, accepting slower deserialization.</p>\n<h2>Advanced Considerations</h2>\n<ul>\n<li>Use profiling tools like <code>perf</code> to confirm cache miss reductions</li>\n<li>Consider <code>#[repr(C, packed)]</code> for C-compatible but packed layout</li>\n<li>Field reordering can optimize cache line usage without changing <code>repr</code></li>\n<li>Test trade-offs on target hardware, especially ARM vs x86_64</li>\n</ul>\n<h2>Key Takeaways</h2>\n<p>âœ… <strong><code>repr(C)</code></strong>: Choose for performance-critical code where cache efficiency matters<br>âœ… <strong><code>repr(packed)</code></strong>: Use for memory-constrained scenarios with infrequent access<br>ðŸš€ Profile cache performance before and after to validate optimizations</p>\n<p><strong>Try This:</strong> What happens if you access a field in a <code>repr(packed)</code> struct through a raw pointer?<br><strong>Answer:</strong> Unaligned access through raw pointers can cause panics on strict architectures or performance penaltiesâ€”always measure on your target platform!</p>\n",
    "author": "mayo",
    "category": "rust",
    "tags": [
      "rust",
      "optimization",
      "memory",
      "performance",
      "cache"
    ],
    "readingTime": "3 min",
    "seo": {
      "title": "Rust's repr: Optimize Struct Memory for Cache Efficiency",
      "description": "Expert technical discussion on low-level memory optimization in Rust, covering repr attributes, cache efficiency, and performance trade-offs",
      "keywords": [
        "rust",
        "optimization",
        "memory",
        "performance",
        "cache"
      ]
    },
    "headings": [
      {
        "id": "how-they-work",
        "text": "How They Work",
        "level": 2
      },
      {
        "id": "optimization-for-cache-locality",
        "text": "Optimization for Cache Locality",
        "level": 2
      },
      {
        "id": "trade-offs",
        "text": "Trade-Offs",
        "level": 2
      },
      {
        "id": "example-scenario",
        "text": "Example Scenario",
        "level": 2
      },
      {
        "id": "advanced-considerations",
        "text": "Advanced Considerations",
        "level": 2
      },
      {
        "id": "key-takeaways",
        "text": "Key Takeaways",
        "level": 2
      }
    ]
  },
  {
    "id": "vec-new-vs-with-capacity",
    "slug": "vec-new-vs-with-capacity",
    "title": "Rust Vec::new() vs. with_capacity(): When to Use Each",
    "date": "2025-06-25",
    "excerpt": "An expert technical discussion on Vec allocation strategies in Rust, comparing Vec::new() and Vec::with_capacity() for optimal performance.",
    "content": "Understanding Vec allocation strategies is crucial for writing performant Rust code, especially when dealing with collections and iterators.\n\n## Key Differences\n\n| `Vec::new()` | `Vec::with_capacity(n)` |\n|--------------|-------------------------|\n| Creates an empty Vec with no pre-allocated space | Creates an empty Vec with space for n elements |\n| Initial capacity is 0 (allocates on first push) | Initial capacity is exactly n (no early allocations) |\n| Grows dynamically (may reallocate multiple times) | Avoids reallocation until len() > n |\n\n## When to Use Each\n\nUse `Vec::new()` when:\n- The number of elements is unknown or small\n- You want simplicity (e.g., short-lived vectors)\n\n```rust\nlet mut v = Vec::new(); // Good for ad-hoc usage\nv.push(1);\n```\n\nUse `Vec::with_capacity(n)` when:\n- You know the exact or maximum number of elements upfront\n- Optimizing for performance (avoids reallocations)\n\n```rust\nlet mut v = Vec::with_capacity(1000); // Pre-allocate for 1000 items\nfor i in 0..1000 {\n    v.push(i); // No reallocation happens\n}\n```\n\n## Performance Impact\n\n`Vec::new()` may trigger multiple reallocations as it grows (e.g., starts at 0, then 4, 8, 16, ...).\n`Vec::with_capacity(n)` guarantees one allocation upfront (if n is correct).\n\n## Example Benchmark\n\n```rust\nuse std::time::Instant;\n\nfn main() {\n    let start = Instant::now();\n    let mut v1 = Vec::new();\n    for i in 0..1_000_000 {\n        v1.push(i); // Reallocates ~20 times\n    }\n    println!(\"Vec::new(): {:?}\", start.elapsed());\n\n    let start = Instant::now();\n    let mut v2 = Vec::with_capacity(1_000_000);\n    for i in 0..1_000_000 {\n        v2.push(i); // No reallocations\n    }\n    println!(\"Vec::with_capacity(): {:?}\", start.elapsed());\n}\n```\n\nOutput (typical):\n```\nVec::new(): 1.2ms\nVec::with_capacity(): 0.3ms  // 4x faster\n```\n\n## Advanced Notes\n\n- `shrink_to_fit()`: Reduces excess capacity (e.g., after removing elements)\n- `vec![]` macro: Uses with_capacity implicitly for literals (e.g., vec![1, 2, 3])\n\n## Key Takeaways\n\nâœ… Default to `Vec::new()` for simplicity.  \nâœ… Use `with_capacity(n)` when:\n- You know the size upfront\n- Performance is critical (e.g., hot loops)\n\n**Try This:** What happens if you push beyond the pre-allocated capacity?  \n**Answer:** The Vec grows automatically (like `Vec::new()`), but only after exceeding n.",
    "contentHtml": "<p>Understanding Vec allocation strategies is crucial for writing performant Rust code, especially when dealing with collections and iterators.</p>\n<h2>Key Differences</h2>\n<table>\n<thead>\n<tr>\n<th><code>Vec::new()</code></th>\n<th><code>Vec::with_capacity(n)</code></th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Creates an empty Vec with no pre-allocated space</td>\n<td>Creates an empty Vec with space for n elements</td>\n</tr>\n<tr>\n<td>Initial capacity is 0 (allocates on first push)</td>\n<td>Initial capacity is exactly n (no early allocations)</td>\n</tr>\n<tr>\n<td>Grows dynamically (may reallocate multiple times)</td>\n<td>Avoids reallocation until len() &gt; n</td>\n</tr>\n</tbody></table>\n<h2>When to Use Each</h2>\n<p>Use <code>Vec::new()</code> when:</p>\n<ul>\n<li>The number of elements is unknown or small</li>\n<li>You want simplicity (e.g., short-lived vectors)</li>\n</ul>\n<pre><code class=\"language-rust\">let mut v = Vec::new(); // Good for ad-hoc usage\nv.push(1);\n</code></pre>\n<p>Use <code>Vec::with_capacity(n)</code> when:</p>\n<ul>\n<li>You know the exact or maximum number of elements upfront</li>\n<li>Optimizing for performance (avoids reallocations)</li>\n</ul>\n<pre><code class=\"language-rust\">let mut v = Vec::with_capacity(1000); // Pre-allocate for 1000 items\nfor i in 0..1000 {\n    v.push(i); // No reallocation happens\n}\n</code></pre>\n<h2>Performance Impact</h2>\n<p><code>Vec::new()</code> may trigger multiple reallocations as it grows (e.g., starts at 0, then 4, 8, 16, ...).\n<code>Vec::with_capacity(n)</code> guarantees one allocation upfront (if n is correct).</p>\n<h2>Example Benchmark</h2>\n<pre><code class=\"language-rust\">use std::time::Instant;\n\nfn main() {\n    let start = Instant::now();\n    let mut v1 = Vec::new();\n    for i in 0..1_000_000 {\n        v1.push(i); // Reallocates ~20 times\n    }\n    println!(&quot;Vec::new(): {:?}&quot;, start.elapsed());\n\n    let start = Instant::now();\n    let mut v2 = Vec::with_capacity(1_000_000);\n    for i in 0..1_000_000 {\n        v2.push(i); // No reallocations\n    }\n    println!(&quot;Vec::with_capacity(): {:?}&quot;, start.elapsed());\n}\n</code></pre>\n<p>Output (typical):</p>\n<pre><code>Vec::new(): 1.2ms\nVec::with_capacity(): 0.3ms  // 4x faster\n</code></pre>\n<h2>Advanced Notes</h2>\n<ul>\n<li><code>shrink_to_fit()</code>: Reduces excess capacity (e.g., after removing elements)</li>\n<li><code>vec![]</code> macro: Uses with_capacity implicitly for literals (e.g., vec![1, 2, 3])</li>\n</ul>\n<h2>Key Takeaways</h2>\n<p>âœ… Default to <code>Vec::new()</code> for simplicity.<br>âœ… Use <code>with_capacity(n)</code> when:</p>\n<ul>\n<li>You know the size upfront</li>\n<li>Performance is critical (e.g., hot loops)</li>\n</ul>\n<p><strong>Try This:</strong> What happens if you push beyond the pre-allocated capacity?<br><strong>Answer:</strong> The Vec grows automatically (like <code>Vec::new()</code>), but only after exceeding n.</p>\n",
    "author": "mayo",
    "category": "rust",
    "tags": [
      "rust",
      "collections",
      "performance",
      "vec",
      "iterators"
    ],
    "readingTime": "2 min",
    "seo": {
      "title": "Rust Vec::new() vs. with_capacity(): When to Use Each",
      "description": "An expert technical discussion on Vec allocation strategies in Rust, comparing Vec::new() and Vec::with_capacity() for optimal performance.",
      "keywords": [
        "rust",
        "collections",
        "performance",
        "vec",
        "iterators"
      ]
    },
    "headings": [
      {
        "id": "key-differences",
        "text": "Key Differences",
        "level": 2
      },
      {
        "id": "when-to-use-each",
        "text": "When to Use Each",
        "level": 2
      },
      {
        "id": "performance-impact",
        "text": "Performance Impact",
        "level": 2
      },
      {
        "id": "example-benchmark",
        "text": "Example Benchmark",
        "level": 2
      },
      {
        "id": "advanced-notes",
        "text": "Advanced Notes",
        "level": 2
      },
      {
        "id": "key-takeaways",
        "text": "Key Takeaways",
        "level": 2
      }
    ]
  },
  {
    "id": "getting-started-with-rust",
    "slug": "getting-started-with-rust",
    "title": "Getting Started with Rust: A Guide for Beginners",
    "date": "2025-04-15",
    "excerpt": "An introduction to Rust for beginners, covering installation, basic syntax, and your first project.",
    "content": "Rust has been gaining significant traction among developers for its focus on performance, memory safety, and concurrency. If you're new to Rust, this guide will help you get started with the basics.\n\n## Setting Up Your Environment\n\nFirst, you'll need to install Rust on your system. The easiest way is to use rustup, the Rust toolchain installer:\n\n```bash\ncurl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh\n```\n\nThis command will download a script and start the installation process. Follow the instructions on screen to complete the installation.\n\n## Your First Rust Program\n\nLet's create a simple \"Hello, World!\" program. Create a new file called `hello.rs` with the following content:\n\n```rust\nfn main() {\n    println!(\"Hello, World!\");\n}\n```\n\nTo compile and run this program, use the following commands:\n\n```bash\nrustc hello.rs\n./hello\n```\n\n## Understanding Cargo\n\nCargo is Rust's build system and package manager. It handles many tasks such as building your code, downloading libraries, and building those libraries.\n\nTo create a new project with Cargo:\n\n```bash\ncargo new hello_cargo\ncd hello_cargo\n```\n\nThis creates a new directory called `hello_cargo` with the following structure:\n\n```\nhello_cargo/\nâ”œâ”€â”€ Cargo.toml\nâ””â”€â”€ src/\n    â””â”€â”€ main.rs\n```\n\nThe `Cargo.toml` file contains metadata about your project and its dependencies. The `src/main.rs` file contains your application code.\n\nTo build and run your project:\n\n```bash\ncargo build   # Compile the project\ncargo run     # Compile and run the project\n```\n\n## Key Concepts in Rust\n\n### Variables and Mutability\n\nBy default, variables in Rust are immutable:\n\n```rust\nlet x = 5;\n// x = 6; // This would cause an error\n```\n\nTo make a variable mutable, use the `mut` keyword:\n\n```rust\nlet mut y = 5;\ny = 6; // This works fine\n```\n\n### Ownership\n\nOwnership is Rust's most unique feature and enables memory safety without garbage collection. The main rules are:\n\n1. Each value in Rust has a variable that's its owner.\n2. There can only be one owner at a time.\n3. When the owner goes out of scope, the value will be dropped.\n\n```rust\nfn main() {\n    let s1 = String::from(\"hello\");\n    let s2 = s1; // s1 is moved to s2, s1 is no longer valid\n    \n    // println!(\"{}\", s1); // This would cause an error\n    println!(\"{}\", s2); // This works fine\n}\n```\n\n## Next Steps\n\nNow that you have the basics, try building a small project to practice your skills. The Rust documentation is an excellent resource for learning more:\n\n- [The Rust Book](https://doc.rust-lang.org/book/)\n- [Rust by Example](https://doc.rust-lang.org/rust-by-example/)\n\nHappy coding with Rust!",
    "contentHtml": "<p>Rust has been gaining significant traction among developers for its focus on performance, memory safety, and concurrency. If you&#39;re new to Rust, this guide will help you get started with the basics.</p>\n<h2>Setting Up Your Environment</h2>\n<p>First, you&#39;ll need to install Rust on your system. The easiest way is to use rustup, the Rust toolchain installer:</p>\n<pre><code class=\"language-bash\">curl --proto &#39;=https&#39; --tlsv1.2 -sSf https://sh.rustup.rs | sh\n</code></pre>\n<p>This command will download a script and start the installation process. Follow the instructions on screen to complete the installation.</p>\n<h2>Your First Rust Program</h2>\n<p>Let&#39;s create a simple &quot;Hello, World!&quot; program. Create a new file called <code>hello.rs</code> with the following content:</p>\n<pre><code class=\"language-rust\">fn main() {\n    println!(&quot;Hello, World!&quot;);\n}\n</code></pre>\n<p>To compile and run this program, use the following commands:</p>\n<pre><code class=\"language-bash\">rustc hello.rs\n./hello\n</code></pre>\n<h2>Understanding Cargo</h2>\n<p>Cargo is Rust&#39;s build system and package manager. It handles many tasks such as building your code, downloading libraries, and building those libraries.</p>\n<p>To create a new project with Cargo:</p>\n<pre><code class=\"language-bash\">cargo new hello_cargo\ncd hello_cargo\n</code></pre>\n<p>This creates a new directory called <code>hello_cargo</code> with the following structure:</p>\n<pre><code>hello_cargo/\nâ”œâ”€â”€ Cargo.toml\nâ””â”€â”€ src/\n    â””â”€â”€ main.rs\n</code></pre>\n<p>The <code>Cargo.toml</code> file contains metadata about your project and its dependencies. The <code>src/main.rs</code> file contains your application code.</p>\n<p>To build and run your project:</p>\n<pre><code class=\"language-bash\">cargo build   # Compile the project\ncargo run     # Compile and run the project\n</code></pre>\n<h2>Key Concepts in Rust</h2>\n<h3>Variables and Mutability</h3>\n<p>By default, variables in Rust are immutable:</p>\n<pre><code class=\"language-rust\">let x = 5;\n// x = 6; // This would cause an error\n</code></pre>\n<p>To make a variable mutable, use the <code>mut</code> keyword:</p>\n<pre><code class=\"language-rust\">let mut y = 5;\ny = 6; // This works fine\n</code></pre>\n<h3>Ownership</h3>\n<p>Ownership is Rust&#39;s most unique feature and enables memory safety without garbage collection. The main rules are:</p>\n<ol>\n<li>Each value in Rust has a variable that&#39;s its owner.</li>\n<li>There can only be one owner at a time.</li>\n<li>When the owner goes out of scope, the value will be dropped.</li>\n</ol>\n<pre><code class=\"language-rust\">fn main() {\n    let s1 = String::from(&quot;hello&quot;);\n    let s2 = s1; // s1 is moved to s2, s1 is no longer valid\n    \n    // println!(&quot;{}&quot;, s1); // This would cause an error\n    println!(&quot;{}&quot;, s2); // This works fine\n}\n</code></pre>\n<h2>Next Steps</h2>\n<p>Now that you have the basics, try building a small project to practice your skills. The Rust documentation is an excellent resource for learning more:</p>\n<ul>\n<li><a href=\"https://doc.rust-lang.org/book/\">The Rust Book</a></li>\n<li><a href=\"https://doc.rust-lang.org/rust-by-example/\">Rust by Example</a></li>\n</ul>\n<p>Happy coding with Rust!</p>\n",
    "author": "Mayorana",
    "category": "rust",
    "tags": [
      "rust",
      "programming",
      "beginners",
      "tutorial"
    ],
    "readingTime": "3 min",
    "seo": {
      "title": "Getting Started with Rust: A Guide for Beginners",
      "description": "An introduction to Rust for beginners, covering installation, basic syntax, and your first project.",
      "keywords": [
        "rust",
        "programming",
        "beginners",
        "tutorial"
      ]
    },
    "headings": [
      {
        "id": "setting-up-your-environment",
        "text": "Setting Up Your Environment",
        "level": 2
      },
      {
        "id": "your-first-rust-program",
        "text": "Your First Rust Program",
        "level": 2
      },
      {
        "id": "understanding-cargo",
        "text": "Understanding Cargo",
        "level": 2
      },
      {
        "id": "key-concepts-in-rust",
        "text": "Key Concepts in Rust",
        "level": 2
      },
      {
        "id": "variables-and-mutability",
        "text": "Variables and Mutability",
        "level": 3
      },
      {
        "id": "ownership",
        "text": "Ownership",
        "level": 3
      },
      {
        "id": "next-steps",
        "text": "Next Steps",
        "level": 2
      }
    ]
  }
]