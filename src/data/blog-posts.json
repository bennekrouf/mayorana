[
  {
    "id": "borrowing-rules-rust",
    "slug": "borrowing-rules-rust",
    "title": "mutable vs. immutable borrows.",
    "date": "2025-08-10",
    "excerpt": "Rust memory and string",
    "content": "Rust’s borrowing rules, enforced by the borrow checker at compile time, ensure memory safety and prevent data races without runtime overhead. These rules govern how data can be accessed via references, distinguishing between mutable (`&mut T`) and immutable (`&T`) borrows.\n\n## The Borrowing Rules (Compiler-Enforced)\n\n1. **Either One Mutable Borrow (`&mut T`) OR Multiple Immutable Borrows (`&T`)**:\n   - You can have:\n     - **One mutable reference** (`&mut T`), OR\n     - **Any number of immutable references** (`&T`).\n   - Never both at the same time for the same data.\n2. **References Must Always Be Valid (No Dangling Pointers)**:\n   - Borrowed references cannot outlive the data they point to, enforced by Rust’s lifetime system.\n\n## Immutable Borrows (`&T`)\n\n- **Read-only access**: Cannot modify the data.\n- **Multiple allowed**: Safe for concurrent reads, as no modifications can occur.\n\n**Example**:\n```rust\nlet x = 42;\nlet r1 = &x;  // OK: Immutable borrow\nlet r2 = &x;  // OK: Another immutable borrow\nprintln!(\"{}, {}\", r1, r2);  // Works fine\n```\n\n## Mutable Borrows (`&mut T`)\n\n- **Exclusive access**: Allows modification of the data.\n- **No other borrows allowed**: No `&T` or additional `&mut T` can coexist for the same data.\n\n**Example**:\n```rust\nlet mut x = 42;\nlet r1 = &mut x;  // OK: Mutable borrow\n*r1 += 1;         // Can modify\n// let r2 = &x;   // ERROR: Cannot borrow `x` as immutable while mutable borrow exists\n```\n\n## Compiler Rejects These Scenarios\n\n1. **Mutable + Immutable Overlap**:\n   ```rust\n   let mut data = 10;\n   let r1 = &data;      // Immutable borrow\n   let r2 = &mut data;  // ERROR: Cannot borrow as mutable while borrowed as immutable\n   ```\n\n2. **Multiple Mutable Borrows**:\n   ```rust\n   let mut s = String::new();\n   let r1 = &mut s;\n   let r2 = &mut s;  // ERROR: Second mutable borrow\n   ```\n\n3. **Dangling References**:\n   ```rust\n   fn dangling() -> &String {\n       let s = String::from(\"oops\");\n       &s  // ERROR: `s` dies here, reference would dangle\n   }\n   ```\n\n## Why These Rules Matter\n\n- **Prevents Data Races**: By disallowing concurrent mutable access, Rust ensures thread safety by default.\n- **Ensures Memory Safety**: No dangling pointers or iterator invalidation, as the borrow checker enforces valid references.\n\n## Key Takeaways\n\n✅ **Immutable borrows (`&T`)**:\n- Many allowed, but no mutation.\n✅ **Mutable borrows (`&mut T`)**:\n- Only one allowed, exclusive access.\n🚫 **Violations caught at compile time**: No runtime overhead.\n\n**Real-World Impact**: These rules enable fearless concurrency, as seen in crates like `Rayon` for parallel iteration.\n\n**Experiment**: Try creating a function that takes `&mut T` and call it twice with the same data.  \n**Answer**: The borrow checker won’t allow it unless the first borrow’s scope ends, preventing overlapping mutable borrows.",
    "contentHtml": "<p>Rust’s borrowing rules, enforced by the borrow checker at compile time, ensure memory safety and prevent data races without runtime overhead. These rules govern how data can be accessed via references, distinguishing between mutable (<code>&amp;mut T</code>) and immutable (<code>&amp;T</code>) borrows.</p>\n<h2>The Borrowing Rules (Compiler-Enforced)</h2>\n<ol>\n<li><strong>Either One Mutable Borrow (<code>&amp;mut T</code>) OR Multiple Immutable Borrows (<code>&amp;T</code>)</strong>:<ul>\n<li>You can have:<ul>\n<li><strong>One mutable reference</strong> (<code>&amp;mut T</code>), OR</li>\n<li><strong>Any number of immutable references</strong> (<code>&amp;T</code>).</li>\n</ul>\n</li>\n<li>Never both at the same time for the same data.</li>\n</ul>\n</li>\n<li><strong>References Must Always Be Valid (No Dangling Pointers)</strong>:<ul>\n<li>Borrowed references cannot outlive the data they point to, enforced by Rust’s lifetime system.</li>\n</ul>\n</li>\n</ol>\n<h2>Immutable Borrows (<code>&amp;T</code>)</h2>\n<ul>\n<li><strong>Read-only access</strong>: Cannot modify the data.</li>\n<li><strong>Multiple allowed</strong>: Safe for concurrent reads, as no modifications can occur.</li>\n</ul>\n<p><strong>Example</strong>:</p>\n<pre><code class=\"language-rust\">let x = 42;\nlet r1 = &amp;x;  // OK: Immutable borrow\nlet r2 = &amp;x;  // OK: Another immutable borrow\nprintln!(&quot;{}, {}&quot;, r1, r2);  // Works fine\n</code></pre>\n<h2>Mutable Borrows (<code>&amp;mut T</code>)</h2>\n<ul>\n<li><strong>Exclusive access</strong>: Allows modification of the data.</li>\n<li><strong>No other borrows allowed</strong>: No <code>&amp;T</code> or additional <code>&amp;mut T</code> can coexist for the same data.</li>\n</ul>\n<p><strong>Example</strong>:</p>\n<pre><code class=\"language-rust\">let mut x = 42;\nlet r1 = &amp;mut x;  // OK: Mutable borrow\n*r1 += 1;         // Can modify\n// let r2 = &amp;x;   // ERROR: Cannot borrow `x` as immutable while mutable borrow exists\n</code></pre>\n<h2>Compiler Rejects These Scenarios</h2>\n<ol>\n<li><p><strong>Mutable + Immutable Overlap</strong>:</p>\n<pre><code class=\"language-rust\">let mut data = 10;\nlet r1 = &amp;data;      // Immutable borrow\nlet r2 = &amp;mut data;  // ERROR: Cannot borrow as mutable while borrowed as immutable\n</code></pre>\n</li>\n<li><p><strong>Multiple Mutable Borrows</strong>:</p>\n<pre><code class=\"language-rust\">let mut s = String::new();\nlet r1 = &amp;mut s;\nlet r2 = &amp;mut s;  // ERROR: Second mutable borrow\n</code></pre>\n</li>\n<li><p><strong>Dangling References</strong>:</p>\n<pre><code class=\"language-rust\">fn dangling() -&gt; &amp;String {\n    let s = String::from(&quot;oops&quot;);\n    &amp;s  // ERROR: `s` dies here, reference would dangle\n}\n</code></pre>\n</li>\n</ol>\n<h2>Why These Rules Matter</h2>\n<ul>\n<li><strong>Prevents Data Races</strong>: By disallowing concurrent mutable access, Rust ensures thread safety by default.</li>\n<li><strong>Ensures Memory Safety</strong>: No dangling pointers or iterator invalidation, as the borrow checker enforces valid references.</li>\n</ul>\n<h2>Key Takeaways</h2>\n<p>✅ <strong>Immutable borrows (<code>&amp;T</code>)</strong>:</p>\n<ul>\n<li>Many allowed, but no mutation.\n✅ <strong>Mutable borrows (<code>&amp;mut T</code>)</strong>:</li>\n<li>Only one allowed, exclusive access.\n🚫 <strong>Violations caught at compile time</strong>: No runtime overhead.</li>\n</ul>\n<p><strong>Real-World Impact</strong>: These rules enable fearless concurrency, as seen in crates like <code>Rayon</code> for parallel iteration.</p>\n<p><strong>Experiment</strong>: Try creating a function that takes <code>&amp;mut T</code> and call it twice with the same data.<br><strong>Answer</strong>: The borrow checker won’t allow it unless the first borrow’s scope ends, preventing overlapping mutable borrows.</p>\n",
    "author": "mayo",
    "category": "rust",
    "tags": [
      "rust",
      "memory",
      "borrowing",
      "ownership",
      "safety"
    ],
    "readingTime": "3 min",
    "locale": "en",
    "seo": {
      "title": "mutable vs. immutable borrows.",
      "description": "Rust memory and string",
      "keywords": [
        "rust",
        "memory",
        "borrowing",
        "ownership",
        "safety"
      ]
    },
    "headings": [
      {
        "id": "the-borrowing-rules-compiler-enforced",
        "text": "The Borrowing Rules (Compiler-Enforced)",
        "level": 2
      },
      {
        "id": "immutable-borrows-andt",
        "text": "Immutable Borrows (`&T`)",
        "level": 2
      },
      {
        "id": "mutable-borrows-andmut-t",
        "text": "Mutable Borrows (`&mut T`)",
        "level": 2
      },
      {
        "id": "compiler-rejects-these-scenarios",
        "text": "Compiler Rejects These Scenarios",
        "level": 2
      },
      {
        "id": "why-these-rules-matter",
        "text": "Why These Rules Matter",
        "level": 2
      },
      {
        "id": "key-takeaways",
        "text": "Key Takeaways",
        "level": 2
      }
    ]
  },
  {
    "id": "string-literals-memory-rust",
    "slug": "string-literals-memory-rust",
    "title": "Where do string literals (&str) live?",
    "date": "2025-08-06",
    "excerpt": "Rust memory and string",
    "content": "String literals (`&str`) in Rust are handled efficiently, with distinct memory characteristics compared to heap-allocated `String` types. Understanding their allocation and lifetime is key to writing performant and safe Rust code.\n\n## String Literals (&str) in Memory\n\n### Storage Location\n\n- String literals (e.g., `\"hello\"`) are stored in the **read-only data segment** (`.rodata`) of the compiled binary, not on the heap or stack.\n- They are embedded directly in the executable and loaded into memory at program startup.\n- Memory is **static**, meaning it lives for the entire program duration.\n\n### Type Inference\n\n- The type of `\"hello\"` is `&'static str`:\n  - `&str`: An immutable string slice.\n  - `'static`: A lifetime lasting the entire program.\n\n**Example: Memory Layout**:\n```rust\nlet s: &'static str = \"hello\"; // Points to static memory\n```\n\n- **Binary Representation**:\n  - Executable Memory: `\"hello\"` stored in `.rodata` section, e.g., at address `0x1000`.\n  - Variable `s`: A pointer (`0x1000`) + length (`5`), stored on the stack.\n\n## Key Properties\n\n| **Property** | **Explanation** |\n|--------------|-----------------|\n| **Immutable** | Cannot modify the literal (e.g., `\"hello\"[0] = 'H'` is forbidden). |\n| **Zero-Cost** | No runtime allocation (already in memory). |\n| **Lifetime** | Always `'static` (valid for the whole program). |\n\n## Comparison with `String`\n\n| **Feature** | **&'static str (literal)** | **String** |\n|-------------|----------------------------|------------|\n| **Memory Location** | Read-only data segment | Heap |\n| **Mutability** | Immutable | Mutable |\n| **Lifetime** | `'static` | Scoped to owner |\n| **Allocation Cost** | None (compile-time) | Runtime allocation |\n\n## Common Use Cases\n\n### Constants\n```rust\nconst GREETING: &str = \"hello\"; // No allocation\n```\n\n### Function Arguments\nPrefer `&str` over `&String` to accept literals without allocation:\n```rust\nfn print(s: &str) { /* ... */ }\nprint(\"world\"); // No conversion needed\n```\n\n## Why Not Always Use &'static str?\n\n- Limited to **compile-time-known strings**.\n- Cannot dynamically create or modify them (unlike `String`).\n\n**Example: Dynamic Strings Require `String`**:\n```rust\nlet name = \"Alice\".to_string(); // Heap-allocated copy\nname.push_str(\" and Bob\");      // Mutability possible\n```\n\n## The Problem: Dangling Pointer Risk\n\nReturning a reference (`&str`) to a local `String` creates a dangling pointer, as the `String` is dropped when the function ends.\n\n**Example: Code That Fails to Compile**:\n```rust\nfn return_str() -> &str {         // ERROR: Missing lifetime specifier!\n    let s = String::from(\"hello\");\n    &s                            // Returns a reference to `s`...\n}                                 // `s` is dropped here (dangling pointer!)\n```\n\n**Compiler Error**:\n```\nerror[E0106]: missing lifetime specifier\n --> src/main.rs:1:17\n  |\n1 | fn return_str() -> &str {\n  |                   ^ expected named lifetime parameter\n  |\n  = help: this function's return type contains a borrowed value, but there is no value for it to be borrowed from\n```\n\n### Why Rust Rejects This\n\n- **Ownership Rules**: `String` (`s`) is owned by the function and dropped when the scope ends. Returning `&s` would create a reference to freed memory.\n- **Lifetime Enforcement**: Rust requires explicit lifetimes to ensure references are always valid. Here, the reference (`&str`) has no owner to borrow from after the function exits.\n\n### How to Fix It\n\n#### Option 1: Return an Owned `String` (No Reference)\n```rust\nfn return_owned() -> String {  // Transfer ownership to caller\n    String::from(\"hello\")      // No reference, no lifetime issue\n}\n```\n\n#### Option 2: Return a `&'static str` (String Literal)\n```rust\nfn return_static() -> &'static str {  // Lives forever in binary\n    \"hello\"                          // Static memory (not heap)\n}\n```\n\n#### Option 3: Use `Cow<str>` for Flexibility\n```rust\nuse std::borrow::Cow;\n\nfn return_cow(is_heap: bool) -> Cow<'static, str> {\n    if is_heap {\n        Cow::Owned(String::from(\"hello\"))  // Heap-allocated\n    } else {\n        Cow::Borrowed(\"hello\")             // Static memory\n    }\n}\n```\n\n## Key Takeaways\n\n✅ **String literals**:\n- Live in static memory (part of the binary).\n- Are immutable and zero-cost.\n- Have `'static` lifetime.\n\n🚀 **When to use them**:\n- For fixed, read-only strings (e.g., messages, constants).\n- To avoid allocations in function APIs (`&str` over `&String`).\n\n✅ **Never return `&str` borrowed from a local `String`**—it’s impossible in safe Rust.\n\n✅ **Solutions**:\n- Return `String` (ownership transfer).\n- Use `&'static str` (literals only).\n- Use `Cow<str>` for dynamic choices.\n\n**Advanced Note**: Rust optimizes `&str` references to literals. Even if you write:\n```rust\nlet s = String::from(\"hello\");\nlet slice = &s[..]; // Points to heap, not static memory!\n```\nThe compiler may elide copies if the content is known statically.\n\n**Experiment**: What happens if you try returning `&s[..]` instead of `&s`?  \n**Answer**: No—it’s the same issue! The slice still points to the doomed `String`.",
    "contentHtml": "<p>String literals (<code>&amp;str</code>) in Rust are handled efficiently, with distinct memory characteristics compared to heap-allocated <code>String</code> types. Understanding their allocation and lifetime is key to writing performant and safe Rust code.</p>\n<h2>String Literals (&amp;str) in Memory</h2>\n<h3>Storage Location</h3>\n<ul>\n<li>String literals (e.g., <code>&quot;hello&quot;</code>) are stored in the <strong>read-only data segment</strong> (<code>.rodata</code>) of the compiled binary, not on the heap or stack.</li>\n<li>They are embedded directly in the executable and loaded into memory at program startup.</li>\n<li>Memory is <strong>static</strong>, meaning it lives for the entire program duration.</li>\n</ul>\n<h3>Type Inference</h3>\n<ul>\n<li>The type of <code>&quot;hello&quot;</code> is <code>&amp;&#39;static str</code>:<ul>\n<li><code>&amp;str</code>: An immutable string slice.</li>\n<li><code>&#39;static</code>: A lifetime lasting the entire program.</li>\n</ul>\n</li>\n</ul>\n<p><strong>Example: Memory Layout</strong>:</p>\n<pre><code class=\"language-rust\">let s: &amp;&#39;static str = &quot;hello&quot;; // Points to static memory\n</code></pre>\n<ul>\n<li><strong>Binary Representation</strong>:<ul>\n<li>Executable Memory: <code>&quot;hello&quot;</code> stored in <code>.rodata</code> section, e.g., at address <code>0x1000</code>.</li>\n<li>Variable <code>s</code>: A pointer (<code>0x1000</code>) + length (<code>5</code>), stored on the stack.</li>\n</ul>\n</li>\n</ul>\n<h2>Key Properties</h2>\n<table>\n<thead>\n<tr>\n<th><strong>Property</strong></th>\n<th><strong>Explanation</strong></th>\n</tr>\n</thead>\n<tbody><tr>\n<td><strong>Immutable</strong></td>\n<td>Cannot modify the literal (e.g., <code>&quot;hello&quot;[0] = &#39;H&#39;</code> is forbidden).</td>\n</tr>\n<tr>\n<td><strong>Zero-Cost</strong></td>\n<td>No runtime allocation (already in memory).</td>\n</tr>\n<tr>\n<td><strong>Lifetime</strong></td>\n<td>Always <code>&#39;static</code> (valid for the whole program).</td>\n</tr>\n</tbody></table>\n<h2>Comparison with <code>String</code></h2>\n<table>\n<thead>\n<tr>\n<th><strong>Feature</strong></th>\n<th><strong>&amp;&#39;static str (literal)</strong></th>\n<th><strong>String</strong></th>\n</tr>\n</thead>\n<tbody><tr>\n<td><strong>Memory Location</strong></td>\n<td>Read-only data segment</td>\n<td>Heap</td>\n</tr>\n<tr>\n<td><strong>Mutability</strong></td>\n<td>Immutable</td>\n<td>Mutable</td>\n</tr>\n<tr>\n<td><strong>Lifetime</strong></td>\n<td><code>&#39;static</code></td>\n<td>Scoped to owner</td>\n</tr>\n<tr>\n<td><strong>Allocation Cost</strong></td>\n<td>None (compile-time)</td>\n<td>Runtime allocation</td>\n</tr>\n</tbody></table>\n<h2>Common Use Cases</h2>\n<h3>Constants</h3>\n<pre><code class=\"language-rust\">const GREETING: &amp;str = &quot;hello&quot;; // No allocation\n</code></pre>\n<h3>Function Arguments</h3>\n<p>Prefer <code>&amp;str</code> over <code>&amp;String</code> to accept literals without allocation:</p>\n<pre><code class=\"language-rust\">fn print(s: &amp;str) { /* ... */ }\nprint(&quot;world&quot;); // No conversion needed\n</code></pre>\n<h2>Why Not Always Use &amp;&#39;static str?</h2>\n<ul>\n<li>Limited to <strong>compile-time-known strings</strong>.</li>\n<li>Cannot dynamically create or modify them (unlike <code>String</code>).</li>\n</ul>\n<p><strong>Example: Dynamic Strings Require <code>String</code></strong>:</p>\n<pre><code class=\"language-rust\">let name = &quot;Alice&quot;.to_string(); // Heap-allocated copy\nname.push_str(&quot; and Bob&quot;);      // Mutability possible\n</code></pre>\n<h2>The Problem: Dangling Pointer Risk</h2>\n<p>Returning a reference (<code>&amp;str</code>) to a local <code>String</code> creates a dangling pointer, as the <code>String</code> is dropped when the function ends.</p>\n<p><strong>Example: Code That Fails to Compile</strong>:</p>\n<pre><code class=\"language-rust\">fn return_str() -&gt; &amp;str {         // ERROR: Missing lifetime specifier!\n    let s = String::from(&quot;hello&quot;);\n    &amp;s                            // Returns a reference to `s`...\n}                                 // `s` is dropped here (dangling pointer!)\n</code></pre>\n<p><strong>Compiler Error</strong>:</p>\n<pre><code>error[E0106]: missing lifetime specifier\n --&gt; src/main.rs:1:17\n  |\n1 | fn return_str() -&gt; &amp;str {\n  |                   ^ expected named lifetime parameter\n  |\n  = help: this function&#39;s return type contains a borrowed value, but there is no value for it to be borrowed from\n</code></pre>\n<h3>Why Rust Rejects This</h3>\n<ul>\n<li><strong>Ownership Rules</strong>: <code>String</code> (<code>s</code>) is owned by the function and dropped when the scope ends. Returning <code>&amp;s</code> would create a reference to freed memory.</li>\n<li><strong>Lifetime Enforcement</strong>: Rust requires explicit lifetimes to ensure references are always valid. Here, the reference (<code>&amp;str</code>) has no owner to borrow from after the function exits.</li>\n</ul>\n<h3>How to Fix It</h3>\n<h4>Option 1: Return an Owned <code>String</code> (No Reference)</h4>\n<pre><code class=\"language-rust\">fn return_owned() -&gt; String {  // Transfer ownership to caller\n    String::from(&quot;hello&quot;)      // No reference, no lifetime issue\n}\n</code></pre>\n<h4>Option 2: Return a <code>&amp;&#39;static str</code> (String Literal)</h4>\n<pre><code class=\"language-rust\">fn return_static() -&gt; &amp;&#39;static str {  // Lives forever in binary\n    &quot;hello&quot;                          // Static memory (not heap)\n}\n</code></pre>\n<h4>Option 3: Use <code>Cow&lt;str&gt;</code> for Flexibility</h4>\n<pre><code class=\"language-rust\">use std::borrow::Cow;\n\nfn return_cow(is_heap: bool) -&gt; Cow&lt;&#39;static, str&gt; {\n    if is_heap {\n        Cow::Owned(String::from(&quot;hello&quot;))  // Heap-allocated\n    } else {\n        Cow::Borrowed(&quot;hello&quot;)             // Static memory\n    }\n}\n</code></pre>\n<h2>Key Takeaways</h2>\n<p>✅ <strong>String literals</strong>:</p>\n<ul>\n<li>Live in static memory (part of the binary).</li>\n<li>Are immutable and zero-cost.</li>\n<li>Have <code>&#39;static</code> lifetime.</li>\n</ul>\n<p>🚀 <strong>When to use them</strong>:</p>\n<ul>\n<li>For fixed, read-only strings (e.g., messages, constants).</li>\n<li>To avoid allocations in function APIs (<code>&amp;str</code> over <code>&amp;String</code>).</li>\n</ul>\n<p>✅ <strong>Never return <code>&amp;str</code> borrowed from a local <code>String</code></strong>—it’s impossible in safe Rust.</p>\n<p>✅ <strong>Solutions</strong>:</p>\n<ul>\n<li>Return <code>String</code> (ownership transfer).</li>\n<li>Use <code>&amp;&#39;static str</code> (literals only).</li>\n<li>Use <code>Cow&lt;str&gt;</code> for dynamic choices.</li>\n</ul>\n<p><strong>Advanced Note</strong>: Rust optimizes <code>&amp;str</code> references to literals. Even if you write:</p>\n<pre><code class=\"language-rust\">let s = String::from(&quot;hello&quot;);\nlet slice = &amp;s[..]; // Points to heap, not static memory!\n</code></pre>\n<p>The compiler may elide copies if the content is known statically.</p>\n<p><strong>Experiment</strong>: What happens if you try returning <code>&amp;s[..]</code> instead of <code>&amp;s</code>?<br><strong>Answer</strong>: No—it’s the same issue! The slice still points to the doomed <code>String</code>.</p>\n",
    "author": "mayo",
    "category": "rust",
    "tags": [
      "rust",
      "memory",
      "string",
      "str",
      "allocation"
    ],
    "readingTime": "4 min",
    "locale": "en",
    "seo": {
      "title": "Where do string literals (&str) live?",
      "description": "Rust memory and string",
      "keywords": [
        "rust",
        "memory",
        "string",
        "str",
        "allocation"
      ]
    },
    "headings": [
      {
        "id": "string-literals-andstr-in-memory",
        "text": "String Literals (&str) in Memory",
        "level": 2
      },
      {
        "id": "storage-location",
        "text": "Storage Location",
        "level": 3
      },
      {
        "id": "type-inference",
        "text": "Type Inference",
        "level": 3
      },
      {
        "id": "key-properties",
        "text": "Key Properties",
        "level": 2
      },
      {
        "id": "comparison-with-string",
        "text": "Comparison with `String`",
        "level": 2
      },
      {
        "id": "common-use-cases",
        "text": "Common Use Cases",
        "level": 2
      },
      {
        "id": "constants",
        "text": "Constants",
        "level": 3
      },
      {
        "id": "function-arguments",
        "text": "Function Arguments",
        "level": 3
      },
      {
        "id": "why-not-always-use-andstatic-str",
        "text": "Why Not Always Use &'static str?",
        "level": 2
      },
      {
        "id": "the-problem-dangling-pointer-risk",
        "text": "The Problem: Dangling Pointer Risk",
        "level": 2
      },
      {
        "id": "why-rust-rejects-this",
        "text": "Why Rust Rejects This",
        "level": 3
      },
      {
        "id": "how-to-fix-it",
        "text": "How to Fix It",
        "level": 3
      },
      {
        "id": "option-1-return-an-owned-string-no-reference",
        "text": "Option 1: Return an Owned `String` (No Reference)",
        "level": 4
      },
      {
        "id": "option-2-return-a-andstatic-str-string-literal",
        "text": "Option 2: Return a `&'static str` (String Literal)",
        "level": 4
      },
      {
        "id": "option-3-use-cowlessstrgreater-for-flexibility",
        "text": "Option 3: Use `Cow<str>` for Flexibility",
        "level": 4
      },
      {
        "id": "key-takeaways",
        "text": "Key Takeaways",
        "level": 2
      }
    ]
  },
  {
    "id": "box-pointer-rust",
    "slug": "box-pointer-rust",
    "title": "What is the purpose of Box<T> in Rust?",
    "date": "2025-08-05",
    "excerpt": "Rust memory and string",
    "content": "`Box<T>` is a smart pointer in Rust that provides heap allocation for a value of type `T`. It is the simplest way to store data on the heap, offering ownership and memory safety guarantees without runtime overhead.\n\n## What is Box<T>?\n\n- **Heap Allocation**: Moves data from the stack to the heap.\n  ```rust\n  let x = Box::new(42); // `42` is stored on the heap\n  ```\n- **Ownership**: `Box<T>` owns the data and ensures it is dropped when the `Box` goes out of scope.\n- **Fixed Size**: The `Box` itself is a pointer (`usize`) with a known stack size, even if `T` is dynamically sized (e.g., `Box<dyn Trait>`).\n\n## When to Use Box<T>\n\n### 1. Recursive Types (e.g., Linked Lists)\nRust requires compile-time-known sizes, but recursive types (like trees or lists) would be infinitely sized without indirection.\n\n```rust\nenum List {\n    Cons(i32, Box<List>), // Without `Box`, this would be invalid\n    Nil,\n}\n```\n\n### 2. Large Data (Avoid Stack Overflow)\nMoving large structs (e.g., a 1MB buffer) to the heap prevents stack overflows.\n\n```rust\nlet big_data = Box::new([0u8; 1_000_000]); // Heap-allocated array\n```\n\n### 3. Trait Objects (dyn Trait)\nStoring heterogeneous types behind a trait interface for dynamic dispatch.\n\n```rust\ntrait Animal { fn speak(&self); }\nstruct Cat;\nimpl Animal for Cat { fn speak(&self) { println!(\"Meow\"); } }\n\nlet animals: Vec<Box<dyn Animal>> = vec![Box::new(Cat)]; // Dynamic dispatch\n```\n\n### 4. Transferring Ownership Across Threads\n`Box` can be used with `std::thread::spawn` to move owned data to another thread.\n\n```rust\nlet x = Box::new(42);\nstd::thread::spawn(move || {\n    println!(\"{}\", x); // `x` is moved into the thread\n});\n```\n\n## How Box<T> Differs from Other Pointers\n\n| **Type** | **Ownership** | **Use Case** |\n|----------|---------------|--------------|\n| `Box<T>` | Owned (unique) | Heap allocation, recursive types |\n| `&T`/`&mut T` | Borrowed | Temporary references |\n| `Rc<T>` | Shared (reference-counted) | Multiple owners in single-threaded code |\n| `Arc<T>` | Shared (atomic refcount) | Thread-safe multiple owners |\n\n## Memory Safety Guarantees\n\n- **No manual `free()`**: Automatically deallocates when `Box` goes out of scope.\n- **No null pointers**: `Box` cannot be null (unlike raw pointers).\n- **No leaks**: Compiler enforces ownership rules.\n\n## Example: Box vs Stack Allocation\n\n```rust\n// Stack (fails if too large)\n// let arr = [0u8; 10_000_000]; // Likely stack overflow\n\n// Heap (works)\nlet arr = Box::new([0u8; 10_000_000]); // Safe\n```\n\n## Key Takeaways\n\n✅ **Use `Box<T>` when you need**:\n- Heap allocation for large or recursive data.\n- Trait objects (`dyn Trait`).\n- Explicit ownership with a fixed-size pointer.\n\n🚫 **Avoid if**:\n- You only need a reference (`&T`).\n- You need shared ownership (use `Rc` or `Arc` instead).\n\n**Thought Experiment**: What happens if you try to `Box` a value already on the heap?  \n**Answer**: It’s fine—just adds another pointer indirection, as the `Box` will point to the new heap allocation.",
    "contentHtml": "<p><code>Box&lt;T&gt;</code> is a smart pointer in Rust that provides heap allocation for a value of type <code>T</code>. It is the simplest way to store data on the heap, offering ownership and memory safety guarantees without runtime overhead.</p>\n<h2>What is Box<T>?</h2>\n<ul>\n<li><strong>Heap Allocation</strong>: Moves data from the stack to the heap.<pre><code class=\"language-rust\">let x = Box::new(42); // `42` is stored on the heap\n</code></pre>\n</li>\n<li><strong>Ownership</strong>: <code>Box&lt;T&gt;</code> owns the data and ensures it is dropped when the <code>Box</code> goes out of scope.</li>\n<li><strong>Fixed Size</strong>: The <code>Box</code> itself is a pointer (<code>usize</code>) with a known stack size, even if <code>T</code> is dynamically sized (e.g., <code>Box&lt;dyn Trait&gt;</code>).</li>\n</ul>\n<h2>When to Use Box<T></h2>\n<h3>1. Recursive Types (e.g., Linked Lists)</h3>\n<p>Rust requires compile-time-known sizes, but recursive types (like trees or lists) would be infinitely sized without indirection.</p>\n<pre><code class=\"language-rust\">enum List {\n    Cons(i32, Box&lt;List&gt;), // Without `Box`, this would be invalid\n    Nil,\n}\n</code></pre>\n<h3>2. Large Data (Avoid Stack Overflow)</h3>\n<p>Moving large structs (e.g., a 1MB buffer) to the heap prevents stack overflows.</p>\n<pre><code class=\"language-rust\">let big_data = Box::new([0u8; 1_000_000]); // Heap-allocated array\n</code></pre>\n<h3>3. Trait Objects (dyn Trait)</h3>\n<p>Storing heterogeneous types behind a trait interface for dynamic dispatch.</p>\n<pre><code class=\"language-rust\">trait Animal { fn speak(&amp;self); }\nstruct Cat;\nimpl Animal for Cat { fn speak(&amp;self) { println!(&quot;Meow&quot;); } }\n\nlet animals: Vec&lt;Box&lt;dyn Animal&gt;&gt; = vec![Box::new(Cat)]; // Dynamic dispatch\n</code></pre>\n<h3>4. Transferring Ownership Across Threads</h3>\n<p><code>Box</code> can be used with <code>std::thread::spawn</code> to move owned data to another thread.</p>\n<pre><code class=\"language-rust\">let x = Box::new(42);\nstd::thread::spawn(move || {\n    println!(&quot;{}&quot;, x); // `x` is moved into the thread\n});\n</code></pre>\n<h2>How Box<T> Differs from Other Pointers</h2>\n<table>\n<thead>\n<tr>\n<th><strong>Type</strong></th>\n<th><strong>Ownership</strong></th>\n<th><strong>Use Case</strong></th>\n</tr>\n</thead>\n<tbody><tr>\n<td><code>Box&lt;T&gt;</code></td>\n<td>Owned (unique)</td>\n<td>Heap allocation, recursive types</td>\n</tr>\n<tr>\n<td><code>&amp;T</code>/<code>&amp;mut T</code></td>\n<td>Borrowed</td>\n<td>Temporary references</td>\n</tr>\n<tr>\n<td><code>Rc&lt;T&gt;</code></td>\n<td>Shared (reference-counted)</td>\n<td>Multiple owners in single-threaded code</td>\n</tr>\n<tr>\n<td><code>Arc&lt;T&gt;</code></td>\n<td>Shared (atomic refcount)</td>\n<td>Thread-safe multiple owners</td>\n</tr>\n</tbody></table>\n<h2>Memory Safety Guarantees</h2>\n<ul>\n<li><strong>No manual <code>free()</code></strong>: Automatically deallocates when <code>Box</code> goes out of scope.</li>\n<li><strong>No null pointers</strong>: <code>Box</code> cannot be null (unlike raw pointers).</li>\n<li><strong>No leaks</strong>: Compiler enforces ownership rules.</li>\n</ul>\n<h2>Example: Box vs Stack Allocation</h2>\n<pre><code class=\"language-rust\">// Stack (fails if too large)\n// let arr = [0u8; 10_000_000]; // Likely stack overflow\n\n// Heap (works)\nlet arr = Box::new([0u8; 10_000_000]); // Safe\n</code></pre>\n<h2>Key Takeaways</h2>\n<p>✅ <strong>Use <code>Box&lt;T&gt;</code> when you need</strong>:</p>\n<ul>\n<li>Heap allocation for large or recursive data.</li>\n<li>Trait objects (<code>dyn Trait</code>).</li>\n<li>Explicit ownership with a fixed-size pointer.</li>\n</ul>\n<p>🚫 <strong>Avoid if</strong>:</p>\n<ul>\n<li>You only need a reference (<code>&amp;T</code>).</li>\n<li>You need shared ownership (use <code>Rc</code> or <code>Arc</code> instead).</li>\n</ul>\n<p><strong>Thought Experiment</strong>: What happens if you try to <code>Box</code> a value already on the heap?<br><strong>Answer</strong>: It’s fine—just adds another pointer indirection, as the <code>Box</code> will point to the new heap allocation.</p>\n",
    "author": "mayo",
    "category": "rust",
    "tags": [
      "rust",
      "memory",
      "box",
      "heap",
      "ownership"
    ],
    "readingTime": "3 min",
    "locale": "en",
    "seo": {
      "title": "What is the purpose of Box<T> in Rust?",
      "description": "Rust memory and string",
      "keywords": [
        "rust",
        "memory",
        "box",
        "heap",
        "ownership"
      ]
    },
    "headings": [
      {
        "id": "what-is-boxlesstgreater",
        "text": "What is Box<T>?",
        "level": 2
      },
      {
        "id": "when-to-use-boxlesstgreater",
        "text": "When to Use Box<T>",
        "level": 2
      },
      {
        "id": "1-recursive-types-eg-linked-lists",
        "text": "1. Recursive Types (e.g., Linked Lists)",
        "level": 3
      },
      {
        "id": "2-large-data-avoid-stack-overflow",
        "text": "2. Large Data (Avoid Stack Overflow)",
        "level": 3
      },
      {
        "id": "3-trait-objects-dyn-trait",
        "text": "3. Trait Objects (dyn Trait)",
        "level": 3
      },
      {
        "id": "4-transferring-ownership-across-threads",
        "text": "4. Transferring Ownership Across Threads",
        "level": 3
      },
      {
        "id": "how-boxlesstgreater-differs-from-other-pointers",
        "text": "How Box<T> Differs from Other Pointers",
        "level": 2
      },
      {
        "id": "memory-safety-guarantees",
        "text": "Memory Safety Guarantees",
        "level": 2
      },
      {
        "id": "example-box-vs-stack-allocation",
        "text": "Example: Box vs Stack Allocation",
        "level": 2
      },
      {
        "id": "key-takeaways",
        "text": "Key Takeaways",
        "level": 2
      }
    ]
  },
  {
    "id": "string-str-mismatch-rust",
    "slug": "string-str-mismatch-rust",
    "title": "Why &str Won't Fit &String in Rust: Fun Fixes for String Mismatches!",
    "date": "2025-08-04",
    "excerpt": "Rust memory and string",
    "content": "In Rust, you cannot pass a `&str` directly to a function expecting a `&String` due to their distinct types, which ensures type safety and prevents assumptions about memory ownership. Below, I explain why this mismatch occurs and how to handle it effectively.\n\n## The Core Issue: Type Mismatch\n\n- **`&String`**: A reference to a heap-allocated, growable `String`.\n- **`&str`**: A string slice that can point to heap, stack, or static memory.\n- They are **different types**, so Rust rejects implicit conversions for safety.\n\n**Example: The Problem**:\n```rust\nfn print_string(s: &String) {\n    println!(\"{}\", s);\n}\n\nfn main() {\n    let my_str = \"hello\";  // Type: `&'static str`\n    print_string(my_str);  // ERROR: expected `&String`, found `&str`\n}\n```\n\n## Solutions to Bridge &str and &String\n\n### 1. Deref Coercion (Automatic Conversion)\n\nRust automatically converts `&String` to `&str` via the `Deref` trait, but not the reverse. The best fix is to change the function to accept `&str` for greater flexibility.\n\n```rust\nfn print_str(s: &str) {  // Now accepts both `&str` and `&String`\n    println!(\"{}\", s);\n}\n\nfn main() {\n    let my_string = String::from(\"hello\");\n    let my_str = \"world\";\n    print_str(&my_string);  // Works: `&String` coerces to `&str`\n    print_str(my_str);      // Works directly\n}\n```\n\n**Why this works**: `String` implements `Deref<Target=str>`, allowing `&String` to coerce to `&str`.\n\n### 2. Explicit Conversion (When You Need &String)\n\nIf the function must take `&String`, convert `&str` to a `String` first:\n\n```rust\nfn print_string(s: &String) {\n    println!(\"{}\", s);\n}\n\nfn main() {\n    let my_str = \"hello\";\n    print_string(&my_str.to_string());  // Allocates a new `String`\n}\n```\n\n**Drawback**: This allocates a new heap buffer, which should be avoided if possible due to performance costs.\n\n### 3. Use `AsRef<str>` for Maximum Flexibility\n\nFor functions that should work with any string-like type:\n\n```rust\nfn print_as_str<S: AsRef<str>>(s: S) {\n    println!(\"{}\", s.as_ref());\n}\n\nfn main() {\n    let my_string = String::from(\"hello\");\n    let my_str = \"world\";\n    print_as_str(&my_string);  // Works\n    print_as_str(my_str);      // Works\n}\n```\n\n**Bonus**: Also accepts `Cow<str>`, `Box<str>`, etc.\n\n## Key Takeaways\n\n✅ **Preferred**: Use `&str` in function arguments (flexible and zero-cost).  \n✅ **If stuck with `&String`**: Convert `&str` to `String` (allocates).  \n✅ **For APIs**: Use `AsRef<str>` or `impl Deref<Target=str>` for maximum compatibility.\n\n**Why Rust Enforces This**:\n- Prevents accidental allocations or assumptions about memory ownership.\n- Encourages efficient, borrow-friendly APIs.\n\n**Try This**: What happens if you pass a `String` to `print_str` without `&`?  \n**Answer**: It moves ownership, causing a compile error since `print_str` expects a reference (`&str`), not an owned `String`.",
    "contentHtml": "<p>In Rust, you cannot pass a <code>&amp;str</code> directly to a function expecting a <code>&amp;String</code> due to their distinct types, which ensures type safety and prevents assumptions about memory ownership. Below, I explain why this mismatch occurs and how to handle it effectively.</p>\n<h2>The Core Issue: Type Mismatch</h2>\n<ul>\n<li><strong><code>&amp;String</code></strong>: A reference to a heap-allocated, growable <code>String</code>.</li>\n<li><strong><code>&amp;str</code></strong>: A string slice that can point to heap, stack, or static memory.</li>\n<li>They are <strong>different types</strong>, so Rust rejects implicit conversions for safety.</li>\n</ul>\n<p><strong>Example: The Problem</strong>:</p>\n<pre><code class=\"language-rust\">fn print_string(s: &amp;String) {\n    println!(&quot;{}&quot;, s);\n}\n\nfn main() {\n    let my_str = &quot;hello&quot;;  // Type: `&amp;&#39;static str`\n    print_string(my_str);  // ERROR: expected `&amp;String`, found `&amp;str`\n}\n</code></pre>\n<h2>Solutions to Bridge &amp;str and &amp;String</h2>\n<h3>1. Deref Coercion (Automatic Conversion)</h3>\n<p>Rust automatically converts <code>&amp;String</code> to <code>&amp;str</code> via the <code>Deref</code> trait, but not the reverse. The best fix is to change the function to accept <code>&amp;str</code> for greater flexibility.</p>\n<pre><code class=\"language-rust\">fn print_str(s: &amp;str) {  // Now accepts both `&amp;str` and `&amp;String`\n    println!(&quot;{}&quot;, s);\n}\n\nfn main() {\n    let my_string = String::from(&quot;hello&quot;);\n    let my_str = &quot;world&quot;;\n    print_str(&amp;my_string);  // Works: `&amp;String` coerces to `&amp;str`\n    print_str(my_str);      // Works directly\n}\n</code></pre>\n<p><strong>Why this works</strong>: <code>String</code> implements <code>Deref&lt;Target=str&gt;</code>, allowing <code>&amp;String</code> to coerce to <code>&amp;str</code>.</p>\n<h3>2. Explicit Conversion (When You Need &amp;String)</h3>\n<p>If the function must take <code>&amp;String</code>, convert <code>&amp;str</code> to a <code>String</code> first:</p>\n<pre><code class=\"language-rust\">fn print_string(s: &amp;String) {\n    println!(&quot;{}&quot;, s);\n}\n\nfn main() {\n    let my_str = &quot;hello&quot;;\n    print_string(&amp;my_str.to_string());  // Allocates a new `String`\n}\n</code></pre>\n<p><strong>Drawback</strong>: This allocates a new heap buffer, which should be avoided if possible due to performance costs.</p>\n<h3>3. Use <code>AsRef&lt;str&gt;</code> for Maximum Flexibility</h3>\n<p>For functions that should work with any string-like type:</p>\n<pre><code class=\"language-rust\">fn print_as_str&lt;S: AsRef&lt;str&gt;&gt;(s: S) {\n    println!(&quot;{}&quot;, s.as_ref());\n}\n\nfn main() {\n    let my_string = String::from(&quot;hello&quot;);\n    let my_str = &quot;world&quot;;\n    print_as_str(&amp;my_string);  // Works\n    print_as_str(my_str);      // Works\n}\n</code></pre>\n<p><strong>Bonus</strong>: Also accepts <code>Cow&lt;str&gt;</code>, <code>Box&lt;str&gt;</code>, etc.</p>\n<h2>Key Takeaways</h2>\n<p>✅ <strong>Preferred</strong>: Use <code>&amp;str</code> in function arguments (flexible and zero-cost).<br>✅ <strong>If stuck with <code>&amp;String</code></strong>: Convert <code>&amp;str</code> to <code>String</code> (allocates).<br>✅ <strong>For APIs</strong>: Use <code>AsRef&lt;str&gt;</code> or <code>impl Deref&lt;Target=str&gt;</code> for maximum compatibility.</p>\n<p><strong>Why Rust Enforces This</strong>:</p>\n<ul>\n<li>Prevents accidental allocations or assumptions about memory ownership.</li>\n<li>Encourages efficient, borrow-friendly APIs.</li>\n</ul>\n<p><strong>Try This</strong>: What happens if you pass a <code>String</code> to <code>print_str</code> without <code>&amp;</code>?<br><strong>Answer</strong>: It moves ownership, causing a compile error since <code>print_str</code> expects a reference (<code>&amp;str</code>), not an owned <code>String</code>.</p>\n",
    "author": "mayo",
    "category": "rust",
    "tags": [
      "rust",
      "memory",
      "string",
      "str",
      "ownership"
    ],
    "readingTime": "3 min",
    "locale": "en",
    "seo": {
      "title": "Why &str Won't Fit &String in Rust: Fun Fixes for String Mismatches!",
      "description": "Rust memory and string",
      "keywords": [
        "rust",
        "memory",
        "string",
        "str",
        "ownership"
      ]
    },
    "headings": [
      {
        "id": "the-core-issue-type-mismatch",
        "text": "The Core Issue: Type Mismatch",
        "level": 2
      },
      {
        "id": "solutions-to-bridge-andstr-and-andstring",
        "text": "Solutions to Bridge &str and &String",
        "level": 2
      },
      {
        "id": "1-deref-coercion-automatic-conversion",
        "text": "1. Deref Coercion (Automatic Conversion)",
        "level": 3
      },
      {
        "id": "2-explicit-conversion-when-you-need-andstring",
        "text": "2. Explicit Conversion (When You Need &String)",
        "level": 3
      },
      {
        "id": "3-use-asreflessstrgreater-for-maximum-flexibility",
        "text": "3. Use `AsRef<str>` for Maximum Flexibility",
        "level": 3
      },
      {
        "id": "key-takeaways",
        "text": "Key Takeaways",
        "level": 2
      }
    ]
  },
  {
    "id": "dangling-pointer-rust",
    "slug": "dangling-pointer-rust",
    "title": "How does Rust prevent dangling pointer at compile time?",
    "date": "2025-08-03",
    "excerpt": "Rust memory and string",
    "content": "A **dangling pointer** occurs when a pointer references memory that has already been freed, leading to undefined behavior like crashes or security vulnerabilities. In languages like C/C++, this is a common issue:\n\n```c\nint* create_int() {\n    int x = 5;  // `x` lives on the stack\n    return &x;  // Returns a pointer to `x`...\n}  // `x` is destroyed here (dangling pointer returned!)\n```\n\nRust eliminates dangling pointers at compile time using its ownership model and lifetime system, ensuring memory safety without runtime overhead.\n\n## How Rust Prevents Dangling Pointers\n\nRust uses two key mechanisms to prevent dangling pointers:\n\n### 1. Ownership + Borrowing Rules\n\n- **Rule**: References (`&T` or `&mut T`) must not outlive the data they point to.\n- **Enforced by**: The borrow checker, which tracks variable scopes and ensures references remain valid.\n\n**Example: Rejected at Compile Time**:\n```rust\nfn dangling() -> &String {  // Missing lifetime specifier!\n    let s = String::from(\"hello\");\n    &s  // ERROR: `s` dies at end of function\n}       // Compiler: \"returns a reference to dropped data\"\n```\n\n**Fixed with Lifetimes** (Explicit Guarantee):\n```rust\nfn valid_reference<'a>(s: &'a String) -> &'a String {\n    s  // OK: Returned reference tied to input's lifetime\n}\n```\n\n### 2. Lifetime Annotations\n\n- Rust requires **explicit lifetime declarations** (`'a`) when references cross scope boundaries.\n- The compiler ensures all references obey their assigned lifetimes, preventing references to freed memory.\n\n**Example: Struct with Reference**:\n```rust\nstruct Book<'a> {  // Must declare lifetime\n    title: &'a str  // Reference must live as long as `Book`\n}\n\nfn main() {\n    let title = String::from(\"Rust\");\n    let book = Book { title: &title };\n    // `book.title` cannot outlive `title`\n}\n```\n\n## Why This Matters\n\n| **Language** | **Dangling Pointer Risk** | **Safety Mechanism** |\n|--------------|---------------------------|----------------------|\n| C/C++        | High (manual memory mgmt) | None (programmer's responsibility) |\n| Rust         | Zero                      | Compile-time checks (ownership + lifetimes) |\n\n## Key Takeaways\n\n✅ Rust’s compiler guarantees:\n- No references to freed memory.\n- No undefined behavior from dangling pointers.\n- Safety without runtime overhead.\n\n**Real-World Impact**: Crates like `hyper` (HTTP) and `tokio` (async) rely on these guarantees for secure, performant code.",
    "contentHtml": "<p>A <strong>dangling pointer</strong> occurs when a pointer references memory that has already been freed, leading to undefined behavior like crashes or security vulnerabilities. In languages like C/C++, this is a common issue:</p>\n<pre><code class=\"language-c\">int* create_int() {\n    int x = 5;  // `x` lives on the stack\n    return &amp;x;  // Returns a pointer to `x`...\n}  // `x` is destroyed here (dangling pointer returned!)\n</code></pre>\n<p>Rust eliminates dangling pointers at compile time using its ownership model and lifetime system, ensuring memory safety without runtime overhead.</p>\n<h2>How Rust Prevents Dangling Pointers</h2>\n<p>Rust uses two key mechanisms to prevent dangling pointers:</p>\n<h3>1. Ownership + Borrowing Rules</h3>\n<ul>\n<li><strong>Rule</strong>: References (<code>&amp;T</code> or <code>&amp;mut T</code>) must not outlive the data they point to.</li>\n<li><strong>Enforced by</strong>: The borrow checker, which tracks variable scopes and ensures references remain valid.</li>\n</ul>\n<p><strong>Example: Rejected at Compile Time</strong>:</p>\n<pre><code class=\"language-rust\">fn dangling() -&gt; &amp;String {  // Missing lifetime specifier!\n    let s = String::from(&quot;hello&quot;);\n    &amp;s  // ERROR: `s` dies at end of function\n}       // Compiler: &quot;returns a reference to dropped data&quot;\n</code></pre>\n<p><strong>Fixed with Lifetimes</strong> (Explicit Guarantee):</p>\n<pre><code class=\"language-rust\">fn valid_reference&lt;&#39;a&gt;(s: &amp;&#39;a String) -&gt; &amp;&#39;a String {\n    s  // OK: Returned reference tied to input&#39;s lifetime\n}\n</code></pre>\n<h3>2. Lifetime Annotations</h3>\n<ul>\n<li>Rust requires <strong>explicit lifetime declarations</strong> (<code>&#39;a</code>) when references cross scope boundaries.</li>\n<li>The compiler ensures all references obey their assigned lifetimes, preventing references to freed memory.</li>\n</ul>\n<p><strong>Example: Struct with Reference</strong>:</p>\n<pre><code class=\"language-rust\">struct Book&lt;&#39;a&gt; {  // Must declare lifetime\n    title: &amp;&#39;a str  // Reference must live as long as `Book`\n}\n\nfn main() {\n    let title = String::from(&quot;Rust&quot;);\n    let book = Book { title: &amp;title };\n    // `book.title` cannot outlive `title`\n}\n</code></pre>\n<h2>Why This Matters</h2>\n<table>\n<thead>\n<tr>\n<th><strong>Language</strong></th>\n<th><strong>Dangling Pointer Risk</strong></th>\n<th><strong>Safety Mechanism</strong></th>\n</tr>\n</thead>\n<tbody><tr>\n<td>C/C++</td>\n<td>High (manual memory mgmt)</td>\n<td>None (programmer&#39;s responsibility)</td>\n</tr>\n<tr>\n<td>Rust</td>\n<td>Zero</td>\n<td>Compile-time checks (ownership + lifetimes)</td>\n</tr>\n</tbody></table>\n<h2>Key Takeaways</h2>\n<p>✅ Rust’s compiler guarantees:</p>\n<ul>\n<li>No references to freed memory.</li>\n<li>No undefined behavior from dangling pointers.</li>\n<li>Safety without runtime overhead.</li>\n</ul>\n<p><strong>Real-World Impact</strong>: Crates like <code>hyper</code> (HTTP) and <code>tokio</code> (async) rely on these guarantees for secure, performant code.</p>\n",
    "author": "mayo",
    "category": "rust",
    "tags": [
      "rust",
      "memory",
      "dangling-pointer",
      "ownership",
      "lifetimes"
    ],
    "readingTime": "2 min",
    "locale": "en",
    "seo": {
      "title": "How does Rust prevent dangling pointer at compile time?",
      "description": "Rust memory and string",
      "keywords": [
        "rust",
        "memory",
        "dangling-pointer",
        "ownership",
        "lifetimes"
      ]
    },
    "headings": [
      {
        "id": "how-rust-prevents-dangling-pointers",
        "text": "How Rust Prevents Dangling Pointers",
        "level": 2
      },
      {
        "id": "1-ownership-borrowing-rules",
        "text": "1. Ownership + Borrowing Rules",
        "level": 3
      },
      {
        "id": "2-lifetime-annotations",
        "text": "2. Lifetime Annotations",
        "level": 3
      },
      {
        "id": "why-this-matters",
        "text": "Why This Matters",
        "level": 2
      },
      {
        "id": "key-takeaways",
        "text": "Key Takeaways",
        "level": 2
      }
    ]
  },
  {
    "id": "ownership-safety-rust",
    "slug": "ownership-safety-rust",
    "title": "How does ownership prevent memory leaks and data races?",
    "date": "2025-08-02",
    "excerpt": "Rust memory and string",
    "content": "Ownership is Rust's core memory management system, enforcing strict rules at compile time to ensure safety without a garbage collector. It prevents memory leaks and data races through a combination of ownership rules, move semantics, and borrowing.\n\n## Ownership in Rust\n\n- Each value has a **single owner** (variable).\n- When the owner goes out of scope, the value is **dropped** (`Drop` trait called).\n- Ownership can be **transferred** (moved), making the original variable invalid.\n\n## Key Rules\n\n### Move Semantics\n\nAssigning a heap-allocated value (e.g., `String`) to another variable transfers ownership, invalidating the original.\n\n**Example**:\n```rust\nlet s1 = String::from(\"hello\");\nlet s2 = s1; // Ownership moved to s2\n// println!(\"{}\", s1); // Compile error: value borrowed after move\n```\n\n### Copy vs. Move\n\n- Types with **known size** (`i32`, `bool`) implement `Copy` and are cloned automatically.\n- Heap-allocated types (`String`, `Vec`) do not implement `Copy` and are moved.\n\n### Function Calls\n\nPassing a value to a function moves or copies it, following the same rules.\n\n**Example**:\n```rust\nfn take_ownership(s: String) { /* ... */ }\n\nlet s = String::from(\"hello\");\ntake_ownership(s); // Ownership moved into the function\n// println!(\"{}\", s); // Error: s is invalid\n```\n\n## How Ownership Prevents Memory Leaks\n\n- **Automatic Cleanup**: When the owner goes out of scope, Rust calls `drop` to free memory (no manual `free()` needed).\n- **No Double Frees**: Since only one owner exists, the value is dropped exactly once.\n\n## How Ownership Prevents Data Races\n\n- **Borrowing Rules**:\n  - **Immutable borrows** (`&T`): Multiple allowed, but no mutable borrows can coexist.\n  - **Mutable borrows** (`&mut T`): Only one allowed, and no other borrows can exist.\n- **Compile-Time Enforcement**: The compiler rejects code that could lead to data races.\n\n**Example: Data Race Prevention**:\n```rust\nlet mut data = vec![1, 2, 3];\n\nlet r1 = &data; // Immutable borrow OK\nlet r2 = &data; // Another immutable borrow OK\n// let r3 = &mut data; // ERROR: Cannot borrow as mutable while immutable borrows exist\n\nprintln!(\"{:?}, {:?}\", r1, r2);\n```\n\n## Key Takeaways\n\n✅ **Ownership ensures**:\n- No dangling pointers (via lifetimes).\n- No memory leaks (via `Drop`).\n- No data races (via borrowing rules).\n\nRust’s ownership model guarantees memory safety and concurrency safety at compile time, delivering performance and reliability.",
    "contentHtml": "<p>Ownership is Rust&#39;s core memory management system, enforcing strict rules at compile time to ensure safety without a garbage collector. It prevents memory leaks and data races through a combination of ownership rules, move semantics, and borrowing.</p>\n<h2>Ownership in Rust</h2>\n<ul>\n<li>Each value has a <strong>single owner</strong> (variable).</li>\n<li>When the owner goes out of scope, the value is <strong>dropped</strong> (<code>Drop</code> trait called).</li>\n<li>Ownership can be <strong>transferred</strong> (moved), making the original variable invalid.</li>\n</ul>\n<h2>Key Rules</h2>\n<h3>Move Semantics</h3>\n<p>Assigning a heap-allocated value (e.g., <code>String</code>) to another variable transfers ownership, invalidating the original.</p>\n<p><strong>Example</strong>:</p>\n<pre><code class=\"language-rust\">let s1 = String::from(&quot;hello&quot;);\nlet s2 = s1; // Ownership moved to s2\n// println!(&quot;{}&quot;, s1); // Compile error: value borrowed after move\n</code></pre>\n<h3>Copy vs. Move</h3>\n<ul>\n<li>Types with <strong>known size</strong> (<code>i32</code>, <code>bool</code>) implement <code>Copy</code> and are cloned automatically.</li>\n<li>Heap-allocated types (<code>String</code>, <code>Vec</code>) do not implement <code>Copy</code> and are moved.</li>\n</ul>\n<h3>Function Calls</h3>\n<p>Passing a value to a function moves or copies it, following the same rules.</p>\n<p><strong>Example</strong>:</p>\n<pre><code class=\"language-rust\">fn take_ownership(s: String) { /* ... */ }\n\nlet s = String::from(&quot;hello&quot;);\ntake_ownership(s); // Ownership moved into the function\n// println!(&quot;{}&quot;, s); // Error: s is invalid\n</code></pre>\n<h2>How Ownership Prevents Memory Leaks</h2>\n<ul>\n<li><strong>Automatic Cleanup</strong>: When the owner goes out of scope, Rust calls <code>drop</code> to free memory (no manual <code>free()</code> needed).</li>\n<li><strong>No Double Frees</strong>: Since only one owner exists, the value is dropped exactly once.</li>\n</ul>\n<h2>How Ownership Prevents Data Races</h2>\n<ul>\n<li><strong>Borrowing Rules</strong>:<ul>\n<li><strong>Immutable borrows</strong> (<code>&amp;T</code>): Multiple allowed, but no mutable borrows can coexist.</li>\n<li><strong>Mutable borrows</strong> (<code>&amp;mut T</code>): Only one allowed, and no other borrows can exist.</li>\n</ul>\n</li>\n<li><strong>Compile-Time Enforcement</strong>: The compiler rejects code that could lead to data races.</li>\n</ul>\n<p><strong>Example: Data Race Prevention</strong>:</p>\n<pre><code class=\"language-rust\">let mut data = vec![1, 2, 3];\n\nlet r1 = &amp;data; // Immutable borrow OK\nlet r2 = &amp;data; // Another immutable borrow OK\n// let r3 = &amp;mut data; // ERROR: Cannot borrow as mutable while immutable borrows exist\n\nprintln!(&quot;{:?}, {:?}&quot;, r1, r2);\n</code></pre>\n<h2>Key Takeaways</h2>\n<p>✅ <strong>Ownership ensures</strong>:</p>\n<ul>\n<li>No dangling pointers (via lifetimes).</li>\n<li>No memory leaks (via <code>Drop</code>).</li>\n<li>No data races (via borrowing rules).</li>\n</ul>\n<p>Rust’s ownership model guarantees memory safety and concurrency safety at compile time, delivering performance and reliability.</p>\n",
    "author": "mayo",
    "category": "rust",
    "tags": [
      "rust",
      "memory",
      "ownership",
      "borrowing",
      "data-races"
    ],
    "readingTime": "2 min",
    "locale": "en",
    "seo": {
      "title": "How does ownership prevent memory leaks and data races?",
      "description": "Rust memory and string",
      "keywords": [
        "rust",
        "memory",
        "ownership",
        "borrowing",
        "data-races"
      ]
    },
    "headings": [
      {
        "id": "ownership-in-rust",
        "text": "Ownership in Rust",
        "level": 2
      },
      {
        "id": "key-rules",
        "text": "Key Rules",
        "level": 2
      },
      {
        "id": "move-semantics",
        "text": "Move Semantics",
        "level": 3
      },
      {
        "id": "copy-vs-move",
        "text": "Copy vs. Move",
        "level": 3
      },
      {
        "id": "function-calls",
        "text": "Function Calls",
        "level": 3
      },
      {
        "id": "how-ownership-prevents-memory-leaks",
        "text": "How Ownership Prevents Memory Leaks",
        "level": 2
      },
      {
        "id": "how-ownership-prevents-data-races",
        "text": "How Ownership Prevents Data Races",
        "level": 2
      },
      {
        "id": "key-takeaways",
        "text": "Key Takeaways",
        "level": 2
      }
    ]
  },
  {
    "id": "stack-heap-allocation-rust",
    "slug": "stack-heap-allocation-rust",
    "title": "Stack vs. Heap in Rust: Where Does Your Data Live?",
    "date": "2025-08-01",
    "excerpt": "Rust memory and string",
    "content": "Rust uses stack and heap allocation to manage memory, with distinct characteristics for each. Understanding their differences and how Rust decides where to allocate data is key to writing efficient and safe code.\n\n## Stack vs. Heap in Rust\n\n| **Stack** | **Heap** |\n|-----------|----------|\n| Fast allocation/deallocation (LIFO). | Slower allocation (dynamic). |\n| Fixed, known size at compile time. | Size can grow (e.g., `String`, `Vec`). |\n| Automatic cleanup (no `free()` needed). | Manual management (via `Drop` trait). |\n| Used for primitive types (`i32`, `bool`), small structs. | Used for large, dynamic data (`String`, `Box<T>`). |\n\n## How Rust Decides Where to Allocate\n\n### By Default → Stack\n\nIf a type has a **fixed size** (e.g., `i32`, arrays, structs with no `String`/`Vec`), it is allocated on the **stack**.\n\n**Example**:\n```rust\nlet x = 5; // Stack (i32 is fixed-size)\n```\n\n### Explicit Heap Allocation\n\nUse types like `Box<T>`, `String`, `Vec`, etc., to allocate on the **heap**.\n\n**Example**:\n```rust\nlet s = String::from(\"heap\"); // Heap (growable UTF-8 string)\nlet boxed = Box::new(42);     // Heap (Box<T>)\n```\n\n## Move Semantics\n\nWhen a value is **moved**, its heap data is transferred, not copied, ensuring efficient memory management.\n\n**Example**:\n```rust\nlet s1 = String::from(\"hello\"); // Heap-allocated\nlet s2 = s1; // Moves ownership (heap data not copied)\n// println!(\"{}\", s1); // ERROR: s1 is invalidated\n```\n\n## Key Takeaways\n\n✅ **Stack**: Fast, fixed-size, automatic.  \n✅ **Heap**: Flexible, dynamic, manual (via smart pointers).  \n✅ Rust defaults to stack but uses heap for growable/unknown-size data.\n\n**Follow-Up**: When would you force heap allocation?  \n- For large structs (avoid stack overflow).  \n- When you need dynamic dispatch (e.g., `Box<dyn Trait>`).  \n- To share ownership across threads (`Arc<T>`).",
    "contentHtml": "<p>Rust uses stack and heap allocation to manage memory, with distinct characteristics for each. Understanding their differences and how Rust decides where to allocate data is key to writing efficient and safe code.</p>\n<h2>Stack vs. Heap in Rust</h2>\n<table>\n<thead>\n<tr>\n<th><strong>Stack</strong></th>\n<th><strong>Heap</strong></th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Fast allocation/deallocation (LIFO).</td>\n<td>Slower allocation (dynamic).</td>\n</tr>\n<tr>\n<td>Fixed, known size at compile time.</td>\n<td>Size can grow (e.g., <code>String</code>, <code>Vec</code>).</td>\n</tr>\n<tr>\n<td>Automatic cleanup (no <code>free()</code> needed).</td>\n<td>Manual management (via <code>Drop</code> trait).</td>\n</tr>\n<tr>\n<td>Used for primitive types (<code>i32</code>, <code>bool</code>), small structs.</td>\n<td>Used for large, dynamic data (<code>String</code>, <code>Box&lt;T&gt;</code>).</td>\n</tr>\n</tbody></table>\n<h2>How Rust Decides Where to Allocate</h2>\n<h3>By Default → Stack</h3>\n<p>If a type has a <strong>fixed size</strong> (e.g., <code>i32</code>, arrays, structs with no <code>String</code>/<code>Vec</code>), it is allocated on the <strong>stack</strong>.</p>\n<p><strong>Example</strong>:</p>\n<pre><code class=\"language-rust\">let x = 5; // Stack (i32 is fixed-size)\n</code></pre>\n<h3>Explicit Heap Allocation</h3>\n<p>Use types like <code>Box&lt;T&gt;</code>, <code>String</code>, <code>Vec</code>, etc., to allocate on the <strong>heap</strong>.</p>\n<p><strong>Example</strong>:</p>\n<pre><code class=\"language-rust\">let s = String::from(&quot;heap&quot;); // Heap (growable UTF-8 string)\nlet boxed = Box::new(42);     // Heap (Box&lt;T&gt;)\n</code></pre>\n<h2>Move Semantics</h2>\n<p>When a value is <strong>moved</strong>, its heap data is transferred, not copied, ensuring efficient memory management.</p>\n<p><strong>Example</strong>:</p>\n<pre><code class=\"language-rust\">let s1 = String::from(&quot;hello&quot;); // Heap-allocated\nlet s2 = s1; // Moves ownership (heap data not copied)\n// println!(&quot;{}&quot;, s1); // ERROR: s1 is invalidated\n</code></pre>\n<h2>Key Takeaways</h2>\n<p>✅ <strong>Stack</strong>: Fast, fixed-size, automatic.<br>✅ <strong>Heap</strong>: Flexible, dynamic, manual (via smart pointers).<br>✅ Rust defaults to stack but uses heap for growable/unknown-size data.</p>\n<p><strong>Follow-Up</strong>: When would you force heap allocation?  </p>\n<ul>\n<li>For large structs (avoid stack overflow).  </li>\n<li>When you need dynamic dispatch (e.g., <code>Box&lt;dyn Trait&gt;</code>).  </li>\n<li>To share ownership across threads (<code>Arc&lt;T&gt;</code>).</li>\n</ul>\n",
    "author": "mayo",
    "category": "rust",
    "tags": [
      "rust",
      "memory",
      "stack",
      "heap",
      "allocation"
    ],
    "readingTime": "2 min",
    "locale": "en",
    "seo": {
      "title": "Stack vs. Heap in Rust: Where Does Your Data Live?",
      "description": "Rust memory and string",
      "keywords": [
        "rust",
        "memory",
        "stack",
        "heap",
        "allocation"
      ]
    },
    "headings": [
      {
        "id": "stack-vs-heap-in-rust",
        "text": "Stack vs. Heap in Rust",
        "level": 2
      },
      {
        "id": "how-rust-decides-where-to-allocate",
        "text": "How Rust Decides Where to Allocate",
        "level": 2
      },
      {
        "id": "by-default-stack",
        "text": "By Default → Stack",
        "level": 3
      },
      {
        "id": "explicit-heap-allocation",
        "text": "Explicit Heap Allocation",
        "level": 3
      },
      {
        "id": "move-semantics",
        "text": "Move Semantics",
        "level": 2
      },
      {
        "id": "key-takeaways",
        "text": "Key Takeaways",
        "level": 2
      }
    ]
  },
  {
    "id": "memory-safety-rust",
    "slug": "memory-safety-rust",
    "title": "How does Rust ensure memory safety without a garbage collector?",
    "date": "2025-07-31",
    "excerpt": "Rust memory and string",
    "content": "Rust guarantees memory safety at compile time using three key mechanisms: ownership, borrowing, and lifetimes. These ensure no memory leaks, data races, or dangling pointers without the need for a garbage collector.\n\n## The C/C++ Problem\nC and C++ give developers complete control over memory, but this leads to critical safety issues:\n\n**Dangling Pointers**:\n```c\nchar* get_string() {\n    char buffer[100] = \"hello\"; // Stack allocated\n    return buffer;              // Returns pointer to freed memory\n} // ERROR: buffer is destroyed here\n\nint* ptr = malloc(sizeof(int));\nfree(ptr);\n*ptr = 42; // ERROR: Use after free\n```\n\n**Memory Leaks**:\n```cpp\nvoid leak_memory() {\n    int* data = new int[1000]; // Heap allocation\n    if (some_condition) {\n        return; // ERROR: Memory never freed\n    }\n    delete[] data; // Only freed on normal path\n}\n```\n\n**Double Free**:\n```c\nint* ptr = malloc(sizeof(int));\nfree(ptr);\nfree(ptr); // ERROR: Double free causes undefined behavior\n```\n\n## Java's Garbage Collection Approach\nJava solves these issues with automatic memory management:\n\n**✅ Pros**:\n- No dangling pointers (references become null when objects are collected)\n- No memory leaks for reachable objects\n- No double free errors\n\n**❌ Cons**:\n- **Runtime overhead**: GC pauses can cause unpredictable latency\n- **Memory overhead**: Additional metadata for tracking objects\n- **No deterministic cleanup**: Objects freed at GC's discretion, not immediately\n\n```java\n// Java - memory managed automatically\nString createString() {\n    String s = new String(\"hello\"); // Heap allocated\n    return s; // Safe: GC will clean up when no longer referenced\n} // No explicit cleanup needed\n```\n\n## 1. Ownership Rules\n- Each value in Rust has a **single owner**.\n- When the owner goes out of scope, the value is **dropped** (memory freed).\n- Prevents **double frees** and **memory leaks**.\n\n**Example**:\n```rust\nfn main() {\n    let s = String::from(\"hello\"); // `s` owns the string\n    takes_ownership(s);            // Ownership moved → `s` is invalid here\n    // println!(\"{}\", s); // ERROR: borrow of moved value\n}\n\nfn takes_ownership(s: String) { \n    println!(\"{}\", s); \n} // `s` is dropped here\n```\n\n## 2. Borrowing & References\n- Allows **immutable** (`&T`) or **mutable** (`&mut T`) borrows.\n- Enforced rules:\n  - Either **one mutable reference** or **multiple immutable references** (no data races).\n  - References must always be **valid** (no dangling pointers).\n\n**Example**:\n```rust\nfn main() {\n    let mut s = String::from(\"hello\");\n    let r1 = &s;     // OK: Immutable borrow\n    let r2 = &s;     // OK: Another immutable borrow\n    // let r3 = &mut s; // ERROR: Cannot borrow as mutable while borrowed as immutable\n    println!(\"{}, {}\", r1, r2);\n}\n```\n\n## 3. Lifetimes\n- Ensures references **never outlive** the data they point to.\n- Prevents **dangling references**.\n\n**Example**:\n```rust\nfn longest<'a>(x: &'a str, y: &'a str) -> &'a str {\n    if x.len() > y.len() { x } else { y }\n}\n\nfn main() {\n    let s1 = String::from(\"hello\");\n    let result;\n    {\n        let s2 = String::from(\"world\");\n        result = longest(&s1, &s2); // ERROR: `s2` doesn't live long enough\n    }\n    // println!(\"{}\", result); // `result` would be invalid here\n}\n```\n\n## Why No Garbage Collector (GC)?\n- **Zero-cost abstractions**: No runtime overhead.\n- **Predictable performance**: Memory is freed deterministically.\n- **No runtime pauses**: Unlike GC-based languages (Java, Go).\n\n## Key Takeaways\n✅ **Ownership**: Prevents memory leaks.  \n✅ **Borrowing**: Prevents data races.  \n✅ **Lifetimes**: Prevents dangling pointers.\n\nRust's model ensures memory safety without runtime checks, making it both safe and fast.",
    "contentHtml": "<p>Rust guarantees memory safety at compile time using three key mechanisms: ownership, borrowing, and lifetimes. These ensure no memory leaks, data races, or dangling pointers without the need for a garbage collector.</p>\n<h2>The C/C++ Problem</h2>\n<p>C and C++ give developers complete control over memory, but this leads to critical safety issues:</p>\n<p><strong>Dangling Pointers</strong>:</p>\n<pre><code class=\"language-c\">char* get_string() {\n    char buffer[100] = &quot;hello&quot;; // Stack allocated\n    return buffer;              // Returns pointer to freed memory\n} // ERROR: buffer is destroyed here\n\nint* ptr = malloc(sizeof(int));\nfree(ptr);\n*ptr = 42; // ERROR: Use after free\n</code></pre>\n<p><strong>Memory Leaks</strong>:</p>\n<pre><code class=\"language-cpp\">void leak_memory() {\n    int* data = new int[1000]; // Heap allocation\n    if (some_condition) {\n        return; // ERROR: Memory never freed\n    }\n    delete[] data; // Only freed on normal path\n}\n</code></pre>\n<p><strong>Double Free</strong>:</p>\n<pre><code class=\"language-c\">int* ptr = malloc(sizeof(int));\nfree(ptr);\nfree(ptr); // ERROR: Double free causes undefined behavior\n</code></pre>\n<h2>Java&#39;s Garbage Collection Approach</h2>\n<p>Java solves these issues with automatic memory management:</p>\n<p><strong>✅ Pros</strong>:</p>\n<ul>\n<li>No dangling pointers (references become null when objects are collected)</li>\n<li>No memory leaks for reachable objects</li>\n<li>No double free errors</li>\n</ul>\n<p><strong>❌ Cons</strong>:</p>\n<ul>\n<li><strong>Runtime overhead</strong>: GC pauses can cause unpredictable latency</li>\n<li><strong>Memory overhead</strong>: Additional metadata for tracking objects</li>\n<li><strong>No deterministic cleanup</strong>: Objects freed at GC&#39;s discretion, not immediately</li>\n</ul>\n<pre><code class=\"language-java\">// Java - memory managed automatically\nString createString() {\n    String s = new String(&quot;hello&quot;); // Heap allocated\n    return s; // Safe: GC will clean up when no longer referenced\n} // No explicit cleanup needed\n</code></pre>\n<h2>1. Ownership Rules</h2>\n<ul>\n<li>Each value in Rust has a <strong>single owner</strong>.</li>\n<li>When the owner goes out of scope, the value is <strong>dropped</strong> (memory freed).</li>\n<li>Prevents <strong>double frees</strong> and <strong>memory leaks</strong>.</li>\n</ul>\n<p><strong>Example</strong>:</p>\n<pre><code class=\"language-rust\">fn main() {\n    let s = String::from(&quot;hello&quot;); // `s` owns the string\n    takes_ownership(s);            // Ownership moved → `s` is invalid here\n    // println!(&quot;{}&quot;, s); // ERROR: borrow of moved value\n}\n\nfn takes_ownership(s: String) { \n    println!(&quot;{}&quot;, s); \n} // `s` is dropped here\n</code></pre>\n<h2>2. Borrowing &amp; References</h2>\n<ul>\n<li>Allows <strong>immutable</strong> (<code>&amp;T</code>) or <strong>mutable</strong> (<code>&amp;mut T</code>) borrows.</li>\n<li>Enforced rules:<ul>\n<li>Either <strong>one mutable reference</strong> or <strong>multiple immutable references</strong> (no data races).</li>\n<li>References must always be <strong>valid</strong> (no dangling pointers).</li>\n</ul>\n</li>\n</ul>\n<p><strong>Example</strong>:</p>\n<pre><code class=\"language-rust\">fn main() {\n    let mut s = String::from(&quot;hello&quot;);\n    let r1 = &amp;s;     // OK: Immutable borrow\n    let r2 = &amp;s;     // OK: Another immutable borrow\n    // let r3 = &amp;mut s; // ERROR: Cannot borrow as mutable while borrowed as immutable\n    println!(&quot;{}, {}&quot;, r1, r2);\n}\n</code></pre>\n<h2>3. Lifetimes</h2>\n<ul>\n<li>Ensures references <strong>never outlive</strong> the data they point to.</li>\n<li>Prevents <strong>dangling references</strong>.</li>\n</ul>\n<p><strong>Example</strong>:</p>\n<pre><code class=\"language-rust\">fn longest&lt;&#39;a&gt;(x: &amp;&#39;a str, y: &amp;&#39;a str) -&gt; &amp;&#39;a str {\n    if x.len() &gt; y.len() { x } else { y }\n}\n\nfn main() {\n    let s1 = String::from(&quot;hello&quot;);\n    let result;\n    {\n        let s2 = String::from(&quot;world&quot;);\n        result = longest(&amp;s1, &amp;s2); // ERROR: `s2` doesn&#39;t live long enough\n    }\n    // println!(&quot;{}&quot;, result); // `result` would be invalid here\n}\n</code></pre>\n<h2>Why No Garbage Collector (GC)?</h2>\n<ul>\n<li><strong>Zero-cost abstractions</strong>: No runtime overhead.</li>\n<li><strong>Predictable performance</strong>: Memory is freed deterministically.</li>\n<li><strong>No runtime pauses</strong>: Unlike GC-based languages (Java, Go).</li>\n</ul>\n<h2>Key Takeaways</h2>\n<p>✅ <strong>Ownership</strong>: Prevents memory leaks.<br>✅ <strong>Borrowing</strong>: Prevents data races.<br>✅ <strong>Lifetimes</strong>: Prevents dangling pointers.</p>\n<p>Rust&#39;s model ensures memory safety without runtime checks, making it both safe and fast.</p>\n",
    "author": "mayo",
    "category": "rust",
    "tags": [
      "rust",
      "memory",
      "ownership",
      "borrowing",
      "lifetimes"
    ],
    "readingTime": "3 min",
    "locale": "en",
    "seo": {
      "title": "How does Rust ensure memory safety without a garbage collector?",
      "description": "Rust memory and string",
      "keywords": [
        "rust",
        "memory",
        "ownership",
        "borrowing",
        "lifetimes"
      ]
    },
    "headings": [
      {
        "id": "the-cc-problem",
        "text": "The C/C++ Problem",
        "level": 2
      },
      {
        "id": "javas-garbage-collection-approach",
        "text": "Java's Garbage Collection Approach",
        "level": 2
      },
      {
        "id": "1-ownership-rules",
        "text": "1. Ownership Rules",
        "level": 2
      },
      {
        "id": "2-borrowing-and-references",
        "text": "2. Borrowing & References",
        "level": 2
      },
      {
        "id": "3-lifetimes",
        "text": "3. Lifetimes",
        "level": 2
      },
      {
        "id": "why-no-garbage-collector-gc",
        "text": "Why No Garbage Collector (GC)?",
        "level": 2
      },
      {
        "id": "key-takeaways",
        "text": "Key Takeaways",
        "level": 2
      }
    ]
  },
  {
    "id": "cow-copy-on-write-rust",
    "slug": "cow-copy-on-write-rust",
    "title": "How does Cow<'a, B> (Copy-on-Write) work in Rust? When use it ?",
    "date": "2025-07-30",
    "excerpt": "Rust memory and string",
    "content": "`Cow<'a, B>` (Copy-on-Write) is a smart pointer in Rust’s `std::borrow` module that provides a clone-free abstraction over borrowed and owned data. It enables efficient handling of data that may or may not need modification, minimizing allocations while maintaining flexibility.\n\n## What is Cow?\n\n`Cow` (short for Copy-on-Write) can represent:\n- **Borrowed data** (`&'a B`): A reference to existing data, avoiding allocations.\n- **Owned data** (`<B as ToOwned>::Owned`): A fully owned copy, allocated only when mutation is required.\n\n**Definition** (from `std::borrow`):\n```rust\npub enum Cow<'a, B>\nwhere\n    B: 'a + ToOwned + ?Sized,\n{\n    Borrowed(&'a B),  // Immutable reference (no allocation)\n    Owned(<B as ToOwned>::Owned),  // Owned data (allocated when needed)\n}\n```\n\n**How It Works**:\n- Initially wraps a reference (`Borrowed`), which is zero-cost.\n- Converts to owned data (`Owned`) lazily, only when modification is needed.\n\n## Example with Cow<str> (Strings)\n\n```rust\nuse std::borrow::Cow;\n\nfn process(input: &str) -> Cow<str> {\n    if input.contains(\"error\") {\n        Cow::Owned(input.replace(\"error\", \"\"))  // Allocates new String\n    } else {\n        Cow::Borrowed(input)  // No allocation\n    }\n}\n\nfn main() {\n    let msg1 = \"hello world\";  // No allocation\n    let msg2 = \"error: foo\";   // Will allocate when processed\n\n    println!(\"{}\", process(msg1)); // \"hello world\" (borrowed)\n    println!(\"{}\", process(msg2)); // \": foo\" (owned)\n}\n```\n\n## Key Use Cases\n\n### 1. Optimizing String Operations\nAvoid allocations when modifying strings conditionally:\n\n```rust\nfn to_uppercase(input: &str) -> Cow<str> {\n    if input.chars().any(|c| c.is_lowercase()) {\n        Cow::Owned(input.to_uppercase())  // Allocates only if needed\n    } else {\n        Cow::Borrowed(input)\n    }\n}\n```\n\n**Extended Example** (checking for digits):\n```rust\nfn to_uppercase_no_digits(input: &str) -> Cow<str> {\n    if input.chars().any(|c| c.is_lowercase() || c.is_digit(10)) {\n        Cow::Owned(input.to_uppercase().replace(|c: char| c.is_digit(10), \"\"))\n    } else {\n        Cow::Borrowed(input)\n    }\n}\n```\n\n`Cow` ensures no allocation if the input is already uppercase and digit-free, optimizing read-only paths.\n\n### 2. API Flexibility\nAccept both borrowed and owned data without forcing clones:\n\n```rust\nfn print(data: Cow<str>) {\n    println!(\"{}\", data);\n}\n\nfn main() {\n    let my_string = String::from(\"world\");\n    print(Cow::Borrowed(\"hello\"));  // No allocation\n    print(Cow::Owned(my_string));   // Works too\n}\n```\n\nThis supports `&str`, `String`, or other types implementing `ToOwned`.\n\n### 3. Zero-Copy Parsing\nCommon in parsers (e.g., `serde`), where fields are often unmodified:\n\n```rust\nstruct JsonValue<'a> {\n    data: Cow<'a, str>,  // Borrows from input unless modified\n}\n```\n\n## When to Avoid Cow\n\n- **Always-mutated data**: Use `String` or `Vec` directly to avoid `Cow` overhead.\n- **Thread-safety**: `Cow` is not thread-safe; use `Arc` + `Mutex` for concurrent access.\n\n## Performance Implications\n\n| **Scenario** | **Behavior** | **Allocation Cost** |\n|--------------|--------------|---------------------|\n| No modification | Stays as `Borrowed` | Zero |\n| Modification | Converts to `Owned` | One allocation |\n\n## Key Takeaways\n\n✅ **Use `Cow` when**:\n- You need to conditionally modify borrowed data.\n- You want to avoid allocations for read-only paths.\n- Your API should accept both `&str` and `String` efficiently.\n\n🚀 **Real-world uses**:\n- `regex::Match` (borrows input strings).\n- `serde` deserialization.\n- Path manipulation (`PathBuf` vs. `&Path`).\n\n**Note**: `Cow` works with any `ToOwned` type (e.g., `[u8]` → `Vec<u8]`, `Path` → `PathBuf`).\n\n**Experiment**: Modifying the `to_uppercase` example to handle digits (as shown above) demonstrates how `Cow` avoids allocations unless both lowercase letters *and* digits are present, optimizing performance.",
    "contentHtml": "<p><code>Cow&lt;&#39;a, B&gt;</code> (Copy-on-Write) is a smart pointer in Rust’s <code>std::borrow</code> module that provides a clone-free abstraction over borrowed and owned data. It enables efficient handling of data that may or may not need modification, minimizing allocations while maintaining flexibility.</p>\n<h2>What is Cow?</h2>\n<p><code>Cow</code> (short for Copy-on-Write) can represent:</p>\n<ul>\n<li><strong>Borrowed data</strong> (<code>&amp;&#39;a B</code>): A reference to existing data, avoiding allocations.</li>\n<li><strong>Owned data</strong> (<code>&lt;B as ToOwned&gt;::Owned</code>): A fully owned copy, allocated only when mutation is required.</li>\n</ul>\n<p><strong>Definition</strong> (from <code>std::borrow</code>):</p>\n<pre><code class=\"language-rust\">pub enum Cow&lt;&#39;a, B&gt;\nwhere\n    B: &#39;a + ToOwned + ?Sized,\n{\n    Borrowed(&amp;&#39;a B),  // Immutable reference (no allocation)\n    Owned(&lt;B as ToOwned&gt;::Owned),  // Owned data (allocated when needed)\n}\n</code></pre>\n<p><strong>How It Works</strong>:</p>\n<ul>\n<li>Initially wraps a reference (<code>Borrowed</code>), which is zero-cost.</li>\n<li>Converts to owned data (<code>Owned</code>) lazily, only when modification is needed.</li>\n</ul>\n<h2>Example with Cow<str> (Strings)</h2>\n<pre><code class=\"language-rust\">use std::borrow::Cow;\n\nfn process(input: &amp;str) -&gt; Cow&lt;str&gt; {\n    if input.contains(&quot;error&quot;) {\n        Cow::Owned(input.replace(&quot;error&quot;, &quot;&quot;))  // Allocates new String\n    } else {\n        Cow::Borrowed(input)  // No allocation\n    }\n}\n\nfn main() {\n    let msg1 = &quot;hello world&quot;;  // No allocation\n    let msg2 = &quot;error: foo&quot;;   // Will allocate when processed\n\n    println!(&quot;{}&quot;, process(msg1)); // &quot;hello world&quot; (borrowed)\n    println!(&quot;{}&quot;, process(msg2)); // &quot;: foo&quot; (owned)\n}\n</code></pre>\n<h2>Key Use Cases</h2>\n<h3>1. Optimizing String Operations</h3>\n<p>Avoid allocations when modifying strings conditionally:</p>\n<pre><code class=\"language-rust\">fn to_uppercase(input: &amp;str) -&gt; Cow&lt;str&gt; {\n    if input.chars().any(|c| c.is_lowercase()) {\n        Cow::Owned(input.to_uppercase())  // Allocates only if needed\n    } else {\n        Cow::Borrowed(input)\n    }\n}\n</code></pre>\n<p><strong>Extended Example</strong> (checking for digits):</p>\n<pre><code class=\"language-rust\">fn to_uppercase_no_digits(input: &amp;str) -&gt; Cow&lt;str&gt; {\n    if input.chars().any(|c| c.is_lowercase() || c.is_digit(10)) {\n        Cow::Owned(input.to_uppercase().replace(|c: char| c.is_digit(10), &quot;&quot;))\n    } else {\n        Cow::Borrowed(input)\n    }\n}\n</code></pre>\n<p><code>Cow</code> ensures no allocation if the input is already uppercase and digit-free, optimizing read-only paths.</p>\n<h3>2. API Flexibility</h3>\n<p>Accept both borrowed and owned data without forcing clones:</p>\n<pre><code class=\"language-rust\">fn print(data: Cow&lt;str&gt;) {\n    println!(&quot;{}&quot;, data);\n}\n\nfn main() {\n    let my_string = String::from(&quot;world&quot;);\n    print(Cow::Borrowed(&quot;hello&quot;));  // No allocation\n    print(Cow::Owned(my_string));   // Works too\n}\n</code></pre>\n<p>This supports <code>&amp;str</code>, <code>String</code>, or other types implementing <code>ToOwned</code>.</p>\n<h3>3. Zero-Copy Parsing</h3>\n<p>Common in parsers (e.g., <code>serde</code>), where fields are often unmodified:</p>\n<pre><code class=\"language-rust\">struct JsonValue&lt;&#39;a&gt; {\n    data: Cow&lt;&#39;a, str&gt;,  // Borrows from input unless modified\n}\n</code></pre>\n<h2>When to Avoid Cow</h2>\n<ul>\n<li><strong>Always-mutated data</strong>: Use <code>String</code> or <code>Vec</code> directly to avoid <code>Cow</code> overhead.</li>\n<li><strong>Thread-safety</strong>: <code>Cow</code> is not thread-safe; use <code>Arc</code> + <code>Mutex</code> for concurrent access.</li>\n</ul>\n<h2>Performance Implications</h2>\n<table>\n<thead>\n<tr>\n<th><strong>Scenario</strong></th>\n<th><strong>Behavior</strong></th>\n<th><strong>Allocation Cost</strong></th>\n</tr>\n</thead>\n<tbody><tr>\n<td>No modification</td>\n<td>Stays as <code>Borrowed</code></td>\n<td>Zero</td>\n</tr>\n<tr>\n<td>Modification</td>\n<td>Converts to <code>Owned</code></td>\n<td>One allocation</td>\n</tr>\n</tbody></table>\n<h2>Key Takeaways</h2>\n<p>✅ <strong>Use <code>Cow</code> when</strong>:</p>\n<ul>\n<li>You need to conditionally modify borrowed data.</li>\n<li>You want to avoid allocations for read-only paths.</li>\n<li>Your API should accept both <code>&amp;str</code> and <code>String</code> efficiently.</li>\n</ul>\n<p>🚀 <strong>Real-world uses</strong>:</p>\n<ul>\n<li><code>regex::Match</code> (borrows input strings).</li>\n<li><code>serde</code> deserialization.</li>\n<li>Path manipulation (<code>PathBuf</code> vs. <code>&amp;Path</code>).</li>\n</ul>\n<p><strong>Note</strong>: <code>Cow</code> works with any <code>ToOwned</code> type (e.g., <code>[u8]</code> → <code>Vec&lt;u8]</code>, <code>Path</code> → <code>PathBuf</code>).</p>\n<p><strong>Experiment</strong>: Modifying the <code>to_uppercase</code> example to handle digits (as shown above) demonstrates how <code>Cow</code> avoids allocations unless both lowercase letters <em>and</em> digits are present, optimizing performance.</p>\n",
    "author": "mayo",
    "category": "rust",
    "tags": [
      "rust",
      "string"
    ],
    "readingTime": "3 min",
    "locale": "en",
    "seo": {
      "title": "How does Cow<'a, B> (Copy-on-Write) work in Rust? When use it ?",
      "description": "Rust memory and string",
      "keywords": [
        "rust",
        "string"
      ]
    },
    "headings": [
      {
        "id": "what-is-cow",
        "text": "What is Cow?",
        "level": 2
      },
      {
        "id": "example-with-cowlessstrgreater-strings",
        "text": "Example with Cow<str> (Strings)",
        "level": 2
      },
      {
        "id": "key-use-cases",
        "text": "Key Use Cases",
        "level": 2
      },
      {
        "id": "1-optimizing-string-operations",
        "text": "1. Optimizing String Operations",
        "level": 3
      },
      {
        "id": "2-api-flexibility",
        "text": "2. API Flexibility",
        "level": 3
      },
      {
        "id": "3-zero-copy-parsing",
        "text": "3. Zero-Copy Parsing",
        "level": 3
      },
      {
        "id": "when-to-avoid-cow",
        "text": "When to Avoid Cow",
        "level": 2
      },
      {
        "id": "performance-implications",
        "text": "Performance Implications",
        "level": 2
      },
      {
        "id": "key-takeaways",
        "text": "Key Takeaways",
        "level": 2
      }
    ]
  },
  {
    "id": "drop-trait-rust",
    "slug": "drop-trait-rust",
    "title": "Understanding the Drop Trait in Rust",
    "date": "2025-07-30",
    "excerpt": "Rust memory and string",
    "content": "The `Drop` trait in Rust enables custom cleanup logic when a value goes out of scope, providing deterministic resource management similar to C++’s RAII (Resource Acquisition Is Initialization). It ensures memory safety and proper resource deallocation without a garbage collector.\n\n## What is the Drop Trait?\n\nThe `Drop` trait defines a single method, `drop`, which is automatically called when a value is destroyed:\n\n```rust\ntrait Drop {\n    fn drop(&mut self);  // Called automatically when the value is destroyed\n}\n```\n\n## How It Works\n\n- **Automatic Invocation**: Rust calls `drop` when:\n  - A variable goes out of scope.\n  - Ownership is transferred (e.g., moved into a function).\n  - Explicitly dropped via `std::mem::drop`.\n- **LIFO Order**: Values are dropped in the reverse order of their declaration (stack-like behavior).\n\n**Example: Basic Drop**:\n```rust\nstruct Resource {\n    id: u32,\n}\n\nimpl Drop for Resource {\n    fn drop(&mut self) {\n        println!(\"Dropping resource {}\", self.id);\n    }\n}\n\nfn main() {\n    let _res1 = Resource { id: 1 };  // Dropped second\n    let _res2 = Resource { id: 2 };  // Dropped first\n}\n```\n\n**Output**:\n```\nDropping resource 2\nDropping resource 1\n```\n\n## When to Implement Drop Manually\n\n### 1. Resource Cleanup\nFor managing non-memory resources like files, sockets, or locks:\n\n```rust\nstruct DatabaseConnection {\n    // Connection details\n}\n\nimpl Drop for DatabaseConnection {\n    fn drop(&mut self) {\n        self.close();  // Ensure connection is released\n    }\n}\n```\n\n### 2. Custom Memory Management\nFor integrating with FFI or unsafe code:\n\n```rust\nstruct RawBuffer {\n    ptr: *mut u8,\n}\n\nimpl Drop for RawBuffer {\n    fn drop(&mut self) {\n        unsafe { libc::free(self.ptr as *mut _); }  // Manually free heap memory\n    }\n}\n```\n\n### 3. Logging/Telemetry\nTo track object lifecycle:\n\n```rust\nstruct MetricsTracker {\n    start: std::time::Instant,\n}\n\nimpl Drop for MetricsTracker {\n    fn drop(&mut self) {\n        log::info!(\"Tracker dropped after {}ms\", self.start.elapsed().as_millis());\n    }\n}\n```\n\n## Key Rules\n\n- **No Explicit Calls**: Rarely call `drop` directly; use `std::mem::drop` to explicitly drop a value.\n- **No Panics**: Avoid panicking in `drop`, as it can lead to double-drops or program aborts.\n- **Auto Traits**: Types implementing `Drop` cannot be `Copy`.\n\n## Drop vs. Copy/Clone\n\n| **Trait** | **Purpose** | **Mutually Exclusive?** |\n|-----------|-------------|-------------------------|\n| `Drop`    | Cleanup logic | Yes (cannot be `Copy`) |\n| `Copy`    | Bitwise copy | Yes |\n| `Clone`   | Explicit deep copy | No |\n\n## Advanced: #[may_dangle] (Nightly)\nFor generic types where `T` might not need dropping (unsafe):\n\n```rust\nunsafe impl<#[may_dangle] T> Drop for MyBox<T> {\n    fn drop(&mut self) { /* ... */ }\n}\n```\n\n## When Not to Use Drop\n\n- **Simple Data**: No need for `Drop` if cleanup is handled by other types (e.g., `Box`, `Vec`).\n- **Thread-Safety**: Use `Arc` + `Mutex` instead of manual locking in `drop`.\n\n## Key Takeaways\n\n✅ **Use `Drop` for**:\n- Resource cleanup (files, locks, memory).\n- FFI/safety-critical guarantees.\n- Debugging/profiling.\n\n🚫 **Avoid**:\n- Reimplementing logic provided by Rust (e.g., `Box`’s deallocation).\n- Complex operations that could panic.\n\n**Real-World Example**: The `MutexGuard` type uses `Drop` to release locks automatically:\n\n```rust\n{\n    let guard = mutex.lock();  // Lock acquired\n    // ...\n}  // `guard` dropped here → lock released\n```\n\n**Experiment**: What happens if you call `mem::forget` on a type with `Drop`?  \n**Answer**: The destructor won’t run, potentially causing a resource leak (e.g., unclosed files or unfreed memory).",
    "contentHtml": "<p>The <code>Drop</code> trait in Rust enables custom cleanup logic when a value goes out of scope, providing deterministic resource management similar to C++’s RAII (Resource Acquisition Is Initialization). It ensures memory safety and proper resource deallocation without a garbage collector.</p>\n<h2>What is the Drop Trait?</h2>\n<p>The <code>Drop</code> trait defines a single method, <code>drop</code>, which is automatically called when a value is destroyed:</p>\n<pre><code class=\"language-rust\">trait Drop {\n    fn drop(&amp;mut self);  // Called automatically when the value is destroyed\n}\n</code></pre>\n<h2>How It Works</h2>\n<ul>\n<li><strong>Automatic Invocation</strong>: Rust calls <code>drop</code> when:<ul>\n<li>A variable goes out of scope.</li>\n<li>Ownership is transferred (e.g., moved into a function).</li>\n<li>Explicitly dropped via <code>std::mem::drop</code>.</li>\n</ul>\n</li>\n<li><strong>LIFO Order</strong>: Values are dropped in the reverse order of their declaration (stack-like behavior).</li>\n</ul>\n<p><strong>Example: Basic Drop</strong>:</p>\n<pre><code class=\"language-rust\">struct Resource {\n    id: u32,\n}\n\nimpl Drop for Resource {\n    fn drop(&amp;mut self) {\n        println!(&quot;Dropping resource {}&quot;, self.id);\n    }\n}\n\nfn main() {\n    let _res1 = Resource { id: 1 };  // Dropped second\n    let _res2 = Resource { id: 2 };  // Dropped first\n}\n</code></pre>\n<p><strong>Output</strong>:</p>\n<pre><code>Dropping resource 2\nDropping resource 1\n</code></pre>\n<h2>When to Implement Drop Manually</h2>\n<h3>1. Resource Cleanup</h3>\n<p>For managing non-memory resources like files, sockets, or locks:</p>\n<pre><code class=\"language-rust\">struct DatabaseConnection {\n    // Connection details\n}\n\nimpl Drop for DatabaseConnection {\n    fn drop(&amp;mut self) {\n        self.close();  // Ensure connection is released\n    }\n}\n</code></pre>\n<h3>2. Custom Memory Management</h3>\n<p>For integrating with FFI or unsafe code:</p>\n<pre><code class=\"language-rust\">struct RawBuffer {\n    ptr: *mut u8,\n}\n\nimpl Drop for RawBuffer {\n    fn drop(&amp;mut self) {\n        unsafe { libc::free(self.ptr as *mut _); }  // Manually free heap memory\n    }\n}\n</code></pre>\n<h3>3. Logging/Telemetry</h3>\n<p>To track object lifecycle:</p>\n<pre><code class=\"language-rust\">struct MetricsTracker {\n    start: std::time::Instant,\n}\n\nimpl Drop for MetricsTracker {\n    fn drop(&amp;mut self) {\n        log::info!(&quot;Tracker dropped after {}ms&quot;, self.start.elapsed().as_millis());\n    }\n}\n</code></pre>\n<h2>Key Rules</h2>\n<ul>\n<li><strong>No Explicit Calls</strong>: Rarely call <code>drop</code> directly; use <code>std::mem::drop</code> to explicitly drop a value.</li>\n<li><strong>No Panics</strong>: Avoid panicking in <code>drop</code>, as it can lead to double-drops or program aborts.</li>\n<li><strong>Auto Traits</strong>: Types implementing <code>Drop</code> cannot be <code>Copy</code>.</li>\n</ul>\n<h2>Drop vs. Copy/Clone</h2>\n<table>\n<thead>\n<tr>\n<th><strong>Trait</strong></th>\n<th><strong>Purpose</strong></th>\n<th><strong>Mutually Exclusive?</strong></th>\n</tr>\n</thead>\n<tbody><tr>\n<td><code>Drop</code></td>\n<td>Cleanup logic</td>\n<td>Yes (cannot be <code>Copy</code>)</td>\n</tr>\n<tr>\n<td><code>Copy</code></td>\n<td>Bitwise copy</td>\n<td>Yes</td>\n</tr>\n<tr>\n<td><code>Clone</code></td>\n<td>Explicit deep copy</td>\n<td>No</td>\n</tr>\n</tbody></table>\n<h2>Advanced: #[may_dangle] (Nightly)</h2>\n<p>For generic types where <code>T</code> might not need dropping (unsafe):</p>\n<pre><code class=\"language-rust\">unsafe impl&lt;#[may_dangle] T&gt; Drop for MyBox&lt;T&gt; {\n    fn drop(&amp;mut self) { /* ... */ }\n}\n</code></pre>\n<h2>When Not to Use Drop</h2>\n<ul>\n<li><strong>Simple Data</strong>: No need for <code>Drop</code> if cleanup is handled by other types (e.g., <code>Box</code>, <code>Vec</code>).</li>\n<li><strong>Thread-Safety</strong>: Use <code>Arc</code> + <code>Mutex</code> instead of manual locking in <code>drop</code>.</li>\n</ul>\n<h2>Key Takeaways</h2>\n<p>✅ <strong>Use <code>Drop</code> for</strong>:</p>\n<ul>\n<li>Resource cleanup (files, locks, memory).</li>\n<li>FFI/safety-critical guarantees.</li>\n<li>Debugging/profiling.</li>\n</ul>\n<p>🚫 <strong>Avoid</strong>:</p>\n<ul>\n<li>Reimplementing logic provided by Rust (e.g., <code>Box</code>’s deallocation).</li>\n<li>Complex operations that could panic.</li>\n</ul>\n<p><strong>Real-World Example</strong>: The <code>MutexGuard</code> type uses <code>Drop</code> to release locks automatically:</p>\n<pre><code class=\"language-rust\">{\n    let guard = mutex.lock();  // Lock acquired\n    // ...\n}  // `guard` dropped here → lock released\n</code></pre>\n<p><strong>Experiment</strong>: What happens if you call <code>mem::forget</code> on a type with <code>Drop</code>?<br><strong>Answer</strong>: The destructor won’t run, potentially causing a resource leak (e.g., unclosed files or unfreed memory).</p>\n",
    "author": "mayo",
    "category": "rust",
    "tags": [
      "rust",
      "drop"
    ],
    "readingTime": "3 min",
    "locale": "en",
    "seo": {
      "title": "Understanding the Drop Trait in Rust",
      "description": "Rust memory and string",
      "keywords": [
        "rust",
        "drop"
      ]
    },
    "headings": [
      {
        "id": "what-is-the-drop-trait",
        "text": "What is the Drop Trait?",
        "level": 2
      },
      {
        "id": "how-it-works",
        "text": "How It Works",
        "level": 2
      },
      {
        "id": "when-to-implement-drop-manually",
        "text": "When to Implement Drop Manually",
        "level": 2
      },
      {
        "id": "1-resource-cleanup",
        "text": "1. Resource Cleanup",
        "level": 3
      },
      {
        "id": "2-custom-memory-management",
        "text": "2. Custom Memory Management",
        "level": 3
      },
      {
        "id": "3-loggingtelemetry",
        "text": "3. Logging/Telemetry",
        "level": 3
      },
      {
        "id": "key-rules",
        "text": "Key Rules",
        "level": 2
      },
      {
        "id": "drop-vs-copyclone",
        "text": "Drop vs. Copy/Clone",
        "level": 2
      },
      {
        "id": "advanced-maydangle-nightly",
        "text": "Advanced: #[may_dangle] (Nightly)",
        "level": 2
      },
      {
        "id": "when-not-to-use-drop",
        "text": "When Not to Use Drop",
        "level": 2
      },
      {
        "id": "key-takeaways",
        "text": "Key Takeaways",
        "level": 2
      }
    ]
  },
  {
    "id": "concurrency-rust",
    "slug": "concurrency-rust",
    "title": "How Rust's Ownership and Borrowing Ensure Safe Concurrency",
    "date": "2025-07-30",
    "excerpt": "Rust memory and string",
    "content": "Rust’s concurrency model leverages its ownership and borrowing rules to guarantee thread safety at compile time, eliminating data races without requiring a garbage collector. This approach ensures safe, high-performance parallelism with minimal runtime overhead.\n\n## Rust’s Concurrency Model\n\nRust uses the following mechanisms to manage concurrency:\n- **Ownership**: Ensures exclusive mutable access to data.\n- **Borrowing**: Governs how data is accessed via references.\n- **Lifetimes**: Prevent dangling references across threads.\n- **Send/Sync Traits**: Define which types are safe for threading.\n\n## How Ownership and Borrowing Prevent Data Races\n\nA **data race** occurs when:\n- Two threads access the same data concurrently.\n- At least one access is a write.\n- There’s no synchronization.\n\nRust’s rules make data races impossible in safe code:\n\n### 1. Exclusive Mutability (`&mut T`)\n- Only one mutable reference (`&mut T`) can exist at a time, enforced by the borrow checker.\n- This prevents multiple threads from writing to the same data simultaneously.\n\n**Example**:\n```rust\nlet mut data = 0;\nlet r1 = &mut data;  // OK: Mutable borrow\n// let r2 = &mut data;  // ERROR: Cannot borrow `data` as mutable more than once\n```\n\n### 2. No Shared Mutability Without Synchronization\n- Shared references (`&T`) are read-only, safe for concurrent access.\n- To mutate shared data, synchronization primitives like `Mutex` are required:\n\n**Example**:\n```rust\nuse std::sync::Mutex;\n\nlet shared = Mutex::new(42);\nlet guard = shared.lock().unwrap();  // Exclusive access\n*guard += 1;  // Safe mutation\n```\n\n## Thread-Safe Types: Send and Sync\n\n- **Send**: A type can be safely transferred across threads (e.g., `String`, `Mutex<T>`).\n- **Sync**: A type can be safely shared between threads via references (e.g., `&i32`, `Arc<T>`).\n\n**Example: Spawning Threads**:\n```rust\nuse std::thread;\n\nlet value = String::from(\"hello\");  // `String` is `Send`\nthread::spawn(move || {             // `move` transfers ownership\n    println!(\"{}\", value);          // Safe: no other thread can access `value`\n}).join().unwrap();\n```\n\n## Common Concurrency Tools\n\n| **Tool** | **Purpose** | **Thread Safety Mechanism** |\n|----------|-------------|-----------------------------|\n| `Mutex<T>` | Mutual exclusion | Locks for exclusive access |\n| `Arc<T>` | Atomic reference counting | Shared ownership across threads |\n| `RwLock<T>` | Read-write lock | Multiple readers or one writer |\n| `mpsc channels` | Message passing | Transfers ownership between threads |\n\n**Example: Shared State with Arc + Mutex**:\n```rust\nuse std::sync::{Arc, Mutex};\nuse std::thread;\n\nlet counter = Arc::new(Mutex::new(0));\nlet mut handles = vec![];\n\nfor _ in 0..10 {\n    let counter = Arc::clone(&counter);\n    handles.push(thread::spawn(move || {\n        let mut num = counter.lock().unwrap();\n        *num += 1;  // Mutex ensures exclusive access\n    }));\n}\n\nfor handle in handles {\n    handle.join().unwrap();\n}\nprintln!(\"Result: {}\", *counter.lock().unwrap());  // Outputs 10\n```\n\n## Why This Matters\n\n- **No runtime overhead**: Safety checks occur at compile time.\n- **No garbage collector**: Safe concurrency without GC pauses.\n- **Fearless parallelism**: The compiler rejects unsafe patterns, enabling confident concurrent programming.\n\n## Key Takeaways\n\n✅ **Ownership rules prevent**:\n- Concurrent mutable access (no data races).\n- Dangling references (via lifetimes).\n\n✅ **Send/Sync enforce** thread safety at compile time.\n\n🚀 **Use `Mutex`, `Arc`, or channels** for safe shared state.\n\n**Real-World Impact**: Crates like `rayon` (parallel iterators) and `tokio` (async runtime) rely on these guarantees for robust concurrency.\n\n**Experiment**: What happens if you try to share an `Rc<T>` across threads?  \n**Answer**: Compile error! `Rc<T>` is not `Send` (not thread-safe). Use `Arc<T>` instead.",
    "contentHtml": "<p>Rust’s concurrency model leverages its ownership and borrowing rules to guarantee thread safety at compile time, eliminating data races without requiring a garbage collector. This approach ensures safe, high-performance parallelism with minimal runtime overhead.</p>\n<h2>Rust’s Concurrency Model</h2>\n<p>Rust uses the following mechanisms to manage concurrency:</p>\n<ul>\n<li><strong>Ownership</strong>: Ensures exclusive mutable access to data.</li>\n<li><strong>Borrowing</strong>: Governs how data is accessed via references.</li>\n<li><strong>Lifetimes</strong>: Prevent dangling references across threads.</li>\n<li><strong>Send/Sync Traits</strong>: Define which types are safe for threading.</li>\n</ul>\n<h2>How Ownership and Borrowing Prevent Data Races</h2>\n<p>A <strong>data race</strong> occurs when:</p>\n<ul>\n<li>Two threads access the same data concurrently.</li>\n<li>At least one access is a write.</li>\n<li>There’s no synchronization.</li>\n</ul>\n<p>Rust’s rules make data races impossible in safe code:</p>\n<h3>1. Exclusive Mutability (<code>&amp;mut T</code>)</h3>\n<ul>\n<li>Only one mutable reference (<code>&amp;mut T</code>) can exist at a time, enforced by the borrow checker.</li>\n<li>This prevents multiple threads from writing to the same data simultaneously.</li>\n</ul>\n<p><strong>Example</strong>:</p>\n<pre><code class=\"language-rust\">let mut data = 0;\nlet r1 = &amp;mut data;  // OK: Mutable borrow\n// let r2 = &amp;mut data;  // ERROR: Cannot borrow `data` as mutable more than once\n</code></pre>\n<h3>2. No Shared Mutability Without Synchronization</h3>\n<ul>\n<li>Shared references (<code>&amp;T</code>) are read-only, safe for concurrent access.</li>\n<li>To mutate shared data, synchronization primitives like <code>Mutex</code> are required:</li>\n</ul>\n<p><strong>Example</strong>:</p>\n<pre><code class=\"language-rust\">use std::sync::Mutex;\n\nlet shared = Mutex::new(42);\nlet guard = shared.lock().unwrap();  // Exclusive access\n*guard += 1;  // Safe mutation\n</code></pre>\n<h2>Thread-Safe Types: Send and Sync</h2>\n<ul>\n<li><strong>Send</strong>: A type can be safely transferred across threads (e.g., <code>String</code>, <code>Mutex&lt;T&gt;</code>).</li>\n<li><strong>Sync</strong>: A type can be safely shared between threads via references (e.g., <code>&amp;i32</code>, <code>Arc&lt;T&gt;</code>).</li>\n</ul>\n<p><strong>Example: Spawning Threads</strong>:</p>\n<pre><code class=\"language-rust\">use std::thread;\n\nlet value = String::from(&quot;hello&quot;);  // `String` is `Send`\nthread::spawn(move || {             // `move` transfers ownership\n    println!(&quot;{}&quot;, value);          // Safe: no other thread can access `value`\n}).join().unwrap();\n</code></pre>\n<h2>Common Concurrency Tools</h2>\n<table>\n<thead>\n<tr>\n<th><strong>Tool</strong></th>\n<th><strong>Purpose</strong></th>\n<th><strong>Thread Safety Mechanism</strong></th>\n</tr>\n</thead>\n<tbody><tr>\n<td><code>Mutex&lt;T&gt;</code></td>\n<td>Mutual exclusion</td>\n<td>Locks for exclusive access</td>\n</tr>\n<tr>\n<td><code>Arc&lt;T&gt;</code></td>\n<td>Atomic reference counting</td>\n<td>Shared ownership across threads</td>\n</tr>\n<tr>\n<td><code>RwLock&lt;T&gt;</code></td>\n<td>Read-write lock</td>\n<td>Multiple readers or one writer</td>\n</tr>\n<tr>\n<td><code>mpsc channels</code></td>\n<td>Message passing</td>\n<td>Transfers ownership between threads</td>\n</tr>\n</tbody></table>\n<p><strong>Example: Shared State with Arc + Mutex</strong>:</p>\n<pre><code class=\"language-rust\">use std::sync::{Arc, Mutex};\nuse std::thread;\n\nlet counter = Arc::new(Mutex::new(0));\nlet mut handles = vec![];\n\nfor _ in 0..10 {\n    let counter = Arc::clone(&amp;counter);\n    handles.push(thread::spawn(move || {\n        let mut num = counter.lock().unwrap();\n        *num += 1;  // Mutex ensures exclusive access\n    }));\n}\n\nfor handle in handles {\n    handle.join().unwrap();\n}\nprintln!(&quot;Result: {}&quot;, *counter.lock().unwrap());  // Outputs 10\n</code></pre>\n<h2>Why This Matters</h2>\n<ul>\n<li><strong>No runtime overhead</strong>: Safety checks occur at compile time.</li>\n<li><strong>No garbage collector</strong>: Safe concurrency without GC pauses.</li>\n<li><strong>Fearless parallelism</strong>: The compiler rejects unsafe patterns, enabling confident concurrent programming.</li>\n</ul>\n<h2>Key Takeaways</h2>\n<p>✅ <strong>Ownership rules prevent</strong>:</p>\n<ul>\n<li>Concurrent mutable access (no data races).</li>\n<li>Dangling references (via lifetimes).</li>\n</ul>\n<p>✅ <strong>Send/Sync enforce</strong> thread safety at compile time.</p>\n<p>🚀 <strong>Use <code>Mutex</code>, <code>Arc</code>, or channels</strong> for safe shared state.</p>\n<p><strong>Real-World Impact</strong>: Crates like <code>rayon</code> (parallel iterators) and <code>tokio</code> (async runtime) rely on these guarantees for robust concurrency.</p>\n<p><strong>Experiment</strong>: What happens if you try to share an <code>Rc&lt;T&gt;</code> across threads?<br><strong>Answer</strong>: Compile error! <code>Rc&lt;T&gt;</code> is not <code>Send</code> (not thread-safe). Use <code>Arc&lt;T&gt;</code> instead.</p>\n",
    "author": "mayo",
    "category": "rust",
    "tags": [
      "rust",
      "concurrency"
    ],
    "readingTime": "3 min",
    "locale": "en",
    "seo": {
      "title": "How Rust's Ownership and Borrowing Ensure Safe Concurrency",
      "description": "Rust memory and string",
      "keywords": [
        "rust",
        "concurrency"
      ]
    },
    "headings": [
      {
        "id": "rusts-concurrency-model",
        "text": "Rust’s Concurrency Model",
        "level": 2
      },
      {
        "id": "how-ownership-and-borrowing-prevent-data-races",
        "text": "How Ownership and Borrowing Prevent Data Races",
        "level": 2
      },
      {
        "id": "1-exclusive-mutability-andmut-t",
        "text": "1. Exclusive Mutability (`&mut T`)",
        "level": 3
      },
      {
        "id": "2-no-shared-mutability-without-synchronization",
        "text": "2. No Shared Mutability Without Synchronization",
        "level": 3
      },
      {
        "id": "thread-safe-types-send-and-sync",
        "text": "Thread-Safe Types: Send and Sync",
        "level": 2
      },
      {
        "id": "common-concurrency-tools",
        "text": "Common Concurrency Tools",
        "level": 2
      },
      {
        "id": "why-this-matters",
        "text": "Why This Matters",
        "level": 2
      },
      {
        "id": "key-takeaways",
        "text": "Key Takeaways",
        "level": 2
      }
    ]
  },
  {
    "id": "flatten-vec-iterators-performance",
    "slug": "flatten-vec-iterators-performance",
    "title": "Flatten a Vec<Vec<T>> into a Vec<T> using iterators",
    "date": "2025-07-29",
    "excerpt": "Flattening Vec<Vec<T>> using iterators compared to manual concatenation, analyzing performance implications and optimization strategies",
    "content": "## Flattening with Iterators\n\nThe most idiomatic way is to use `.flatten()` or `.flat_map()`:\n\n```rust\nlet nested = vec![vec![1, 2], vec![3], vec![4, 5, 6]];\n\n// Method 1: flatten() (for Vec<Iterables>)\nlet flat: Vec<_> = nested.iter().flatten().copied().collect();\n\n// Method 2: flat_map() (for custom transformations)\nlet flat: Vec<_> = nested.into_iter().flat_map(|v| v).collect();\n```\n\n**Output**: `[1, 2, 3, 4, 5, 6]`\n\n## Manual Concatenation\n\nFor comparison, here's how you might do it manually:\n\n```rust\nlet mut flat = Vec::new();\nfor subvec in nested {\n    flat.extend(subvec);  // or append() if subvec is no longer needed\n}\n```\n\n## Performance Comparison\n\n| Method | Time Complexity | Space Complexity | Allocations | Optimizations |\n|--------|-----------------|------------------|-------------|---------------|\n| Iterator (flatten) | O(n) | O(1) iterator | 1 (result) | May fuse iterators |\n| Manual (extend) | O(n) | O(1) temp space | 1 (result) | Pre-allocation possible |\n\n## Key Insights\n\n### Pre-allocation Advantage (Manual)\n\nYou can pre-allocate the target Vec if total size is known:\n\n```rust\nlet total_len: usize = nested.iter().map(|v| v.len()).sum();\nlet mut flat = Vec::with_capacity(total_len);  // Critical for large datasets\nflat.extend(nested.into_iter().flatten());\n```\n\n### Iterator Laziness\n\n- `.flatten()` is lazy, but `.collect()` still needs to allocate the result.\n- Chained iterators (e.g., `.filter().flatten()`) may optimize better than manual loops.\n\n## Benchmark Example\n\n```rust\nlet nested: Vec<Vec<i32>> = (0..1_000).map(|i| vec![i; 100]).collect();\n\n// Iterator approach\nlet start = std::time::Instant::now();\nlet flat = nested.iter().flatten().copied().collect::<Vec<_>>();\nprintln!(\"flatten: {:?}\", start.elapsed());\n\n// Manual approach with pre-allocation\nlet start = std::time::Instant::now();\nlet total_len = nested.iter().map(|v| v.len()).sum();\nlet mut flat = Vec::with_capacity(total_len);\nflat.extend(nested.into_iter().flatten());\nprintln!(\"manual: {:?}\", start.elapsed());\n```\n\n**Typical Result**:\n- Manual with pre-allocation is ~10–20% faster for large Vecs.\n- Iterator version is more concise and equally fast for small data.\n\n## When to Use Each\n\n| Approach | Best For | Pitfalls |\n|----------|----------|----------|\n| Iterator | Readability, chaining operations | Slightly slower without pre-allocation |\n| Manual | Maximum performance, large data | Verbose; requires length calculation |\n\n## Advanced: Zero-Copy Flattening\n\nIf you have `Vec<&[T]>` instead of `Vec<Vec<T>>`, use `.flatten().copied()` to avoid cloning:\n\n```rust\nlet slices: Vec<&[i32]> = vec![&[1, 2], &[3, 4]];\nlet flat: Vec<i32> = slices.iter().flatten().copied().collect();\n```\n\n## Key Takeaways\n\n✅ **Use .flatten() for**:\n- Clean, idiomatic code.\n- Chaining with other iterator adapters (e.g., `.filter()`).\n\n✅ **Use manual extend for**:\n- Large datasets where pre-allocation matters.\n- Cases where you already know the total length.\n\n🚀 **Always pre-allocate for manual concatenation of large collections!**\n\n**Try This**: How would you flatten a `Vec<Vec<T>>` while removing duplicates?\n\n**Answer**: Combine `.flatten()` with `.collect::<HashSet<_>>()`.",
    "contentHtml": "<h2>Flattening with Iterators</h2>\n<p>The most idiomatic way is to use <code>.flatten()</code> or <code>.flat_map()</code>:</p>\n<pre><code class=\"language-rust\">let nested = vec![vec![1, 2], vec![3], vec![4, 5, 6]];\n\n// Method 1: flatten() (for Vec&lt;Iterables&gt;)\nlet flat: Vec&lt;_&gt; = nested.iter().flatten().copied().collect();\n\n// Method 2: flat_map() (for custom transformations)\nlet flat: Vec&lt;_&gt; = nested.into_iter().flat_map(|v| v).collect();\n</code></pre>\n<p><strong>Output</strong>: <code>[1, 2, 3, 4, 5, 6]</code></p>\n<h2>Manual Concatenation</h2>\n<p>For comparison, here&#39;s how you might do it manually:</p>\n<pre><code class=\"language-rust\">let mut flat = Vec::new();\nfor subvec in nested {\n    flat.extend(subvec);  // or append() if subvec is no longer needed\n}\n</code></pre>\n<h2>Performance Comparison</h2>\n<table>\n<thead>\n<tr>\n<th>Method</th>\n<th>Time Complexity</th>\n<th>Space Complexity</th>\n<th>Allocations</th>\n<th>Optimizations</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Iterator (flatten)</td>\n<td>O(n)</td>\n<td>O(1) iterator</td>\n<td>1 (result)</td>\n<td>May fuse iterators</td>\n</tr>\n<tr>\n<td>Manual (extend)</td>\n<td>O(n)</td>\n<td>O(1) temp space</td>\n<td>1 (result)</td>\n<td>Pre-allocation possible</td>\n</tr>\n</tbody></table>\n<h2>Key Insights</h2>\n<h3>Pre-allocation Advantage (Manual)</h3>\n<p>You can pre-allocate the target Vec if total size is known:</p>\n<pre><code class=\"language-rust\">let total_len: usize = nested.iter().map(|v| v.len()).sum();\nlet mut flat = Vec::with_capacity(total_len);  // Critical for large datasets\nflat.extend(nested.into_iter().flatten());\n</code></pre>\n<h3>Iterator Laziness</h3>\n<ul>\n<li><code>.flatten()</code> is lazy, but <code>.collect()</code> still needs to allocate the result.</li>\n<li>Chained iterators (e.g., <code>.filter().flatten()</code>) may optimize better than manual loops.</li>\n</ul>\n<h2>Benchmark Example</h2>\n<pre><code class=\"language-rust\">let nested: Vec&lt;Vec&lt;i32&gt;&gt; = (0..1_000).map(|i| vec![i; 100]).collect();\n\n// Iterator approach\nlet start = std::time::Instant::now();\nlet flat = nested.iter().flatten().copied().collect::&lt;Vec&lt;_&gt;&gt;();\nprintln!(&quot;flatten: {:?}&quot;, start.elapsed());\n\n// Manual approach with pre-allocation\nlet start = std::time::Instant::now();\nlet total_len = nested.iter().map(|v| v.len()).sum();\nlet mut flat = Vec::with_capacity(total_len);\nflat.extend(nested.into_iter().flatten());\nprintln!(&quot;manual: {:?}&quot;, start.elapsed());\n</code></pre>\n<p><strong>Typical Result</strong>:</p>\n<ul>\n<li>Manual with pre-allocation is ~10–20% faster for large Vecs.</li>\n<li>Iterator version is more concise and equally fast for small data.</li>\n</ul>\n<h2>When to Use Each</h2>\n<table>\n<thead>\n<tr>\n<th>Approach</th>\n<th>Best For</th>\n<th>Pitfalls</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Iterator</td>\n<td>Readability, chaining operations</td>\n<td>Slightly slower without pre-allocation</td>\n</tr>\n<tr>\n<td>Manual</td>\n<td>Maximum performance, large data</td>\n<td>Verbose; requires length calculation</td>\n</tr>\n</tbody></table>\n<h2>Advanced: Zero-Copy Flattening</h2>\n<p>If you have <code>Vec&lt;&amp;[T]&gt;</code> instead of <code>Vec&lt;Vec&lt;T&gt;&gt;</code>, use <code>.flatten().copied()</code> to avoid cloning:</p>\n<pre><code class=\"language-rust\">let slices: Vec&lt;&amp;[i32]&gt; = vec![&amp;[1, 2], &amp;[3, 4]];\nlet flat: Vec&lt;i32&gt; = slices.iter().flatten().copied().collect();\n</code></pre>\n<h2>Key Takeaways</h2>\n<p>✅ <strong>Use .flatten() for</strong>:</p>\n<ul>\n<li>Clean, idiomatic code.</li>\n<li>Chaining with other iterator adapters (e.g., <code>.filter()</code>).</li>\n</ul>\n<p>✅ <strong>Use manual extend for</strong>:</p>\n<ul>\n<li>Large datasets where pre-allocation matters.</li>\n<li>Cases where you already know the total length.</li>\n</ul>\n<p>🚀 <strong>Always pre-allocate for manual concatenation of large collections!</strong></p>\n<p><strong>Try This</strong>: How would you flatten a <code>Vec&lt;Vec&lt;T&gt;&gt;</code> while removing duplicates?</p>\n<p><strong>Answer</strong>: Combine <code>.flatten()</code> with <code>.collect::&lt;HashSet&lt;_&gt;&gt;()</code>.</p>\n",
    "author": "mayo",
    "category": "rust",
    "tags": [
      "rust",
      "vec"
    ],
    "readingTime": "3 min",
    "locale": "en",
    "seo": {
      "title": "Flatten a Vec<Vec<T>> into a Vec<T> using iterators",
      "description": "Flattening Vec<Vec<T>> using iterators compared to manual concatenation, analyzing performance implications and optimization strategies",
      "keywords": [
        "rust",
        "vec"
      ]
    },
    "headings": [
      {
        "id": "flattening-with-iterators",
        "text": "Flattening with Iterators",
        "level": 2
      },
      {
        "id": "manual-concatenation",
        "text": "Manual Concatenation",
        "level": 2
      },
      {
        "id": "performance-comparison",
        "text": "Performance Comparison",
        "level": 2
      },
      {
        "id": "key-insights",
        "text": "Key Insights",
        "level": 2
      },
      {
        "id": "pre-allocation-advantage-manual",
        "text": "Pre-allocation Advantage (Manual)",
        "level": 3
      },
      {
        "id": "iterator-laziness",
        "text": "Iterator Laziness",
        "level": 3
      },
      {
        "id": "benchmark-example",
        "text": "Benchmark Example",
        "level": 2
      },
      {
        "id": "when-to-use-each",
        "text": "When to Use Each",
        "level": 2
      },
      {
        "id": "advanced-zero-copy-flattening",
        "text": "Advanced: Zero-Copy Flattening",
        "level": 2
      },
      {
        "id": "key-takeaways",
        "text": "Key Takeaways",
        "level": 2
      }
    ]
  },
  {
    "id": "vec-retain-vs-filter-collect",
    "slug": "vec-retain-vs-filter-collect",
    "title": "Vec::retain() Vs filtering with iter().filter().collect()?",
    "date": "2025-07-28",
    "excerpt": "Comparing Vec::retain() in-place filtering with iter().filter().collect() for different filtering scenarios and performance implications",
    "content": "## Vec::retain(): In-Place Filtering\n\n**Purpose**: Removes elements from a Vec in-place based on a predicate, preserving the order of retained elements.\n\n**Signature**:\n```rust\npub fn retain<F>(&mut self, f: F)\nwhere\n    F: FnMut(&T) -> bool,\n```\n\n## Key Features\n\n| Aspect | retain() | iter().filter().collect() |\n|--------|----------|---------------------------|\n| Mutates Original | ✅ Yes (in-place) | ❌ No (allocates new Vec) |\n| Preserves Order | ✅ Yes | ✅ Yes |\n| Memory Efficiency | ✅ O(1) extra space | ❌ O(n) extra space |\n| Performance | Faster (no reallocation) | Slower (allocates/copies) |\n| Use Case | Filtering without allocation | Creating a new filtered collection |\n\n## Example: Filtering Even Numbers\n\n### Using retain() (In-Place)\n```rust\nlet mut vec = vec![1, 2, 3, 4];\nvec.retain(|x| x % 2 == 0);  // Keeps evens\nassert_eq!(vec, [2, 4]);      // Original `vec` modified\n```\n\n### Using filter().collect() (New Allocation)\n```rust\nlet vec = vec![1, 2, 3, 4];\nlet filtered: Vec<_> = vec.iter().filter(|x| *x % 2 == 0).copied().collect();\nassert_eq!(filtered, [2, 4]);  // New `Vec` created\n// `vec` remains unchanged: [1, 2, 3, 4]\n```\n\n## Performance Comparison\n\n### retain():\n- **Time**: O(n) (single pass, shifts elements left in-place).\n- **Space**: O(1) (no extra allocations).\n\n### filter().collect():\n- **Time**: O(n) (but requires copying to a new allocation).\n- **Space**: O(n) (new Vec allocated).\n\n### Benchmark Suggestion:\n```rust\nlet mut big_vec = (0..1_000_000).collect::<Vec<_>>();\n// Measure `retain`\nlet start = std::time::Instant::now();\nbig_vec.retain(|x| x % 2 == 0);\nprintln!(\"retain: {:?}\", start.elapsed());\n\n// Measure `filter().collect()`\nlet big_vec = (0..1_000_000).collect::<Vec<_>>();\nlet start = std::time::Instant::now();\nlet filtered = big_vec.iter().filter(|x| *x % 2 == 0).collect::<Vec<_>>();\nprintln!(\"filter.collect: {:?}\", start.elapsed());\n```\n\n**Typical Result**: `retain()` is 2–3x faster due to no allocations.\n\n## When to Use Each\n\n### Prefer retain() When:\n- You want to modify the Vec in-place.\n- Memory efficiency is critical (e.g., large Vecs).\n- Order of elements must be preserved.\n\n### Prefer filter().collect() When:\n- You need the original Vec to remain intact.\n- Chaining multiple iterator adapters (e.g., `.filter().map()`).\n- Working with non-Vec iterators (e.g., ranges, slices).\n\n## Advanced Notes\n\n### retain_mut():\nRust also provides `retain_mut()` for predicates that need mutable access to elements:\n\n```rust\nlet mut vec = vec![1, 2, 3];\nvec.retain_mut(|x| {\n    *x += 1;           // Modify in-place\n    *x % 2 == 0        // Keep if even after increment\n});\nassert_eq!(vec, [2, 4]);\n```\n\n### Stability:\nBoth methods preserve the relative order of retained elements (stable filtering).\n\n## Key Takeaways\n\n✅ **retain()**: Faster, memory-efficient, and in-place. Ideal for bulk modifications.\n✅ **filter().collect()**: Flexible, non-destructive. Ideal for iterator pipelines.\n\n## Real-World Use Case:\n- **retain()**: Cleaning up expired sessions in a server's session pool.\n- **filter().collect()**: Transforming API response data into a filtered subset.\n\n**Try This**: What happens if you `retain()` with a predicate that keeps all elements?\n\n**Answer**: No-op (no elements removed, no reallocations).",
    "contentHtml": "<h2>Vec::retain(): In-Place Filtering</h2>\n<p><strong>Purpose</strong>: Removes elements from a Vec in-place based on a predicate, preserving the order of retained elements.</p>\n<p><strong>Signature</strong>:</p>\n<pre><code class=\"language-rust\">pub fn retain&lt;F&gt;(&amp;mut self, f: F)\nwhere\n    F: FnMut(&amp;T) -&gt; bool,\n</code></pre>\n<h2>Key Features</h2>\n<table>\n<thead>\n<tr>\n<th>Aspect</th>\n<th>retain()</th>\n<th>iter().filter().collect()</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Mutates Original</td>\n<td>✅ Yes (in-place)</td>\n<td>❌ No (allocates new Vec)</td>\n</tr>\n<tr>\n<td>Preserves Order</td>\n<td>✅ Yes</td>\n<td>✅ Yes</td>\n</tr>\n<tr>\n<td>Memory Efficiency</td>\n<td>✅ O(1) extra space</td>\n<td>❌ O(n) extra space</td>\n</tr>\n<tr>\n<td>Performance</td>\n<td>Faster (no reallocation)</td>\n<td>Slower (allocates/copies)</td>\n</tr>\n<tr>\n<td>Use Case</td>\n<td>Filtering without allocation</td>\n<td>Creating a new filtered collection</td>\n</tr>\n</tbody></table>\n<h2>Example: Filtering Even Numbers</h2>\n<h3>Using retain() (In-Place)</h3>\n<pre><code class=\"language-rust\">let mut vec = vec![1, 2, 3, 4];\nvec.retain(|x| x % 2 == 0);  // Keeps evens\nassert_eq!(vec, [2, 4]);      // Original `vec` modified\n</code></pre>\n<h3>Using filter().collect() (New Allocation)</h3>\n<pre><code class=\"language-rust\">let vec = vec![1, 2, 3, 4];\nlet filtered: Vec&lt;_&gt; = vec.iter().filter(|x| *x % 2 == 0).copied().collect();\nassert_eq!(filtered, [2, 4]);  // New `Vec` created\n// `vec` remains unchanged: [1, 2, 3, 4]\n</code></pre>\n<h2>Performance Comparison</h2>\n<h3>retain():</h3>\n<ul>\n<li><strong>Time</strong>: O(n) (single pass, shifts elements left in-place).</li>\n<li><strong>Space</strong>: O(1) (no extra allocations).</li>\n</ul>\n<h3>filter().collect():</h3>\n<ul>\n<li><strong>Time</strong>: O(n) (but requires copying to a new allocation).</li>\n<li><strong>Space</strong>: O(n) (new Vec allocated).</li>\n</ul>\n<h3>Benchmark Suggestion:</h3>\n<pre><code class=\"language-rust\">let mut big_vec = (0..1_000_000).collect::&lt;Vec&lt;_&gt;&gt;();\n// Measure `retain`\nlet start = std::time::Instant::now();\nbig_vec.retain(|x| x % 2 == 0);\nprintln!(&quot;retain: {:?}&quot;, start.elapsed());\n\n// Measure `filter().collect()`\nlet big_vec = (0..1_000_000).collect::&lt;Vec&lt;_&gt;&gt;();\nlet start = std::time::Instant::now();\nlet filtered = big_vec.iter().filter(|x| *x % 2 == 0).collect::&lt;Vec&lt;_&gt;&gt;();\nprintln!(&quot;filter.collect: {:?}&quot;, start.elapsed());\n</code></pre>\n<p><strong>Typical Result</strong>: <code>retain()</code> is 2–3x faster due to no allocations.</p>\n<h2>When to Use Each</h2>\n<h3>Prefer retain() When:</h3>\n<ul>\n<li>You want to modify the Vec in-place.</li>\n<li>Memory efficiency is critical (e.g., large Vecs).</li>\n<li>Order of elements must be preserved.</li>\n</ul>\n<h3>Prefer filter().collect() When:</h3>\n<ul>\n<li>You need the original Vec to remain intact.</li>\n<li>Chaining multiple iterator adapters (e.g., <code>.filter().map()</code>).</li>\n<li>Working with non-Vec iterators (e.g., ranges, slices).</li>\n</ul>\n<h2>Advanced Notes</h2>\n<h3>retain_mut():</h3>\n<p>Rust also provides <code>retain_mut()</code> for predicates that need mutable access to elements:</p>\n<pre><code class=\"language-rust\">let mut vec = vec![1, 2, 3];\nvec.retain_mut(|x| {\n    *x += 1;           // Modify in-place\n    *x % 2 == 0        // Keep if even after increment\n});\nassert_eq!(vec, [2, 4]);\n</code></pre>\n<h3>Stability:</h3>\n<p>Both methods preserve the relative order of retained elements (stable filtering).</p>\n<h2>Key Takeaways</h2>\n<p>✅ <strong>retain()</strong>: Faster, memory-efficient, and in-place. Ideal for bulk modifications.\n✅ <strong>filter().collect()</strong>: Flexible, non-destructive. Ideal for iterator pipelines.</p>\n<h2>Real-World Use Case:</h2>\n<ul>\n<li><strong>retain()</strong>: Cleaning up expired sessions in a server&#39;s session pool.</li>\n<li><strong>filter().collect()</strong>: Transforming API response data into a filtered subset.</li>\n</ul>\n<p><strong>Try This</strong>: What happens if you <code>retain()</code> with a predicate that keeps all elements?</p>\n<p><strong>Answer</strong>: No-op (no elements removed, no reallocations).</p>\n",
    "author": "mayo",
    "category": "rust",
    "tags": [
      "rust",
      "retain"
    ],
    "readingTime": "3 min",
    "locale": "en",
    "seo": {
      "title": "Vec::retain() Vs filtering with iter().filter().collect()?",
      "description": "Comparing Vec::retain() in-place filtering with iter().filter().collect() for different filtering scenarios and performance implications",
      "keywords": [
        "rust",
        "retain"
      ]
    },
    "headings": [
      {
        "id": "vecretain-in-place-filtering",
        "text": "Vec::retain(): In-Place Filtering",
        "level": 2
      },
      {
        "id": "key-features",
        "text": "Key Features",
        "level": 2
      },
      {
        "id": "example-filtering-even-numbers",
        "text": "Example: Filtering Even Numbers",
        "level": 2
      },
      {
        "id": "using-retain-in-place",
        "text": "Using retain() (In-Place)",
        "level": 3
      },
      {
        "id": "using-filtercollect-new-allocation",
        "text": "Using filter().collect() (New Allocation)",
        "level": 3
      },
      {
        "id": "performance-comparison",
        "text": "Performance Comparison",
        "level": 2
      },
      {
        "id": "retain",
        "text": "retain():",
        "level": 3
      },
      {
        "id": "filtercollect",
        "text": "filter().collect():",
        "level": 3
      },
      {
        "id": "benchmark-suggestion",
        "text": "Benchmark Suggestion:",
        "level": 3
      },
      {
        "id": "when-to-use-each",
        "text": "When to Use Each",
        "level": 2
      },
      {
        "id": "prefer-retain-when",
        "text": "Prefer retain() When:",
        "level": 3
      },
      {
        "id": "prefer-filtercollect-when",
        "text": "Prefer filter().collect() When:",
        "level": 3
      },
      {
        "id": "advanced-notes",
        "text": "Advanced Notes",
        "level": 2
      },
      {
        "id": "retainmut",
        "text": "retain_mut():",
        "level": 3
      },
      {
        "id": "stability",
        "text": "Stability:",
        "level": 3
      },
      {
        "id": "key-takeaways",
        "text": "Key Takeaways",
        "level": 2
      },
      {
        "id": "real-world-use-case",
        "text": "Real-World Use Case:",
        "level": 2
      }
    ]
  },
  {
    "id": "vec-drain-vs-truncate-clear",
    "slug": "vec-drain-vs-truncate-clear",
    "title": "Vec::drain() Vs Vec::truncate() or Vec::clear()?",
    "date": "2025-07-26",
    "excerpt": "Understanding Vec::drain() functionality and comparing it with Vec::truncate() and Vec::clear() for different element removal scenarios",
    "content": "## What is Vec::drain()?\n\n`drain()` removes a range of elements from a Vec while yielding ownership of them through an iterator. Unlike `truncate()` or `clear()`, it allows you to process the removed elements before they're dropped.\n\n### Signature\n```rust\npub fn drain<R>(&mut self, range: R) -> Drain<'_, T>\nwhere\n    R: RangeBounds<usize>,\n```\n\n## Key Features\n\n| Method | Removes Elements | Yields Ownership | Preserves Capacity | Time Complexity |\n|--------|------------------|------------------|-------------------|-----------------|\n| `drain(..)` | Yes | ✅ Yes (via iterator) | ✅ Yes | O(n) |\n| `truncate()` | Yes (from index) | ❌ No | ✅ Yes | O(1) |\n| `clear()` | All | ❌ No | ✅ Yes | O(1) |\n\n## When to Use Each\n\n### 1. Vec::drain()\n\n**Use Case**: Process removed elements (e.g., filter, transform, or batch-delete).\n\n**Example**:\n```rust\nlet mut vec = vec!['a', 'b', 'c', 'd'];\nfor ch in vec.drain(1..3) {  // Removes 'b' and 'c'\n    println!(\"Removed: {}\", ch);  // Prints 'b', then 'c'\n}\nassert_eq!(vec, ['a', 'd']);  // Keeps remaining elements\n```\n\n**Performance**: Avoids extra allocations if reusing the iterator.\n\n### 2. Vec::truncate()\n\n**Use Case**: Quickly remove elements from the end without processing them.\n\n**Example**:\n```rust\nlet mut vec = vec![1, 2, 3, 4];\nvec.truncate(2);  // Drops 3 and 4 (no iterator)\nassert_eq!(vec, [1, 2]);\n```\n\n### 3. Vec::clear()\n\n**Use Case**: Remove all elements (faster than `drain(..)` if you don't need them).\n\n**Example**:\n```rust\nlet mut vec = vec![1, 2, 3];\nvec.clear();  // Drops all elements\nassert!(vec.is_empty());\n```\n\n## Memory Behavior\n\n- All three methods retain the Vec's capacity (no reallocation if elements are re-added).\n- `drain()` is lazy: Elements are only dropped when the iterator is consumed.\n\n## Advanced Use: Reuse Storage\n\n`drain()` is ideal for replacing a subset of elements efficiently:\n\n```rust\nlet mut vec = vec![\"old\", \"old\", \"new\", \"old\"];\nvec.drain(0..2).for_each(drop);  // Remove first two\nvec.insert(0, \"fresh\");\nassert_eq!(vec, [\"fresh\", \"new\", \"old\"]);\n```\n\n## Key Takeaways\n\n- ✅ **drain()**: Use when you need to process removed elements or batch-delete.\n- ✅ **truncate()/clear()**: Use for fast bulk removal without processing.\n- 🚀 **All preserve capacity**: No reallocation overhead for future ops.\n\n## Real-World Example\n\nIn a game engine, `drain()` could efficiently remove expired entities while allowing cleanup logic (e.g., saving state).\n\n**Try This**: What happens if you `drain()` but don't consume the iterator?\n\n**Answer**: The elements are still removed when the Drain iterator is dropped (due to its Drop impl).",
    "contentHtml": "<h2>What is Vec::drain()?</h2>\n<p><code>drain()</code> removes a range of elements from a Vec while yielding ownership of them through an iterator. Unlike <code>truncate()</code> or <code>clear()</code>, it allows you to process the removed elements before they&#39;re dropped.</p>\n<h3>Signature</h3>\n<pre><code class=\"language-rust\">pub fn drain&lt;R&gt;(&amp;mut self, range: R) -&gt; Drain&lt;&#39;_, T&gt;\nwhere\n    R: RangeBounds&lt;usize&gt;,\n</code></pre>\n<h2>Key Features</h2>\n<table>\n<thead>\n<tr>\n<th>Method</th>\n<th>Removes Elements</th>\n<th>Yields Ownership</th>\n<th>Preserves Capacity</th>\n<th>Time Complexity</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><code>drain(..)</code></td>\n<td>Yes</td>\n<td>✅ Yes (via iterator)</td>\n<td>✅ Yes</td>\n<td>O(n)</td>\n</tr>\n<tr>\n<td><code>truncate()</code></td>\n<td>Yes (from index)</td>\n<td>❌ No</td>\n<td>✅ Yes</td>\n<td>O(1)</td>\n</tr>\n<tr>\n<td><code>clear()</code></td>\n<td>All</td>\n<td>❌ No</td>\n<td>✅ Yes</td>\n<td>O(1)</td>\n</tr>\n</tbody></table>\n<h2>When to Use Each</h2>\n<h3>1. Vec::drain()</h3>\n<p><strong>Use Case</strong>: Process removed elements (e.g., filter, transform, or batch-delete).</p>\n<p><strong>Example</strong>:</p>\n<pre><code class=\"language-rust\">let mut vec = vec![&#39;a&#39;, &#39;b&#39;, &#39;c&#39;, &#39;d&#39;];\nfor ch in vec.drain(1..3) {  // Removes &#39;b&#39; and &#39;c&#39;\n    println!(&quot;Removed: {}&quot;, ch);  // Prints &#39;b&#39;, then &#39;c&#39;\n}\nassert_eq!(vec, [&#39;a&#39;, &#39;d&#39;]);  // Keeps remaining elements\n</code></pre>\n<p><strong>Performance</strong>: Avoids extra allocations if reusing the iterator.</p>\n<h3>2. Vec::truncate()</h3>\n<p><strong>Use Case</strong>: Quickly remove elements from the end without processing them.</p>\n<p><strong>Example</strong>:</p>\n<pre><code class=\"language-rust\">let mut vec = vec![1, 2, 3, 4];\nvec.truncate(2);  // Drops 3 and 4 (no iterator)\nassert_eq!(vec, [1, 2]);\n</code></pre>\n<h3>3. Vec::clear()</h3>\n<p><strong>Use Case</strong>: Remove all elements (faster than <code>drain(..)</code> if you don&#39;t need them).</p>\n<p><strong>Example</strong>:</p>\n<pre><code class=\"language-rust\">let mut vec = vec![1, 2, 3];\nvec.clear();  // Drops all elements\nassert!(vec.is_empty());\n</code></pre>\n<h2>Memory Behavior</h2>\n<ul>\n<li>All three methods retain the Vec&#39;s capacity (no reallocation if elements are re-added).</li>\n<li><code>drain()</code> is lazy: Elements are only dropped when the iterator is consumed.</li>\n</ul>\n<h2>Advanced Use: Reuse Storage</h2>\n<p><code>drain()</code> is ideal for replacing a subset of elements efficiently:</p>\n<pre><code class=\"language-rust\">let mut vec = vec![&quot;old&quot;, &quot;old&quot;, &quot;new&quot;, &quot;old&quot;];\nvec.drain(0..2).for_each(drop);  // Remove first two\nvec.insert(0, &quot;fresh&quot;);\nassert_eq!(vec, [&quot;fresh&quot;, &quot;new&quot;, &quot;old&quot;]);\n</code></pre>\n<h2>Key Takeaways</h2>\n<ul>\n<li>✅ <strong>drain()</strong>: Use when you need to process removed elements or batch-delete.</li>\n<li>✅ <strong>truncate()/clear()</strong>: Use for fast bulk removal without processing.</li>\n<li>🚀 <strong>All preserve capacity</strong>: No reallocation overhead for future ops.</li>\n</ul>\n<h2>Real-World Example</h2>\n<p>In a game engine, <code>drain()</code> could efficiently remove expired entities while allowing cleanup logic (e.g., saving state).</p>\n<p><strong>Try This</strong>: What happens if you <code>drain()</code> but don&#39;t consume the iterator?</p>\n<p><strong>Answer</strong>: The elements are still removed when the Drain iterator is dropped (due to its Drop impl).</p>\n",
    "author": "mayo",
    "category": "rust",
    "tags": [
      "rust",
      "drain"
    ],
    "readingTime": "3 min",
    "locale": "en",
    "seo": {
      "title": "Vec::drain() Vs Vec::truncate() or Vec::clear()?",
      "description": "Understanding Vec::drain() functionality and comparing it with Vec::truncate() and Vec::clear() for different element removal scenarios",
      "keywords": [
        "rust",
        "drain"
      ]
    },
    "headings": [
      {
        "id": "what-is-vecdrain",
        "text": "What is Vec::drain()?",
        "level": 2
      },
      {
        "id": "signature",
        "text": "Signature",
        "level": 3
      },
      {
        "id": "key-features",
        "text": "Key Features",
        "level": 2
      },
      {
        "id": "when-to-use-each",
        "text": "When to Use Each",
        "level": 2
      },
      {
        "id": "1-vecdrain",
        "text": "1. Vec::drain()",
        "level": 3
      },
      {
        "id": "2-vectruncate",
        "text": "2. Vec::truncate()",
        "level": 3
      },
      {
        "id": "3-vecclear",
        "text": "3. Vec::clear()",
        "level": 3
      },
      {
        "id": "memory-behavior",
        "text": "Memory Behavior",
        "level": 2
      },
      {
        "id": "advanced-use-reuse-storage",
        "text": "Advanced Use: Reuse Storage",
        "level": 2
      },
      {
        "id": "key-takeaways",
        "text": "Key Takeaways",
        "level": 2
      },
      {
        "id": "real-world-example",
        "text": "Real-World Example",
        "level": 2
      }
    ]
  },
  {
    "id": "box-slice-vs-vec-differences",
    "slug": "box-slice-vs-vec-differences",
    "title": "What is the difference between Box<[T]> and Vec<T>?",
    "date": "2025-07-24",
    "excerpt": "Comparing Box<[T]> and Vec<T> differences in mutability, memory overhead, and performance implications for different use cases",
    "content": "## Key Differences\n\n| Feature | Vec<T> | Box<[T]> |\n|---------|--------|----------|\n| Size Mutability | Growable/shrinkable (push, pop) | Fixed-size (immutable after creation) |\n| Storage | Heap-allocated + capacity field | Pure heap slice (no extra metadata) |\n| Memory Overhead | 3 usizes (ptr, len, capacity) | 2 usizes (ptr, len) |\n| Conversion Cost | O(1) to Box<[T]> (shrink-to-fit) | O(n) to Vec (must reallocate) |\n\n## When to Use Each\n\n### Prefer Vec<T> When:\n\nYou need dynamic resizing:\n\n```rust\nlet mut vec = vec![1, 2, 3];\nvec.push(4);  // Works\n```\n\nYou frequently modify the collection (e.g., appending/removing elements).\n\n### Prefer Box<[T]> When:\n\nYou want a fixed-size, immutable collection:\n\n```rust\nlet boxed_slice: Box<[i32]> = vec![1, 2, 3].into_boxed_slice();\n// boxed_slice.push(4);  // ERROR: No `push` method\n```\n\nMemory efficiency matters (e.g., embedded systems):\n- Saves 1 usize (no unused capacity).\n\nInterfacing with APIs requiring owned slices:\n\n```rust\nfn process(data: Box<[i32]>) { /* ... */ }\n```\n\n## Conversion Between Them\n\n| Direction | Code | Cost |\n|-----------|------|------|\n| Vec → Box<[T]> | `vec.into_boxed_slice()` | O(1) |\n| Box<[T]> → Vec | `Vec::from(boxed_slice)` | O(n) |\n\n### Example:\n\n```rust\nlet vec = vec![1, 2, 3];\nlet boxed: Box<[i32]> = vec.into_boxed_slice();  // No reallocation\nlet vec_again = Vec::from(boxed);                // Copies data\n```\n\n## Performance Implications\n\n- **Iteration**: Identical (both are contiguous heap arrays).\n- **Memory**: Box<[T]> avoids unused capacity overhead.\n- **Flexibility**: Vec supports in-place growth; Box<[T]> does not.\n\n## Real-World Use Cases\n\n- **Vec**: Buffers for dynamic data (e.g., HTTP request bodies).\n- **Box<[T]>**:\n  - Configurations loaded once and never modified.\n  - Storing large immutable datasets (e.g., game assets).\n\n## Key Takeaways\n\n✅ Use Vec for mutable, growable sequences.\n✅ Use Box<[T]> for immutable, memory-efficient storage.\n⚡ Convert cheaply from Vec to Box<[T]> when done modifying.\n\n**Try This**: What happens if you convert a Vec with spare capacity to Box<[T]>?\n\n**Answer**: `into_boxed_slice()` shrinks the allocation to exact size (no unused capacity).",
    "contentHtml": "<h2>Key Differences</h2>\n<table>\n<thead>\n<tr>\n<th>Feature</th>\n<th>Vec<T></th>\n<th>Box&lt;[T]&gt;</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Size Mutability</td>\n<td>Growable/shrinkable (push, pop)</td>\n<td>Fixed-size (immutable after creation)</td>\n</tr>\n<tr>\n<td>Storage</td>\n<td>Heap-allocated + capacity field</td>\n<td>Pure heap slice (no extra metadata)</td>\n</tr>\n<tr>\n<td>Memory Overhead</td>\n<td>3 usizes (ptr, len, capacity)</td>\n<td>2 usizes (ptr, len)</td>\n</tr>\n<tr>\n<td>Conversion Cost</td>\n<td>O(1) to Box&lt;[T]&gt; (shrink-to-fit)</td>\n<td>O(n) to Vec (must reallocate)</td>\n</tr>\n</tbody></table>\n<h2>When to Use Each</h2>\n<h3>Prefer Vec<T> When:</h3>\n<p>You need dynamic resizing:</p>\n<pre><code class=\"language-rust\">let mut vec = vec![1, 2, 3];\nvec.push(4);  // Works\n</code></pre>\n<p>You frequently modify the collection (e.g., appending/removing elements).</p>\n<h3>Prefer Box&lt;[T]&gt; When:</h3>\n<p>You want a fixed-size, immutable collection:</p>\n<pre><code class=\"language-rust\">let boxed_slice: Box&lt;[i32]&gt; = vec![1, 2, 3].into_boxed_slice();\n// boxed_slice.push(4);  // ERROR: No `push` method\n</code></pre>\n<p>Memory efficiency matters (e.g., embedded systems):</p>\n<ul>\n<li>Saves 1 usize (no unused capacity).</li>\n</ul>\n<p>Interfacing with APIs requiring owned slices:</p>\n<pre><code class=\"language-rust\">fn process(data: Box&lt;[i32]&gt;) { /* ... */ }\n</code></pre>\n<h2>Conversion Between Them</h2>\n<table>\n<thead>\n<tr>\n<th>Direction</th>\n<th>Code</th>\n<th>Cost</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Vec → Box&lt;[T]&gt;</td>\n<td><code>vec.into_boxed_slice()</code></td>\n<td>O(1)</td>\n</tr>\n<tr>\n<td>Box&lt;[T]&gt; → Vec</td>\n<td><code>Vec::from(boxed_slice)</code></td>\n<td>O(n)</td>\n</tr>\n</tbody></table>\n<h3>Example:</h3>\n<pre><code class=\"language-rust\">let vec = vec![1, 2, 3];\nlet boxed: Box&lt;[i32]&gt; = vec.into_boxed_slice();  // No reallocation\nlet vec_again = Vec::from(boxed);                // Copies data\n</code></pre>\n<h2>Performance Implications</h2>\n<ul>\n<li><strong>Iteration</strong>: Identical (both are contiguous heap arrays).</li>\n<li><strong>Memory</strong>: Box&lt;[T]&gt; avoids unused capacity overhead.</li>\n<li><strong>Flexibility</strong>: Vec supports in-place growth; Box&lt;[T]&gt; does not.</li>\n</ul>\n<h2>Real-World Use Cases</h2>\n<ul>\n<li><strong>Vec</strong>: Buffers for dynamic data (e.g., HTTP request bodies).</li>\n<li><strong>Box&lt;[T]&gt;</strong>:<ul>\n<li>Configurations loaded once and never modified.</li>\n<li>Storing large immutable datasets (e.g., game assets).</li>\n</ul>\n</li>\n</ul>\n<h2>Key Takeaways</h2>\n<p>✅ Use Vec for mutable, growable sequences.\n✅ Use Box&lt;[T]&gt; for immutable, memory-efficient storage.\n⚡ Convert cheaply from Vec to Box&lt;[T]&gt; when done modifying.</p>\n<p><strong>Try This</strong>: What happens if you convert a Vec with spare capacity to Box&lt;[T]&gt;?</p>\n<p><strong>Answer</strong>: <code>into_boxed_slice()</code> shrinks the allocation to exact size (no unused capacity).</p>\n",
    "author": "mayo",
    "category": "rust",
    "tags": [
      "rust",
      "collections"
    ],
    "readingTime": "2 min",
    "locale": "en",
    "seo": {
      "title": "What is the difference between Box<[T]> and Vec<T>?",
      "description": "Comparing Box<[T]> and Vec<T> differences in mutability, memory overhead, and performance implications for different use cases",
      "keywords": [
        "rust",
        "collections"
      ]
    },
    "headings": [
      {
        "id": "key-differences",
        "text": "Key Differences",
        "level": 2
      },
      {
        "id": "when-to-use-each",
        "text": "When to Use Each",
        "level": 2
      },
      {
        "id": "prefer-veclesstgreater-when",
        "text": "Prefer Vec<T> When:",
        "level": 3
      },
      {
        "id": "prefer-boxlesstgreater-when",
        "text": "Prefer Box<[T]> When:",
        "level": 3
      },
      {
        "id": "conversion-between-them",
        "text": "Conversion Between Them",
        "level": 2
      },
      {
        "id": "example",
        "text": "Example:",
        "level": 3
      },
      {
        "id": "performance-implications",
        "text": "Performance Implications",
        "level": 2
      },
      {
        "id": "real-world-use-cases",
        "text": "Real-World Use Cases",
        "level": 2
      },
      {
        "id": "key-takeaways",
        "text": "Key Takeaways",
        "level": 2
      }
    ]
  },
  {
    "id": "efficient-duplicate-removal-vec",
    "slug": "efficient-duplicate-removal-vec",
    "title": "How removing duplicates from a Vec<T> where T: Eq + Hash?",
    "date": "2025-07-21",
    "excerpt": "Efficient approaches to remove duplicates from Vec<T> where T: Eq + Hash, comparing HashSet-based and sort-based methods with performance analysis",
    "content": "## Efficient Approaches\n\nWhen T implements Eq + Hash (for equality checks and hashing), the optimal methods are:\n\n## 1. Using HashSet (Preserves Order)\n\n### Steps:\n1. Iterate through the Vec.\n2. Track seen elements with a HashSet.\n3. Collect only unseen elements.\n\n### Code:\n```rust\nuse std::collections::HashSet;\n\nfn dedup_ordered<T: Eq + std::hash::Hash + Clone>(vec: &mut Vec<T>) {\n    let mut seen = HashSet::new();\n    vec.retain(|x| seen.insert(x.clone()));\n}\n```\n\n### Example:\n```rust\nlet mut vec = vec![1, 2, 2, 3, 3, 3];\ndedup_ordered(&mut vec);\nassert_eq!(vec, [1, 2, 3]); // Order preserved\n```\n\n### Performance:\n- **Time**: O(n) (average case, assuming good hash distribution).\n- **Space**: O(n) (for the HashSet).\n\n## 2. Sort + Dedup (Destroys Order)\n\n### Steps:\n1. Sort the Vec (groups duplicates together).\n2. Remove consecutive duplicates with dedup().\n\n### Code:\n```rust\nfn dedup_unordered<T: Ord>(vec: &mut Vec<T>) {\n    vec.sort();      // O(n log n)\n    vec.dedup();     // O(n)\n}\n```\n\n### Example:\n```rust\nlet mut vec = vec![3, 2, 2, 1, 3];\ndedup_unordered(&mut vec);\nassert_eq!(vec, [1, 2, 3]); // Order changed\n```\n\n### Performance:\n- **Time**: O(n log n) (dominated by sorting).\n- **Space**: O(1) (in-place, no extra allocations).\n\n## Comparison\n\n| Method | Time Complexity | Space Complexity | Preserves Order? | Use Case |\n|--------|-----------------|------------------|------------------|----------|\n| HashSet | O(n) | O(n) | ✅ Yes | Order matters, no sorting allowed. |\n| Sort + Dedup | O(n log n) | O(1) | ❌ No | Order irrelevant, memory-constrained. |\n\n## Key Takeaways\n\n✅ **Use HashSet if**:\n- Order must be preserved.\n- You can tolerate O(n) space.\n\n✅ **Use Sort + Dedup if**:\n- Order doesn't matter.\n- Memory is tight (e.g., embedded systems).\n\n## Alternatives:\n- For no_std environments, use a BTreeSet (slower but avoids hashing).\n- Use itertools::unique for iterator-based deduplication.\n\n**Try This**: What happens if T is Clone but not Hash?\n\n**Answer**: Use Vec::dedup_by with a custom equality check (no hashing).",
    "contentHtml": "<h2>Efficient Approaches</h2>\n<p>When T implements Eq + Hash (for equality checks and hashing), the optimal methods are:</p>\n<h2>1. Using HashSet (Preserves Order)</h2>\n<h3>Steps:</h3>\n<ol>\n<li>Iterate through the Vec.</li>\n<li>Track seen elements with a HashSet.</li>\n<li>Collect only unseen elements.</li>\n</ol>\n<h3>Code:</h3>\n<pre><code class=\"language-rust\">use std::collections::HashSet;\n\nfn dedup_ordered&lt;T: Eq + std::hash::Hash + Clone&gt;(vec: &amp;mut Vec&lt;T&gt;) {\n    let mut seen = HashSet::new();\n    vec.retain(|x| seen.insert(x.clone()));\n}\n</code></pre>\n<h3>Example:</h3>\n<pre><code class=\"language-rust\">let mut vec = vec![1, 2, 2, 3, 3, 3];\ndedup_ordered(&amp;mut vec);\nassert_eq!(vec, [1, 2, 3]); // Order preserved\n</code></pre>\n<h3>Performance:</h3>\n<ul>\n<li><strong>Time</strong>: O(n) (average case, assuming good hash distribution).</li>\n<li><strong>Space</strong>: O(n) (for the HashSet).</li>\n</ul>\n<h2>2. Sort + Dedup (Destroys Order)</h2>\n<h3>Steps:</h3>\n<ol>\n<li>Sort the Vec (groups duplicates together).</li>\n<li>Remove consecutive duplicates with dedup().</li>\n</ol>\n<h3>Code:</h3>\n<pre><code class=\"language-rust\">fn dedup_unordered&lt;T: Ord&gt;(vec: &amp;mut Vec&lt;T&gt;) {\n    vec.sort();      // O(n log n)\n    vec.dedup();     // O(n)\n}\n</code></pre>\n<h3>Example:</h3>\n<pre><code class=\"language-rust\">let mut vec = vec![3, 2, 2, 1, 3];\ndedup_unordered(&amp;mut vec);\nassert_eq!(vec, [1, 2, 3]); // Order changed\n</code></pre>\n<h3>Performance:</h3>\n<ul>\n<li><strong>Time</strong>: O(n log n) (dominated by sorting).</li>\n<li><strong>Space</strong>: O(1) (in-place, no extra allocations).</li>\n</ul>\n<h2>Comparison</h2>\n<table>\n<thead>\n<tr>\n<th>Method</th>\n<th>Time Complexity</th>\n<th>Space Complexity</th>\n<th>Preserves Order?</th>\n<th>Use Case</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>HashSet</td>\n<td>O(n)</td>\n<td>O(n)</td>\n<td>✅ Yes</td>\n<td>Order matters, no sorting allowed.</td>\n</tr>\n<tr>\n<td>Sort + Dedup</td>\n<td>O(n log n)</td>\n<td>O(1)</td>\n<td>❌ No</td>\n<td>Order irrelevant, memory-constrained.</td>\n</tr>\n</tbody></table>\n<h2>Key Takeaways</h2>\n<p>✅ <strong>Use HashSet if</strong>:</p>\n<ul>\n<li>Order must be preserved.</li>\n<li>You can tolerate O(n) space.</li>\n</ul>\n<p>✅ <strong>Use Sort + Dedup if</strong>:</p>\n<ul>\n<li>Order doesn&#39;t matter.</li>\n<li>Memory is tight (e.g., embedded systems).</li>\n</ul>\n<h2>Alternatives:</h2>\n<ul>\n<li>For no_std environments, use a BTreeSet (slower but avoids hashing).</li>\n<li>Use itertools::unique for iterator-based deduplication.</li>\n</ul>\n<p><strong>Try This</strong>: What happens if T is Clone but not Hash?</p>\n<p><strong>Answer</strong>: Use Vec::dedup_by with a custom equality check (no hashing).</p>\n",
    "author": "mayo",
    "category": "rust",
    "tags": [
      "rust",
      "collections"
    ],
    "readingTime": "2 min",
    "locale": "en",
    "seo": {
      "title": "How removing duplicates from a Vec<T> where T: Eq + Hash?",
      "description": "Efficient approaches to remove duplicates from Vec<T> where T: Eq + Hash, comparing HashSet-based and sort-based methods with performance analysis",
      "keywords": [
        "rust",
        "collections"
      ]
    },
    "headings": [
      {
        "id": "efficient-approaches",
        "text": "Efficient Approaches",
        "level": 2
      },
      {
        "id": "1-using-hashset-preserves-order",
        "text": "1. Using HashSet (Preserves Order)",
        "level": 2
      },
      {
        "id": "steps",
        "text": "Steps:",
        "level": 3
      },
      {
        "id": "code",
        "text": "Code:",
        "level": 3
      },
      {
        "id": "example",
        "text": "Example:",
        "level": 3
      },
      {
        "id": "performance",
        "text": "Performance:",
        "level": 3
      },
      {
        "id": "2-sort-dedup-destroys-order",
        "text": "2. Sort + Dedup (Destroys Order)",
        "level": 2
      },
      {
        "id": "steps",
        "text": "Steps:",
        "level": 3
      },
      {
        "id": "code",
        "text": "Code:",
        "level": 3
      },
      {
        "id": "example",
        "text": "Example:",
        "level": 3
      },
      {
        "id": "performance",
        "text": "Performance:",
        "level": 3
      },
      {
        "id": "comparison",
        "text": "Comparison",
        "level": 2
      },
      {
        "id": "key-takeaways",
        "text": "Key Takeaways",
        "level": 2
      },
      {
        "id": "alternatives",
        "text": "Alternatives:",
        "level": 2
      }
    ]
  },
  {
    "id": "vec-push-vs-with-capacity-performance-duplicate",
    "slug": "vec-push-vs-with-capacity-performance-duplicate",
    "title": "What is the performance impact of using Vec::push() in a loop vs. pre-allocating with Vec::with_capacity()?",
    "date": "2025-07-19",
    "excerpt": "Analyzing performance differences between Vec::push() in loops versus pre-allocating with Vec::with_capacity(), covering memory reallocation costs and optimization strategies",
    "content": "## Key Performance Differences\n\n| Vec::push() in a Loop | Vec::with_capacity() + push() |\n|----------------------|-------------------------------|\n| Reallocates memory multiple times (grows exponentially). | Allocates once upfront. |\n| O(n log n) time complexity (amortized). | O(n) time complexity. |\n| May fragment memory due to repeated allocations. | Single contiguous block of memory. |\n\n## Why Reallocations Are Costly\n\n### Growth Strategy\n- A Vec starts with capacity 0 and doubles its capacity when full (e.g., 0 → 4 → 8 → 16...).\n- Each reallocation involves:\n  - Allocating new memory.\n  - Copying all existing elements.\n  - Freeing the old memory.\n\n### Example for 10 Elements\n- **push() with Vec::new()**: 4 reallocations (capacity 0 → 4 → 8 → 16).\n- **push() with with_capacity(10)**: 0 reallocations.\n\n## Benchmark Comparison\n\n```rust\nuse std::time::Instant;\n\nfn main() {\n    // Test with 1 million elements\n    let n = 1_000_000;\n    \n    // Method 1: No pre-allocation\n    let start = Instant::now();\n    let mut v1 = Vec::new();\n    for i in 0..n {\n        v1.push(i);\n    }\n    println!(\"Vec::new(): {:?}\", start.elapsed());\n    \n    // Method 2: Pre-allocate\n    let start = Instant::now();\n    let mut v2 = Vec::with_capacity(n);\n    for i in 0..n {\n        v2.push(i);\n    }\n    println!(\"Vec::with_capacity(): {:?}\", start.elapsed());\n}\n```\n\n### Typical Results\n```\nVec::new(): 1.8ms  \nVec::with_capacity(): 0.4ms  // 4.5x faster\n```\n\n## When to Pre-Allocate\n\n- **Known Size**: Use with_capacity(n) if you know the exact/maximum number of elements.\n- **Performance-Critical Code**: Avoid reallocations in hot loops.\n- **Large Data**: Prevent stack overflow for huge collections.\n\n## When Vec::new() is Acceptable\n\n- **Small/Unknown Sizes**: For ad-hoc usage or short-lived vectors.\n- **Code Simplicity**: When performance isn't critical.\n\n## Advanced Optimization: extend()\n\nIf you have an iterator, extend() is often faster than a loop with push():\n\n```rust\nlet mut v = Vec::with_capacity(n);\nv.extend(0..n);  // Optimized for iterators (avoids bounds checks)\n```\n\n## Key Takeaways\n\n✅ **Use with_capacity() for**:\n- Predictable element counts.\n- High-performance scenarios.\n\n✅ **Use Vec::new() for**:\n- Small/unknown sizes or prototyping.\n\n🚀 **Avoid unnecessary reallocations**—they dominate runtime for large Vecs.\n\n## Real-World Impact\n\nIn the regex crate, pre-allocation is used for capture groups to avoid reallocations during pattern matching.\n\n**Try This**: What happens if you pre-allocate too much (e.g., with_capacity(1000) but only use 10 elements)?\n\n**Answer**: Wasted memory. Use shrink_to_fit() to release unused capacity.",
    "contentHtml": "<h2>Key Performance Differences</h2>\n<table>\n<thead>\n<tr>\n<th>Vec::push() in a Loop</th>\n<th>Vec::with_capacity() + push()</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Reallocates memory multiple times (grows exponentially).</td>\n<td>Allocates once upfront.</td>\n</tr>\n<tr>\n<td>O(n log n) time complexity (amortized).</td>\n<td>O(n) time complexity.</td>\n</tr>\n<tr>\n<td>May fragment memory due to repeated allocations.</td>\n<td>Single contiguous block of memory.</td>\n</tr>\n</tbody></table>\n<h2>Why Reallocations Are Costly</h2>\n<h3>Growth Strategy</h3>\n<ul>\n<li>A Vec starts with capacity 0 and doubles its capacity when full (e.g., 0 → 4 → 8 → 16...).</li>\n<li>Each reallocation involves:<ul>\n<li>Allocating new memory.</li>\n<li>Copying all existing elements.</li>\n<li>Freeing the old memory.</li>\n</ul>\n</li>\n</ul>\n<h3>Example for 10 Elements</h3>\n<ul>\n<li><strong>push() with Vec::new()</strong>: 4 reallocations (capacity 0 → 4 → 8 → 16).</li>\n<li><strong>push() with with_capacity(10)</strong>: 0 reallocations.</li>\n</ul>\n<h2>Benchmark Comparison</h2>\n<pre><code class=\"language-rust\">use std::time::Instant;\n\nfn main() {\n    // Test with 1 million elements\n    let n = 1_000_000;\n    \n    // Method 1: No pre-allocation\n    let start = Instant::now();\n    let mut v1 = Vec::new();\n    for i in 0..n {\n        v1.push(i);\n    }\n    println!(&quot;Vec::new(): {:?}&quot;, start.elapsed());\n    \n    // Method 2: Pre-allocate\n    let start = Instant::now();\n    let mut v2 = Vec::with_capacity(n);\n    for i in 0..n {\n        v2.push(i);\n    }\n    println!(&quot;Vec::with_capacity(): {:?}&quot;, start.elapsed());\n}\n</code></pre>\n<h3>Typical Results</h3>\n<pre><code>Vec::new(): 1.8ms  \nVec::with_capacity(): 0.4ms  // 4.5x faster\n</code></pre>\n<h2>When to Pre-Allocate</h2>\n<ul>\n<li><strong>Known Size</strong>: Use with_capacity(n) if you know the exact/maximum number of elements.</li>\n<li><strong>Performance-Critical Code</strong>: Avoid reallocations in hot loops.</li>\n<li><strong>Large Data</strong>: Prevent stack overflow for huge collections.</li>\n</ul>\n<h2>When Vec::new() is Acceptable</h2>\n<ul>\n<li><strong>Small/Unknown Sizes</strong>: For ad-hoc usage or short-lived vectors.</li>\n<li><strong>Code Simplicity</strong>: When performance isn&#39;t critical.</li>\n</ul>\n<h2>Advanced Optimization: extend()</h2>\n<p>If you have an iterator, extend() is often faster than a loop with push():</p>\n<pre><code class=\"language-rust\">let mut v = Vec::with_capacity(n);\nv.extend(0..n);  // Optimized for iterators (avoids bounds checks)\n</code></pre>\n<h2>Key Takeaways</h2>\n<p>✅ <strong>Use with_capacity() for</strong>:</p>\n<ul>\n<li>Predictable element counts.</li>\n<li>High-performance scenarios.</li>\n</ul>\n<p>✅ <strong>Use Vec::new() for</strong>:</p>\n<ul>\n<li>Small/unknown sizes or prototyping.</li>\n</ul>\n<p>🚀 <strong>Avoid unnecessary reallocations</strong>—they dominate runtime for large Vecs.</p>\n<h2>Real-World Impact</h2>\n<p>In the regex crate, pre-allocation is used for capture groups to avoid reallocations during pattern matching.</p>\n<p><strong>Try This</strong>: What happens if you pre-allocate too much (e.g., with_capacity(1000) but only use 10 elements)?</p>\n<p><strong>Answer</strong>: Wasted memory. Use shrink_to_fit() to release unused capacity.</p>\n",
    "author": "mayo",
    "category": "rust",
    "tags": [
      "rust",
      "collections"
    ],
    "readingTime": "2 min",
    "locale": "en",
    "seo": {
      "title": "What is the performance impact of using Vec::push() in a loop vs. pre-allocating with Vec::with_capacity()?",
      "description": "Analyzing performance differences between Vec::push() in loops versus pre-allocating with Vec::with_capacity(), covering memory reallocation costs and optimization strategies",
      "keywords": [
        "rust",
        "collections"
      ]
    },
    "headings": [
      {
        "id": "key-performance-differences",
        "text": "Key Performance Differences",
        "level": 2
      },
      {
        "id": "why-reallocations-are-costly",
        "text": "Why Reallocations Are Costly",
        "level": 2
      },
      {
        "id": "growth-strategy",
        "text": "Growth Strategy",
        "level": 3
      },
      {
        "id": "example-for-10-elements",
        "text": "Example for 10 Elements",
        "level": 3
      },
      {
        "id": "benchmark-comparison",
        "text": "Benchmark Comparison",
        "level": 2
      },
      {
        "id": "typical-results",
        "text": "Typical Results",
        "level": 3
      },
      {
        "id": "when-to-pre-allocate",
        "text": "When to Pre-Allocate",
        "level": 2
      },
      {
        "id": "when-vecnew-is-acceptable",
        "text": "When Vec::new() is Acceptable",
        "level": 2
      },
      {
        "id": "advanced-optimization-extend",
        "text": "Advanced Optimization: extend()",
        "level": 2
      },
      {
        "id": "key-takeaways",
        "text": "Key Takeaways",
        "level": 2
      },
      {
        "id": "real-world-impact",
        "text": "Real-World Impact",
        "level": 2
      }
    ]
  },
  {
    "id": "collect-method-rust",
    "slug": "collect-method-rust",
    "title": "Rust's collect() Magic: Turning Iterators into Vecs, HashMaps, and Strings!",
    "date": "2025-07-16",
    "excerpt": "Collections (like Vec), iterators (into_iter, collect), and related concepts",
    "content": "`collect()` is a method that converts an iterator into a collection. It relies on Rust’s `FromIterator` trait, which defines how to build a type from an iterator.\n\n## Key Mechanics\n\n- **Lazy Evaluation**: Iterators are lazy—`collect()` triggers consumption.\n- **Type Inference**: The target collection type must be specified (or inferable).\n- **Flexibility**: Works with any type implementing `FromIterator`.\n\n## Converting to Common Collections\n\n### 1. Iterator → `Vec<T>`\n\n```rust\nlet numbers = 1..5;                 // Range (implements Iterator)\nlet vec: Vec<_> = numbers.collect(); // Vec<i32> == [1, 2, 3, 4]\n```\n\n**Note**: `Vec<_>` lets Rust infer the inner type (`i32` here).\n\n### 2. Iterator → `HashMap<K, V>`\n\nRequires tuples of `(K, V)` pairs:\n```rust\nuse std::collections::HashMap;\n\nlet pairs = vec![(\"a\", 1), (\"b\", 2)].into_iter();\nlet map: HashMap<_, _> = pairs.collect(); // HashMap<&str, i32>\n```\n\n**Alternate Syntax** (with turbofish):\n```rust\nlet map = pairs.collect::<HashMap<&str, i32>>();\n```\n\n### 3. Iterator → `String`\n\nCombine characters or strings:\n```rust\nlet chars = ['R', 'u', 's', 't'].iter();\nlet s: String = chars.collect(); // \"Rust\"\n\n// Or concatenate strings:\nlet words = vec![\"Hello\", \" \", \"World\"].into_iter();\nlet s: String = words.collect(); // \"Hello World\"\n```\n\n## How `collect()` Works Internally\n\n- **`FromIterator` Trait**:\n  Collections implement this to define their construction logic:\n  ```rust\n  pub trait FromIterator<A> {\n      fn from_iter<T>(iter: T) -> Self\n      where\n          T: IntoIterator<Item = A>;\n  }\n  ```\n\n- **Compiler Magic**: Rust infers the target type based on context or annotations.\n\n## Advanced Uses\n\n### Conditional Collection\n\nConvert only even numbers to a `Vec`:\n```rust\nlet evens: Vec<_> = (1..10).filter(|x| x % 2 == 0).collect(); // [2, 4, 6, 8]\n```\n\n### Custom Types\n\nImplement `FromIterator` for your types:\n```rust\nstruct MyCollection(Vec<i32>);\n\nimpl FromIterator<i32> for MyCollection {\n    fn from_iter<I: IntoIterator<Item = i32>>(iter: I) -> Self {\n        MyCollection(iter.into_iter().collect())\n    }\n}\n\nlet nums = MyCollection::from_iter(1..=3); // MyCollection([1, 2, 3])\n```\n\n## Performance Notes\n\n- **Pre-allocated Collections**: Use `with_capacity` + `extend()` if size is known:\n  ```rust\n  let mut vec = Vec::with_capacity(100);\n  vec.extend(1..=100);  // Faster than collect() for large iterables\n  ```\n\n- **Zero-Cost Abstractions**: `collect()` is optimized (e.g., `Vec` from ranges avoids bounds checks).\n\n## Common Pitfalls\n\n- **Ambiguous Types**:\n  Fails if Rust can’t infer the target:\n  ```rust\n  let nums = vec![1, 2].into_iter().collect(); // ERROR: type annotations needed\n  ```\n\n- **Ownership Issues**:\n  Consumes the iterator:\n  ```rust\n  let iter = vec![1, 2].into_iter();\n  let _ = iter.collect::<Vec<_>>();\n  // iter.next(); // ERROR: iter consumed by collect()\n  ```\n\n## Key Takeaways\n\n✅ Use `collect()` to materialize iterators into:\n- `Vec`, `HashMap`, `String`, or any `FromIterator` type.\n✅ Specify the type (e.g., `let v: Vec<_> = ...`).\n🚀 Optimize with `with_capacity` for large collections.\n\n**Real-World Example**:\n`serde_json::from_str` often chains with `collect()` to build complex structures:\n```rust\nlet data: Vec<u8> = \"123\".bytes().collect(); // [49, 50, 51] (ASCII values)\n```",
    "contentHtml": "<p><code>collect()</code> is a method that converts an iterator into a collection. It relies on Rust’s <code>FromIterator</code> trait, which defines how to build a type from an iterator.</p>\n<h2>Key Mechanics</h2>\n<ul>\n<li><strong>Lazy Evaluation</strong>: Iterators are lazy—<code>collect()</code> triggers consumption.</li>\n<li><strong>Type Inference</strong>: The target collection type must be specified (or inferable).</li>\n<li><strong>Flexibility</strong>: Works with any type implementing <code>FromIterator</code>.</li>\n</ul>\n<h2>Converting to Common Collections</h2>\n<h3>1. Iterator → <code>Vec&lt;T&gt;</code></h3>\n<pre><code class=\"language-rust\">let numbers = 1..5;                 // Range (implements Iterator)\nlet vec: Vec&lt;_&gt; = numbers.collect(); // Vec&lt;i32&gt; == [1, 2, 3, 4]\n</code></pre>\n<p><strong>Note</strong>: <code>Vec&lt;_&gt;</code> lets Rust infer the inner type (<code>i32</code> here).</p>\n<h3>2. Iterator → <code>HashMap&lt;K, V&gt;</code></h3>\n<p>Requires tuples of <code>(K, V)</code> pairs:</p>\n<pre><code class=\"language-rust\">use std::collections::HashMap;\n\nlet pairs = vec![(&quot;a&quot;, 1), (&quot;b&quot;, 2)].into_iter();\nlet map: HashMap&lt;_, _&gt; = pairs.collect(); // HashMap&lt;&amp;str, i32&gt;\n</code></pre>\n<p><strong>Alternate Syntax</strong> (with turbofish):</p>\n<pre><code class=\"language-rust\">let map = pairs.collect::&lt;HashMap&lt;&amp;str, i32&gt;&gt;();\n</code></pre>\n<h3>3. Iterator → <code>String</code></h3>\n<p>Combine characters or strings:</p>\n<pre><code class=\"language-rust\">let chars = [&#39;R&#39;, &#39;u&#39;, &#39;s&#39;, &#39;t&#39;].iter();\nlet s: String = chars.collect(); // &quot;Rust&quot;\n\n// Or concatenate strings:\nlet words = vec![&quot;Hello&quot;, &quot; &quot;, &quot;World&quot;].into_iter();\nlet s: String = words.collect(); // &quot;Hello World&quot;\n</code></pre>\n<h2>How <code>collect()</code> Works Internally</h2>\n<ul>\n<li><p><strong><code>FromIterator</code> Trait</strong>:\nCollections implement this to define their construction logic:</p>\n<pre><code class=\"language-rust\">pub trait FromIterator&lt;A&gt; {\n    fn from_iter&lt;T&gt;(iter: T) -&gt; Self\n    where\n        T: IntoIterator&lt;Item = A&gt;;\n}\n</code></pre>\n</li>\n<li><p><strong>Compiler Magic</strong>: Rust infers the target type based on context or annotations.</p>\n</li>\n</ul>\n<h2>Advanced Uses</h2>\n<h3>Conditional Collection</h3>\n<p>Convert only even numbers to a <code>Vec</code>:</p>\n<pre><code class=\"language-rust\">let evens: Vec&lt;_&gt; = (1..10).filter(|x| x % 2 == 0).collect(); // [2, 4, 6, 8]\n</code></pre>\n<h3>Custom Types</h3>\n<p>Implement <code>FromIterator</code> for your types:</p>\n<pre><code class=\"language-rust\">struct MyCollection(Vec&lt;i32&gt;);\n\nimpl FromIterator&lt;i32&gt; for MyCollection {\n    fn from_iter&lt;I: IntoIterator&lt;Item = i32&gt;&gt;(iter: I) -&gt; Self {\n        MyCollection(iter.into_iter().collect())\n    }\n}\n\nlet nums = MyCollection::from_iter(1..=3); // MyCollection([1, 2, 3])\n</code></pre>\n<h2>Performance Notes</h2>\n<ul>\n<li><p><strong>Pre-allocated Collections</strong>: Use <code>with_capacity</code> + <code>extend()</code> if size is known:</p>\n<pre><code class=\"language-rust\">let mut vec = Vec::with_capacity(100);\nvec.extend(1..=100);  // Faster than collect() for large iterables\n</code></pre>\n</li>\n<li><p><strong>Zero-Cost Abstractions</strong>: <code>collect()</code> is optimized (e.g., <code>Vec</code> from ranges avoids bounds checks).</p>\n</li>\n</ul>\n<h2>Common Pitfalls</h2>\n<ul>\n<li><p><strong>Ambiguous Types</strong>:\nFails if Rust can’t infer the target:</p>\n<pre><code class=\"language-rust\">let nums = vec![1, 2].into_iter().collect(); // ERROR: type annotations needed\n</code></pre>\n</li>\n<li><p><strong>Ownership Issues</strong>:\nConsumes the iterator:</p>\n<pre><code class=\"language-rust\">let iter = vec![1, 2].into_iter();\nlet _ = iter.collect::&lt;Vec&lt;_&gt;&gt;();\n// iter.next(); // ERROR: iter consumed by collect()\n</code></pre>\n</li>\n</ul>\n<h2>Key Takeaways</h2>\n<p>✅ Use <code>collect()</code> to materialize iterators into:</p>\n<ul>\n<li><code>Vec</code>, <code>HashMap</code>, <code>String</code>, or any <code>FromIterator</code> type.\n✅ Specify the type (e.g., <code>let v: Vec&lt;_&gt; = ...</code>).\n🚀 Optimize with <code>with_capacity</code> for large collections.</li>\n</ul>\n<p><strong>Real-World Example</strong>:\n<code>serde_json::from_str</code> often chains with <code>collect()</code> to build complex structures:</p>\n<pre><code class=\"language-rust\">let data: Vec&lt;u8&gt; = &quot;123&quot;.bytes().collect(); // [49, 50, 51] (ASCII values)\n</code></pre>\n",
    "author": "mayo",
    "category": "rust",
    "tags": [
      "rust",
      "iterators",
      "collections"
    ],
    "readingTime": "3 min",
    "locale": "en",
    "seo": {
      "title": "Rust's collect() Magic: Turning Iterators into Vecs, HashMaps, and Strings!",
      "description": "Collections (like Vec), iterators (into_iter, collect), and related concepts",
      "keywords": [
        "rust",
        "iterators",
        "collections"
      ]
    },
    "headings": [
      {
        "id": "key-mechanics",
        "text": "Key Mechanics",
        "level": 2
      },
      {
        "id": "converting-to-common-collections",
        "text": "Converting to Common Collections",
        "level": 2
      },
      {
        "id": "1-iterator-veclesstgreater",
        "text": "1. Iterator → `Vec<T>`",
        "level": 3
      },
      {
        "id": "2-iterator-hashmaplessk-vgreater",
        "text": "2. Iterator → `HashMap<K, V>`",
        "level": 3
      },
      {
        "id": "3-iterator-string",
        "text": "3. Iterator → `String`",
        "level": 3
      },
      {
        "id": "how-collect-works-internally",
        "text": "How `collect()` Works Internally",
        "level": 2
      },
      {
        "id": "advanced-uses",
        "text": "Advanced Uses",
        "level": 2
      },
      {
        "id": "conditional-collection",
        "text": "Conditional Collection",
        "level": 3
      },
      {
        "id": "custom-types",
        "text": "Custom Types",
        "level": 3
      },
      {
        "id": "performance-notes",
        "text": "Performance Notes",
        "level": 2
      },
      {
        "id": "common-pitfalls",
        "text": "Common Pitfalls",
        "level": 2
      },
      {
        "id": "key-takeaways",
        "text": "Key Takeaways",
        "level": 2
      }
    ]
  },
  {
    "id": "storing-closures-in-structs",
    "slug": "storing-closures-in-structs",
    "title": "How storing a closure in a struct?",
    "date": "2025-07-14",
    "excerpt": "Storing closures in structs using generic parameters, trait objects, and lifetime annotations with Fn, FnMut, and FnOnce bounds",
    "content": "Storing a closure in a struct requires specifying trait bounds (Fn, FnMut, FnOnce) and potentially lifetimes if the closure captures references. Here's how to do it:\n\n## 1. Generic Struct (Static Dispatch)\n\nUse a generic type parameter with Fn/FnMut/FnOnce bounds. Ideal for fixed closure types.\n\n### Example: Fn Trait\n\n```rust\nstruct Processor<F>\nwhere\n    F: Fn(i32) -> i32, // Trait bound for closure type\n{\n    operation: F,\n    value: i32,\n}\n\nimpl<F> Processor<F>\nwhere\n    F: Fn(i32) -> i32,\n{\n    fn run(&self) -> i32 {\n        (self.operation)(self.value)\n    }\n}\n\nfn main() {\n    let adder = Processor {\n        operation: |x| x + 5, // Closure captured by value\n        value: 10,\n    };\n    println!(\"{}\", adder.run()); // 15\n}\n```\n\n### Key Points\n- **Zero runtime overhead**: Monomorphized for each closure type.\n- **Fixed closure type**: Can't store different closures in the same struct.\n\n## 2. Trait Object (Dynamic Dispatch)\n\nUse Box<dyn Fn...> to store heterogeneous closures. Requires heap allocation.\n\n### Example: Box<dyn Fn>\n\n```rust\nstruct DynamicProcessor<'a> {\n    operation: Box<dyn Fn(i32) -> i32 + 'a>, // Trait object with optional lifetime\n    value: i32,\n}\n\nimpl<'a> DynamicProcessor<'a> {\n    fn run(&self) -> i32 {\n        (self.operation)(self.value)\n    }\n}\n\nfn main() {\n    let multiplier = 2;\n    let processor = DynamicProcessor {\n        operation: Box::new(|x| x * multiplier), // Captures `multiplier`\n        value: 10,\n    };\n    println!(\"{}\", processor.run()); // 20\n}\n```\n\n### Key Points\n- **Lifetime annotation**: Required if the closure captures references (e.g., Box<dyn Fn() -> &str + 'a>).\n- **Flexibility**: Can store any closure matching the trait.\n- **Overhead**: Vtable lookup (dynamic dispatch).\n\n## 3. Capturing References (Lifetimes)\n\nIf the closure captures references, the struct must declare lifetimes to ensure validity:\n\n```rust\nstruct RefProcessor<'a, F>\nwhere\n    F: Fn(&'a str) -> &'a str, // Lifetime tied to input/output\n{\n    process: F,\n    data: &'a str,\n}\n\nfn main() {\n    let data = \"hello\";\n    let processor = RefProcessor {\n        process: |s| &s[1..], // Captures nothing, but input/output tied to `data`\n        data,\n    };\n    println!(\"{}\", (processor.process)(processor.data)); // \"ello\"\n}\n```\n\n## When to Use Each\n\n| Approach | Use Case | Trade-Offs |\n|----------|----------|------------|\n| Generic (impl Fn) | High performance, fixed closure type | Less flexible, binary bloat |\n| Trait Object | Dynamic behavior, multiple closures | Runtime overhead, heap allocation |\n| Lifetime Annotated | Closures capturing references | Ensures safety, adds complexity |\n\n## Key Takeaways\n\n✅ Generic structs: Best for performance and static dispatch.\n✅ Trait objects: Use when storing heterogeneous closures.\n✅ Lifetimes: Required if the closure captures references.\n\n**Try This**: What happens if a closure captures a &mut reference and is stored in a struct?\n\n**Answer**: The struct must be mut, and the closure must implement FnMut!",
    "contentHtml": "<p>Storing a closure in a struct requires specifying trait bounds (Fn, FnMut, FnOnce) and potentially lifetimes if the closure captures references. Here&#39;s how to do it:</p>\n<h2>1. Generic Struct (Static Dispatch)</h2>\n<p>Use a generic type parameter with Fn/FnMut/FnOnce bounds. Ideal for fixed closure types.</p>\n<h3>Example: Fn Trait</h3>\n<pre><code class=\"language-rust\">struct Processor&lt;F&gt;\nwhere\n    F: Fn(i32) -&gt; i32, // Trait bound for closure type\n{\n    operation: F,\n    value: i32,\n}\n\nimpl&lt;F&gt; Processor&lt;F&gt;\nwhere\n    F: Fn(i32) -&gt; i32,\n{\n    fn run(&amp;self) -&gt; i32 {\n        (self.operation)(self.value)\n    }\n}\n\nfn main() {\n    let adder = Processor {\n        operation: |x| x + 5, // Closure captured by value\n        value: 10,\n    };\n    println!(&quot;{}&quot;, adder.run()); // 15\n}\n</code></pre>\n<h3>Key Points</h3>\n<ul>\n<li><strong>Zero runtime overhead</strong>: Monomorphized for each closure type.</li>\n<li><strong>Fixed closure type</strong>: Can&#39;t store different closures in the same struct.</li>\n</ul>\n<h2>2. Trait Object (Dynamic Dispatch)</h2>\n<p>Use Box<dyn Fn...> to store heterogeneous closures. Requires heap allocation.</p>\n<h3>Example: Box<dyn Fn></h3>\n<pre><code class=\"language-rust\">struct DynamicProcessor&lt;&#39;a&gt; {\n    operation: Box&lt;dyn Fn(i32) -&gt; i32 + &#39;a&gt;, // Trait object with optional lifetime\n    value: i32,\n}\n\nimpl&lt;&#39;a&gt; DynamicProcessor&lt;&#39;a&gt; {\n    fn run(&amp;self) -&gt; i32 {\n        (self.operation)(self.value)\n    }\n}\n\nfn main() {\n    let multiplier = 2;\n    let processor = DynamicProcessor {\n        operation: Box::new(|x| x * multiplier), // Captures `multiplier`\n        value: 10,\n    };\n    println!(&quot;{}&quot;, processor.run()); // 20\n}\n</code></pre>\n<h3>Key Points</h3>\n<ul>\n<li><strong>Lifetime annotation</strong>: Required if the closure captures references (e.g., Box&lt;dyn Fn() -&gt; &amp;str + &#39;a&gt;).</li>\n<li><strong>Flexibility</strong>: Can store any closure matching the trait.</li>\n<li><strong>Overhead</strong>: Vtable lookup (dynamic dispatch).</li>\n</ul>\n<h2>3. Capturing References (Lifetimes)</h2>\n<p>If the closure captures references, the struct must declare lifetimes to ensure validity:</p>\n<pre><code class=\"language-rust\">struct RefProcessor&lt;&#39;a, F&gt;\nwhere\n    F: Fn(&amp;&#39;a str) -&gt; &amp;&#39;a str, // Lifetime tied to input/output\n{\n    process: F,\n    data: &amp;&#39;a str,\n}\n\nfn main() {\n    let data = &quot;hello&quot;;\n    let processor = RefProcessor {\n        process: |s| &amp;s[1..], // Captures nothing, but input/output tied to `data`\n        data,\n    };\n    println!(&quot;{}&quot;, (processor.process)(processor.data)); // &quot;ello&quot;\n}\n</code></pre>\n<h2>When to Use Each</h2>\n<table>\n<thead>\n<tr>\n<th>Approach</th>\n<th>Use Case</th>\n<th>Trade-Offs</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Generic (impl Fn)</td>\n<td>High performance, fixed closure type</td>\n<td>Less flexible, binary bloat</td>\n</tr>\n<tr>\n<td>Trait Object</td>\n<td>Dynamic behavior, multiple closures</td>\n<td>Runtime overhead, heap allocation</td>\n</tr>\n<tr>\n<td>Lifetime Annotated</td>\n<td>Closures capturing references</td>\n<td>Ensures safety, adds complexity</td>\n</tr>\n</tbody></table>\n<h2>Key Takeaways</h2>\n<p>✅ Generic structs: Best for performance and static dispatch.\n✅ Trait objects: Use when storing heterogeneous closures.\n✅ Lifetimes: Required if the closure captures references.</p>\n<p><strong>Try This</strong>: What happens if a closure captures a &amp;mut reference and is stored in a struct?</p>\n<p><strong>Answer</strong>: The struct must be mut, and the closure must implement FnMut!</p>\n",
    "author": "mayo",
    "category": "rust",
    "tags": [
      "rust",
      "closures"
    ],
    "readingTime": "3 min",
    "locale": "en",
    "seo": {
      "title": "How storing a closure in a struct?",
      "description": "Storing closures in structs using generic parameters, trait objects, and lifetime annotations with Fn, FnMut, and FnOnce bounds",
      "keywords": [
        "rust",
        "closures"
      ]
    },
    "headings": [
      {
        "id": "1-generic-struct-static-dispatch",
        "text": "1. Generic Struct (Static Dispatch)",
        "level": 2
      },
      {
        "id": "example-fn-trait",
        "text": "Example: Fn Trait",
        "level": 3
      },
      {
        "id": "key-points",
        "text": "Key Points",
        "level": 3
      },
      {
        "id": "2-trait-object-dynamic-dispatch",
        "text": "2. Trait Object (Dynamic Dispatch)",
        "level": 2
      },
      {
        "id": "example-boxlessdyn-fngreater",
        "text": "Example: Box<dyn Fn>",
        "level": 3
      },
      {
        "id": "key-points",
        "text": "Key Points",
        "level": 3
      },
      {
        "id": "3-capturing-references-lifetimes",
        "text": "3. Capturing References (Lifetimes)",
        "level": 2
      },
      {
        "id": "when-to-use-each",
        "text": "When to Use Each",
        "level": 2
      },
      {
        "id": "key-takeaways",
        "text": "Key Takeaways",
        "level": 2
      }
    ]
  },
  {
    "id": "into-iter-vs-iter-ownership",
    "slug": "into-iter-vs-iter-ownership",
    "title": "Implications of iterating over a Vec with .into_iter() instead of .iter()",
    "date": "2025-07-14",
    "excerpt": "Understanding the differences between .into_iter() and .iter() when iterating over Vec, covering ownership implications and performance considerations",
    "content": "## Key Differences\n\n| .into_iter() | .iter() |\n|--------------|---------|\n| Consumes the Vec (takes ownership). | Borrows the Vec immutably. |\n| Yields owned values (T). | Yields references (&T). |\n| Original Vec is unusable afterward. | Original Vec remains intact. |\n\n## When to Use .into_iter()\n\n### Need Ownership of Elements\n\nUseful when you want to move elements out of the Vec (e.g., transferring to another collection):\n\n```rust\nlet vec = vec![String::from(\"a\"), String::from(\"b\")];\nlet new_vec: Vec<String> = vec.into_iter().collect();  // `vec` is consumed\n// println!(\"{:?}\", vec);  // ERROR: `vec` moved\n```\n\n### Destructive Operations\n\nFor operations that destroy the Vec (e.g., sorting and deduplicating in one pass):\n\n```rust\nlet mut vec = vec![3, 1, 2, 1];\nvec = vec.into_iter().unique().sorted().collect();  // Destructive but efficient\n```\n\n### Performance Optimization\n\nAvoids cloning when working with owned data (e.g., Vec<String>):\n\n```rust\nlet vec = vec![String::from(\"rust\")];\nfor s in vec.into_iter() {  // No clone, moves `String`\n    println!(\"{}\", s);\n}\n```\n\n## Ownership Implications\n\n### After .into_iter(), the original Vec is moved and can't be used:\n\n```rust\nlet vec = vec![1, 2, 3];\nlet iter = vec.into_iter();  // `vec` is moved here\n// println!(\"{:?}\", vec);    // ERROR: value borrowed after move\n```\n\n### Works with non-Copy types (e.g., String, Box<T>):\n\n```rust\nlet vec = vec![String::from(\"hello\")];\nlet s = vec.into_iter().next().unwrap();  // Moves the `String` out\n```\n\n## Comparison with .iter()\n\n| Scenario | .into_iter() | .iter() |\n|----------|--------------|---------|\n| Need to reuse the Vec | ❌ No | ✅ Yes |\n| Modify elements | ❌ No (consumed) | ✅ Yes (iter_mut()) |\n| Avoid cloning owned data | ✅ Yes | ❌ No (requires clone()) |\n\n## Real-World Examples\n\n### Transferring Data\n\nMoving a Vec into a function that takes ownership:\n\n```rust\nfn process(data: impl Iterator<Item = String>) { /* ... */ }\nlet vec = vec![String::from(\"a\"), String::from(\"b\")];\nprocess(vec.into_iter());  // Efficient, no clones\n```\n\n### Destructive Filtering\n\nRemove elements while iterating:\n\n```rust\nlet vec = vec![1, 2, 3, 4];\nlet evens: Vec<_> = vec.into_iter().filter(|x| x % 2 == 0).collect();\n```\n\n## Performance Considerations\n\n- **Zero-cost for primitives (i32, bool)**: `.into_iter()` and `.iter()` compile to the same assembly if `T: Copy`.\n- **Avoids allocations** when chaining adapters (e.g., `.map().filter()`).\n\n## Key Takeaways\n\n✅ **Use .into_iter() to**:\n- Move elements out of a Vec.\n- Optimize performance with owned data.\n- Destructively transform collections.\n\n🚫 **Avoid if you need to**:\n- Reuse the Vec after iteration.\n- Share references across threads (`&T` is Sync; `T` might not be).\n\n**Try This**: What happens if you call `.into_iter()` on a Vec and then try to use the original Vec in a parallel iterator (e.g., rayon::iter)?\n\n**Answer**: Compile-time error! The Vec is already consumed. Use `.par_iter()` instead for parallel read-only access.",
    "contentHtml": "<h2>Key Differences</h2>\n<table>\n<thead>\n<tr>\n<th>.into_iter()</th>\n<th>.iter()</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Consumes the Vec (takes ownership).</td>\n<td>Borrows the Vec immutably.</td>\n</tr>\n<tr>\n<td>Yields owned values (T).</td>\n<td>Yields references (&amp;T).</td>\n</tr>\n<tr>\n<td>Original Vec is unusable afterward.</td>\n<td>Original Vec remains intact.</td>\n</tr>\n</tbody></table>\n<h2>When to Use .into_iter()</h2>\n<h3>Need Ownership of Elements</h3>\n<p>Useful when you want to move elements out of the Vec (e.g., transferring to another collection):</p>\n<pre><code class=\"language-rust\">let vec = vec![String::from(&quot;a&quot;), String::from(&quot;b&quot;)];\nlet new_vec: Vec&lt;String&gt; = vec.into_iter().collect();  // `vec` is consumed\n// println!(&quot;{:?}&quot;, vec);  // ERROR: `vec` moved\n</code></pre>\n<h3>Destructive Operations</h3>\n<p>For operations that destroy the Vec (e.g., sorting and deduplicating in one pass):</p>\n<pre><code class=\"language-rust\">let mut vec = vec![3, 1, 2, 1];\nvec = vec.into_iter().unique().sorted().collect();  // Destructive but efficient\n</code></pre>\n<h3>Performance Optimization</h3>\n<p>Avoids cloning when working with owned data (e.g., Vec<String>):</p>\n<pre><code class=\"language-rust\">let vec = vec![String::from(&quot;rust&quot;)];\nfor s in vec.into_iter() {  // No clone, moves `String`\n    println!(&quot;{}&quot;, s);\n}\n</code></pre>\n<h2>Ownership Implications</h2>\n<h3>After .into_iter(), the original Vec is moved and can&#39;t be used:</h3>\n<pre><code class=\"language-rust\">let vec = vec![1, 2, 3];\nlet iter = vec.into_iter();  // `vec` is moved here\n// println!(&quot;{:?}&quot;, vec);    // ERROR: value borrowed after move\n</code></pre>\n<h3>Works with non-Copy types (e.g., String, Box<T>):</h3>\n<pre><code class=\"language-rust\">let vec = vec![String::from(&quot;hello&quot;)];\nlet s = vec.into_iter().next().unwrap();  // Moves the `String` out\n</code></pre>\n<h2>Comparison with .iter()</h2>\n<table>\n<thead>\n<tr>\n<th>Scenario</th>\n<th>.into_iter()</th>\n<th>.iter()</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Need to reuse the Vec</td>\n<td>❌ No</td>\n<td>✅ Yes</td>\n</tr>\n<tr>\n<td>Modify elements</td>\n<td>❌ No (consumed)</td>\n<td>✅ Yes (iter_mut())</td>\n</tr>\n<tr>\n<td>Avoid cloning owned data</td>\n<td>✅ Yes</td>\n<td>❌ No (requires clone())</td>\n</tr>\n</tbody></table>\n<h2>Real-World Examples</h2>\n<h3>Transferring Data</h3>\n<p>Moving a Vec into a function that takes ownership:</p>\n<pre><code class=\"language-rust\">fn process(data: impl Iterator&lt;Item = String&gt;) { /* ... */ }\nlet vec = vec![String::from(&quot;a&quot;), String::from(&quot;b&quot;)];\nprocess(vec.into_iter());  // Efficient, no clones\n</code></pre>\n<h3>Destructive Filtering</h3>\n<p>Remove elements while iterating:</p>\n<pre><code class=\"language-rust\">let vec = vec![1, 2, 3, 4];\nlet evens: Vec&lt;_&gt; = vec.into_iter().filter(|x| x % 2 == 0).collect();\n</code></pre>\n<h2>Performance Considerations</h2>\n<ul>\n<li><strong>Zero-cost for primitives (i32, bool)</strong>: <code>.into_iter()</code> and <code>.iter()</code> compile to the same assembly if <code>T: Copy</code>.</li>\n<li><strong>Avoids allocations</strong> when chaining adapters (e.g., <code>.map().filter()</code>).</li>\n</ul>\n<h2>Key Takeaways</h2>\n<p>✅ <strong>Use .into_iter() to</strong>:</p>\n<ul>\n<li>Move elements out of a Vec.</li>\n<li>Optimize performance with owned data.</li>\n<li>Destructively transform collections.</li>\n</ul>\n<p>🚫 <strong>Avoid if you need to</strong>:</p>\n<ul>\n<li>Reuse the Vec after iteration.</li>\n<li>Share references across threads (<code>&amp;T</code> is Sync; <code>T</code> might not be).</li>\n</ul>\n<p><strong>Try This</strong>: What happens if you call <code>.into_iter()</code> on a Vec and then try to use the original Vec in a parallel iterator (e.g., rayon::iter)?</p>\n<p><strong>Answer</strong>: Compile-time error! The Vec is already consumed. Use <code>.par_iter()</code> instead for parallel read-only access.</p>\n",
    "author": "mayo",
    "category": "rust",
    "tags": [
      "rust",
      "iterators",
      "collections"
    ],
    "readingTime": "3 min",
    "locale": "en",
    "seo": {
      "title": "Implications of iterating over a Vec with .into_iter() instead of .iter()",
      "description": "Understanding the differences between .into_iter() and .iter() when iterating over Vec, covering ownership implications and performance considerations",
      "keywords": [
        "rust",
        "iterators",
        "collections"
      ]
    },
    "headings": [
      {
        "id": "key-differences",
        "text": "Key Differences",
        "level": 2
      },
      {
        "id": "when-to-use-intoiter",
        "text": "When to Use .into_iter()",
        "level": 2
      },
      {
        "id": "need-ownership-of-elements",
        "text": "Need Ownership of Elements",
        "level": 3
      },
      {
        "id": "destructive-operations",
        "text": "Destructive Operations",
        "level": 3
      },
      {
        "id": "performance-optimization",
        "text": "Performance Optimization",
        "level": 3
      },
      {
        "id": "ownership-implications",
        "text": "Ownership Implications",
        "level": 2
      },
      {
        "id": "after-intoiter-the-original-vec-is-moved-and-cant-be-used",
        "text": "After .into_iter(), the original Vec is moved and can't be used:",
        "level": 3
      },
      {
        "id": "works-with-non-copy-types-eg-string-boxlesstgreater",
        "text": "Works with non-Copy types (e.g., String, Box<T>):",
        "level": 3
      },
      {
        "id": "comparison-with-iter",
        "text": "Comparison with .iter()",
        "level": 2
      },
      {
        "id": "real-world-examples",
        "text": "Real-World Examples",
        "level": 2
      },
      {
        "id": "transferring-data",
        "text": "Transferring Data",
        "level": 3
      },
      {
        "id": "destructive-filtering",
        "text": "Destructive Filtering",
        "level": 3
      },
      {
        "id": "performance-considerations",
        "text": "Performance Considerations",
        "level": 2
      },
      {
        "id": "key-takeaways",
        "text": "Key Takeaways",
        "level": 2
      }
    ]
  },
  {
    "id": "higher-order-functions-rust",
    "slug": "higher-order-functions-rust",
    "title": "Rust's Higher-Order Functions: Powering Flexible Closures",
    "date": "2025-07-12",
    "excerpt": "Exploring higher-order functions in Rust for functional programming patterns",
    "content": "Higher-order functions (HOFs) in Rust—functions that accept or return other functions/closures—leverage Rust’s closure system, trait bounds (`Fn`, `FnMut`, `FnOnce`), and ownership model to enable powerful functional programming patterns like callbacks and decorators. I’ll explain how HOFs work in Rust, their mechanics, and practical use cases.\n\n## What are Higher-Order Functions?\n\nHOFs either:\n- Accept one or more functions/closures as arguments, or\n- Return a function/closure.\n\nRust’s support for HOFs is built on its closure system, which integrates seamlessly with ownership, traits, and lifetimes.\n\n## Example: Function Returning a Closure\n\nA function that returns a configurable \"adder\" closure:\n\n```rust\nfn make_adder(x: i32) -> impl Fn(i32) -> i32 {\n    // `move` transfers ownership of `x` into the closure\n    move |y| x + y\n}\n\nfn main() {\n    let add_five = make_adder(5); // Returns a closure that adds 5\n    println!(\"{}\", add_five(3)); // 8\n}\n```\n\n### Key Mechanics\n- **Closure Capture**: The `move` keyword ensures the closure owns `x`, preventing lifetime issues after `make_adder` exits. Without `move`, borrowing `x` would cause a compile error due to `x`’s scope ending.\n- **Return Type**: `impl Fn(i32) -> i32` specifies the closure implements the `Fn` trait. Each closure has a unique anonymous type, so `impl Trait` is used to abstract it.\n\n## Advanced Example: Conditional Closure Return\n\nFor dynamic behavior, return a `Box<dyn Fn>` to support different closures at runtime:\n\n```rust\nfn math_op(op: &str) -> Box<dyn Fn(i32, i32) -> i32> {\n    match op {\n        \"add\" => Box::new(|x, y| x + y),\n        \"mul\" => Box::new(|x, y| x * y),\n        _ => panic!(\"Unsupported operation\"),\n    }\n}\n\nfn main() {\n    let add = math_op(\"add\");\n    let mul = math_op(\"mul\");\n    println!(\"{} {}\", add(2, 3), mul(2, 3)); // 5 6\n}\n```\n\nThis uses dynamic dispatch to handle varying closure types, ideal for plugin-like systems.\n\n## Use Cases for HOFs\n\n1. **Iterator Adaptors**:\n   Closures power iterator methods like `map`, `filter`, and `fold`:\n   ```rust\n   let doubled: Vec<_> = vec![1, 2, 3].iter().map(|x| x * 2).collect(); // [2, 4, 6]\n   ```\n\n2. **Decorators**:\n   Wrap functions with additional logic (e.g., logging, retries):\n   ```rust\n   fn log_call<F: Fn(i32) -> i32>(f: F) -> impl Fn(i32) -> i32 {\n       move |x| {\n           println!(\"Calling with {}\", x);\n           f(x)\n       }\n   }\n   ```\n\n3. **Stateful Logic**:\n   Use `FnMut` for closures that mutate captured state (see previous answers on stateful closures).\n\n## Key Takeaways\n\n✅ **HOFs enable flexible, reusable patterns** by treating functions as first-class values.  \n✅ **Use `impl Fn`** for zero-cost static dispatch in performance-critical code.  \n✅ **Use `Box<dyn Fn>`** for dynamic behavior with multiple closure types.  \n🚀 **Use `move`** to ensure closures own captured data when returned.\n\n**Real-World Example**: HOFs are central to Rust’s iterator API (`map`, `filter`) and async frameworks like `tokio`, where closures define task behavior.\n\n**Experiment**: Modify `make_adder` to return a closure that multiplies instead.  \n**Answer**: The compiler accepts it seamlessly, as both closures implement `Fn(i32) -> i32`, maintaining type consistency.",
    "contentHtml": "<p>Higher-order functions (HOFs) in Rust—functions that accept or return other functions/closures—leverage Rust’s closure system, trait bounds (<code>Fn</code>, <code>FnMut</code>, <code>FnOnce</code>), and ownership model to enable powerful functional programming patterns like callbacks and decorators. I’ll explain how HOFs work in Rust, their mechanics, and practical use cases.</p>\n<h2>What are Higher-Order Functions?</h2>\n<p>HOFs either:</p>\n<ul>\n<li>Accept one or more functions/closures as arguments, or</li>\n<li>Return a function/closure.</li>\n</ul>\n<p>Rust’s support for HOFs is built on its closure system, which integrates seamlessly with ownership, traits, and lifetimes.</p>\n<h2>Example: Function Returning a Closure</h2>\n<p>A function that returns a configurable &quot;adder&quot; closure:</p>\n<pre><code class=\"language-rust\">fn make_adder(x: i32) -&gt; impl Fn(i32) -&gt; i32 {\n    // `move` transfers ownership of `x` into the closure\n    move |y| x + y\n}\n\nfn main() {\n    let add_five = make_adder(5); // Returns a closure that adds 5\n    println!(&quot;{}&quot;, add_five(3)); // 8\n}\n</code></pre>\n<h3>Key Mechanics</h3>\n<ul>\n<li><strong>Closure Capture</strong>: The <code>move</code> keyword ensures the closure owns <code>x</code>, preventing lifetime issues after <code>make_adder</code> exits. Without <code>move</code>, borrowing <code>x</code> would cause a compile error due to <code>x</code>’s scope ending.</li>\n<li><strong>Return Type</strong>: <code>impl Fn(i32) -&gt; i32</code> specifies the closure implements the <code>Fn</code> trait. Each closure has a unique anonymous type, so <code>impl Trait</code> is used to abstract it.</li>\n</ul>\n<h2>Advanced Example: Conditional Closure Return</h2>\n<p>For dynamic behavior, return a <code>Box&lt;dyn Fn&gt;</code> to support different closures at runtime:</p>\n<pre><code class=\"language-rust\">fn math_op(op: &amp;str) -&gt; Box&lt;dyn Fn(i32, i32) -&gt; i32&gt; {\n    match op {\n        &quot;add&quot; =&gt; Box::new(|x, y| x + y),\n        &quot;mul&quot; =&gt; Box::new(|x, y| x * y),\n        _ =&gt; panic!(&quot;Unsupported operation&quot;),\n    }\n}\n\nfn main() {\n    let add = math_op(&quot;add&quot;);\n    let mul = math_op(&quot;mul&quot;);\n    println!(&quot;{} {}&quot;, add(2, 3), mul(2, 3)); // 5 6\n}\n</code></pre>\n<p>This uses dynamic dispatch to handle varying closure types, ideal for plugin-like systems.</p>\n<h2>Use Cases for HOFs</h2>\n<ol>\n<li><p><strong>Iterator Adaptors</strong>:\nClosures power iterator methods like <code>map</code>, <code>filter</code>, and <code>fold</code>:</p>\n<pre><code class=\"language-rust\">let doubled: Vec&lt;_&gt; = vec![1, 2, 3].iter().map(|x| x * 2).collect(); // [2, 4, 6]\n</code></pre>\n</li>\n<li><p><strong>Decorators</strong>:\nWrap functions with additional logic (e.g., logging, retries):</p>\n<pre><code class=\"language-rust\">fn log_call&lt;F: Fn(i32) -&gt; i32&gt;(f: F) -&gt; impl Fn(i32) -&gt; i32 {\n    move |x| {\n        println!(&quot;Calling with {}&quot;, x);\n        f(x)\n    }\n}\n</code></pre>\n</li>\n<li><p><strong>Stateful Logic</strong>:\nUse <code>FnMut</code> for closures that mutate captured state (see previous answers on stateful closures).</p>\n</li>\n</ol>\n<h2>Key Takeaways</h2>\n<p>✅ <strong>HOFs enable flexible, reusable patterns</strong> by treating functions as first-class values.<br>✅ <strong>Use <code>impl Fn</code></strong> for zero-cost static dispatch in performance-critical code.<br>✅ <strong>Use <code>Box&lt;dyn Fn&gt;</code></strong> for dynamic behavior with multiple closure types.<br>🚀 <strong>Use <code>move</code></strong> to ensure closures own captured data when returned.</p>\n<p><strong>Real-World Example</strong>: HOFs are central to Rust’s iterator API (<code>map</code>, <code>filter</code>) and async frameworks like <code>tokio</code>, where closures define task behavior.</p>\n<p><strong>Experiment</strong>: Modify <code>make_adder</code> to return a closure that multiplies instead.<br><strong>Answer</strong>: The compiler accepts it seamlessly, as both closures implement <code>Fn(i32) -&gt; i32</code>, maintaining type consistency.</p>\n",
    "author": "mayo",
    "category": "rust",
    "tags": [
      "rust",
      "closures",
      "higher-order-functions"
    ],
    "readingTime": "3 min",
    "locale": "en",
    "seo": {
      "title": "Rust's Higher-Order Functions: Powering Flexible Closures",
      "description": "Exploring higher-order functions in Rust for functional programming patterns",
      "keywords": [
        "rust",
        "closures",
        "higher-order-functions"
      ]
    },
    "headings": [
      {
        "id": "what-are-higher-order-functions",
        "text": "What are Higher-Order Functions?",
        "level": 2
      },
      {
        "id": "example-function-returning-a-closure",
        "text": "Example: Function Returning a Closure",
        "level": 2
      },
      {
        "id": "key-mechanics",
        "text": "Key Mechanics",
        "level": 3
      },
      {
        "id": "advanced-example-conditional-closure-return",
        "text": "Advanced Example: Conditional Closure Return",
        "level": 2
      },
      {
        "id": "use-cases-for-hofs",
        "text": "Use Cases for HOFs",
        "level": 2
      },
      {
        "id": "key-takeaways",
        "text": "Key Takeaways",
        "level": 2
      }
    ]
  },
  {
    "id": "handling-lifetimes-returning-closures",
    "slug": "handling-lifetimes-returning-closures",
    "title": "How do you handle lifetimes when returning a closure that captures variables from its environment?",
    "date": "2025-07-12",
    "excerpt": "Managing lifetimes when returning closures that capture variables, covering ownership transfer, lifetime annotations, and avoiding dangling references in Rust",
    "content": "When returning a closure that captures variables (especially references), you must ensure the captured data outlives the closure. Rust enforces this through lifetime annotations and ownership rules. Here's how to handle it:\n\n## Key Strategies\n\n### Use move to Transfer Ownership\n\nForce the closure to take ownership of captured variables, eliminating dependency on external lifetimes:\n\n```rust\nfn create_closure() -> impl Fn() -> String {\n    let s = String::from(\"hello\"); // Owned data\n    move || s.clone() // `move` captures `s` by value\n}\n```\n\n### Annotate Lifetimes for Captured References\n\nIf capturing references, explicitly tie the closure's lifetime to the input data:\n\n```rust\nfn capture_ref<'a>(s: &'a str) -> impl Fn() -> &'a str {\n    move || s // Closure's output tied to `'a`\n}\n```\n\n### Avoid Returning Closures Capturing Short-Lived References\n\nClosures capturing references to local variables cannot escape their scope:\n\n```rust\n// ERROR: `s` does not live long enough!\nfn invalid_closure() -> impl Fn() -> &str {\n    let s = String::from(\"hello\");\n    move || &s // `s` dies at end of function\n}\n```\n\n## Example: Safe Lifetime Management\n\n```rust\n// Correct: Closure owns the captured data\nfn safe_closure() -> impl Fn() -> String {\n    let s = String::from(\"hello\");\n    move || s // `s` is moved into the closure (owned)\n}\n\n// Correct: Closure tied to input reference's lifetime\nfn capture_with_lifetime<'a>(s: &'a str) -> impl Fn() -> &'a str + 'a {\n    move || s // Closure's lifetime matches `s`\n}\n```\n\n## Lifetime Pitfalls\n\n### Dangling References\n\nReturning a closure that captures a reference to a local variable will fail:\n\n```rust\nfn dangling_closure() -> impl Fn() -> &str {\n    let local = String::from(\"oops\");\n    move || &local // ERROR: `local` dies here\n}\n```\n\n### Elision Ambiguity\n\nUse explicit lifetimes when the compiler can't infer relationships:\n\n```rust\n// Explicitly annotate input and closure lifetimes\nfn process<'a>(data: &'a [i32]) -> impl Fn(usize) -> &'a i32 + 'a {\n    move |i| &data[i] // Closure tied to `data`'s lifetime\n}\n```\n\n## Key Takeaways\n\n✅ Use move to transfer ownership of captured variables.\n✅ Annotate lifetimes when closures capture references.\n🚫 Avoid returning closures that capture short-lived references.\n\n## Real-World Use Case\n\nIn web frameworks like actix-web, handlers often return closures capturing request data with explicitly managed lifetimes.\n\n**Try This**: What happens if you remove move from capture_with_lifetime?\n\n**Answer**: Compiler error! The closure would try to borrow s, which doesn't live long enough.",
    "contentHtml": "<p>When returning a closure that captures variables (especially references), you must ensure the captured data outlives the closure. Rust enforces this through lifetime annotations and ownership rules. Here&#39;s how to handle it:</p>\n<h2>Key Strategies</h2>\n<h3>Use move to Transfer Ownership</h3>\n<p>Force the closure to take ownership of captured variables, eliminating dependency on external lifetimes:</p>\n<pre><code class=\"language-rust\">fn create_closure() -&gt; impl Fn() -&gt; String {\n    let s = String::from(&quot;hello&quot;); // Owned data\n    move || s.clone() // `move` captures `s` by value\n}\n</code></pre>\n<h3>Annotate Lifetimes for Captured References</h3>\n<p>If capturing references, explicitly tie the closure&#39;s lifetime to the input data:</p>\n<pre><code class=\"language-rust\">fn capture_ref&lt;&#39;a&gt;(s: &amp;&#39;a str) -&gt; impl Fn() -&gt; &amp;&#39;a str {\n    move || s // Closure&#39;s output tied to `&#39;a`\n}\n</code></pre>\n<h3>Avoid Returning Closures Capturing Short-Lived References</h3>\n<p>Closures capturing references to local variables cannot escape their scope:</p>\n<pre><code class=\"language-rust\">// ERROR: `s` does not live long enough!\nfn invalid_closure() -&gt; impl Fn() -&gt; &amp;str {\n    let s = String::from(&quot;hello&quot;);\n    move || &amp;s // `s` dies at end of function\n}\n</code></pre>\n<h2>Example: Safe Lifetime Management</h2>\n<pre><code class=\"language-rust\">// Correct: Closure owns the captured data\nfn safe_closure() -&gt; impl Fn() -&gt; String {\n    let s = String::from(&quot;hello&quot;);\n    move || s // `s` is moved into the closure (owned)\n}\n\n// Correct: Closure tied to input reference&#39;s lifetime\nfn capture_with_lifetime&lt;&#39;a&gt;(s: &amp;&#39;a str) -&gt; impl Fn() -&gt; &amp;&#39;a str + &#39;a {\n    move || s // Closure&#39;s lifetime matches `s`\n}\n</code></pre>\n<h2>Lifetime Pitfalls</h2>\n<h3>Dangling References</h3>\n<p>Returning a closure that captures a reference to a local variable will fail:</p>\n<pre><code class=\"language-rust\">fn dangling_closure() -&gt; impl Fn() -&gt; &amp;str {\n    let local = String::from(&quot;oops&quot;);\n    move || &amp;local // ERROR: `local` dies here\n}\n</code></pre>\n<h3>Elision Ambiguity</h3>\n<p>Use explicit lifetimes when the compiler can&#39;t infer relationships:</p>\n<pre><code class=\"language-rust\">// Explicitly annotate input and closure lifetimes\nfn process&lt;&#39;a&gt;(data: &amp;&#39;a [i32]) -&gt; impl Fn(usize) -&gt; &amp;&#39;a i32 + &#39;a {\n    move |i| &amp;data[i] // Closure tied to `data`&#39;s lifetime\n}\n</code></pre>\n<h2>Key Takeaways</h2>\n<p>✅ Use move to transfer ownership of captured variables.\n✅ Annotate lifetimes when closures capture references.\n🚫 Avoid returning closures that capture short-lived references.</p>\n<h2>Real-World Use Case</h2>\n<p>In web frameworks like actix-web, handlers often return closures capturing request data with explicitly managed lifetimes.</p>\n<p><strong>Try This</strong>: What happens if you remove move from capture_with_lifetime?</p>\n<p><strong>Answer</strong>: Compiler error! The closure would try to borrow s, which doesn&#39;t live long enough.</p>\n",
    "author": "mayo",
    "category": "rust",
    "tags": [
      "rust",
      "closures"
    ],
    "readingTime": "3 min",
    "locale": "en",
    "seo": {
      "title": "How do you handle lifetimes when returning a closure that captures variables from its environment?",
      "description": "Managing lifetimes when returning closures that capture variables, covering ownership transfer, lifetime annotations, and avoiding dangling references in Rust",
      "keywords": [
        "rust",
        "closures"
      ]
    },
    "headings": [
      {
        "id": "key-strategies",
        "text": "Key Strategies",
        "level": 2
      },
      {
        "id": "use-move-to-transfer-ownership",
        "text": "Use move to Transfer Ownership",
        "level": 3
      },
      {
        "id": "annotate-lifetimes-for-captured-references",
        "text": "Annotate Lifetimes for Captured References",
        "level": 3
      },
      {
        "id": "avoid-returning-closures-capturing-short-lived-references",
        "text": "Avoid Returning Closures Capturing Short-Lived References",
        "level": 3
      },
      {
        "id": "example-safe-lifetime-management",
        "text": "Example: Safe Lifetime Management",
        "level": 2
      },
      {
        "id": "lifetime-pitfalls",
        "text": "Lifetime Pitfalls",
        "level": 2
      },
      {
        "id": "dangling-references",
        "text": "Dangling References",
        "level": 3
      },
      {
        "id": "elision-ambiguity",
        "text": "Elision Ambiguity",
        "level": 3
      },
      {
        "id": "key-takeaways",
        "text": "Key Takeaways",
        "level": 2
      },
      {
        "id": "real-world-use-case",
        "text": "Real-World Use Case",
        "level": 2
      }
    ]
  },
  {
    "id": "closure-performance-overhead-rust",
    "slug": "closure-performance-overhead-rust",
    "title": "Using closures versus regular functions ?",
    "date": "2025-07-12",
    "excerpt": "Analyzing performance overhead of closures versus regular functions in Rust, covering static dispatch, heap allocation, and optimization scenarios",
    "content": "## Performance Overhead\n\nClosures in Rust have zero runtime overhead in most cases due to static dispatch and compiler optimizations. However, specific scenarios can introduce costs:\n\n| Aspect | Closures | Regular Functions |\n|--------|----------|-------------------|\n| Dispatch | Static (via monomorphization) | Always static (direct call) |\n| Memory | May store captured data (size varies) | No captured data (fixed size) |\n| Heap Allocation | Only if boxed (Box<dyn Fn>) | Never |\n| Optimization | Inlined aggressively | Inlined aggressively |\n\n## When Closures May Be Less Efficient\n\n### Heap-Allocated Trait Objects (Box<dyn Fn>)\n\nUsing dynamic dispatch (e.g., Box<dyn Fn>) adds overhead:\n- **Vtable Lookups**: Indirect calls via function pointers.\n- **Cache Misses**: Fat pointers (data + vtable) reduce locality.\n\n```rust\nlet closures: Vec<Box<dyn Fn(i32) -> i32>> = vec![\n    Box::new(|x| x + 1),\n    Box::new(|x| x * 2),\n]; // Heap-allocated, slower to call\n```\n\n### Large Captured Environments\n\nClosures storing large structs (e.g., 1KB buffer) increase memory usage and may inhibit inlining:\n\n```rust\nlet data = [0u8; 1024]; // 1KB array\nlet closure = move || data.len(); // Closure size = 1KB + overhead\n```\n\n### Excessive Monomorphization\n\nGeneric closures with many instantiations (e.g., in a hot loop) can bloat binary size:\n\n```rust\n(0..1_000).for_each(|i| { /* Unique closure per iteration */ });\n```\n\n## Zero-Cost Abstractions in Practice\n\n### Static Dispatch (impl Fn)\n\nClosures are as fast as regular functions when:\n- Captured data is small (e.g., primitives).\n- Monomorphization doesn't cause code bloat.\n\n```rust\nlet add = |x, y| x + y; // Same ASM as `fn add(x: i32, y: i32) -> i32`\n```\n\n### Example: Inlining\n\n```rust\nfn main() {\n    let x = 5;\n    let closure = || x * 2; // Inlined → no function call\n    println!(\"{}\", closure()); // ASM: `mov eax, 10`\n}\n```\n\n## Key Takeaways\n\n✅ Use impl Fn for zero-cost static dispatch.\n🚫 Avoid Box<dyn Fn> in performance-critical code.\n⚠️ Optimize large captures: Prefer borrowing or minimizing captured data.\n\n## Real-World Impact\n\n- **rayon** uses closures with static dispatch for parallel iterators (no overhead).\n- **GUI frameworks** like iced leverage closures for event handlers efficiently.\n\n**Try This**: Compare the assembly output of a closure and a function with `cargo rustc -- --emit asm`!",
    "contentHtml": "<h2>Performance Overhead</h2>\n<p>Closures in Rust have zero runtime overhead in most cases due to static dispatch and compiler optimizations. However, specific scenarios can introduce costs:</p>\n<table>\n<thead>\n<tr>\n<th>Aspect</th>\n<th>Closures</th>\n<th>Regular Functions</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Dispatch</td>\n<td>Static (via monomorphization)</td>\n<td>Always static (direct call)</td>\n</tr>\n<tr>\n<td>Memory</td>\n<td>May store captured data (size varies)</td>\n<td>No captured data (fixed size)</td>\n</tr>\n<tr>\n<td>Heap Allocation</td>\n<td>Only if boxed (Box<dyn Fn>)</td>\n<td>Never</td>\n</tr>\n<tr>\n<td>Optimization</td>\n<td>Inlined aggressively</td>\n<td>Inlined aggressively</td>\n</tr>\n</tbody></table>\n<h2>When Closures May Be Less Efficient</h2>\n<h3>Heap-Allocated Trait Objects (Box<dyn Fn>)</h3>\n<p>Using dynamic dispatch (e.g., Box<dyn Fn>) adds overhead:</p>\n<ul>\n<li><strong>Vtable Lookups</strong>: Indirect calls via function pointers.</li>\n<li><strong>Cache Misses</strong>: Fat pointers (data + vtable) reduce locality.</li>\n</ul>\n<pre><code class=\"language-rust\">let closures: Vec&lt;Box&lt;dyn Fn(i32) -&gt; i32&gt;&gt; = vec![\n    Box::new(|x| x + 1),\n    Box::new(|x| x * 2),\n]; // Heap-allocated, slower to call\n</code></pre>\n<h3>Large Captured Environments</h3>\n<p>Closures storing large structs (e.g., 1KB buffer) increase memory usage and may inhibit inlining:</p>\n<pre><code class=\"language-rust\">let data = [0u8; 1024]; // 1KB array\nlet closure = move || data.len(); // Closure size = 1KB + overhead\n</code></pre>\n<h3>Excessive Monomorphization</h3>\n<p>Generic closures with many instantiations (e.g., in a hot loop) can bloat binary size:</p>\n<pre><code class=\"language-rust\">(0..1_000).for_each(|i| { /* Unique closure per iteration */ });\n</code></pre>\n<h2>Zero-Cost Abstractions in Practice</h2>\n<h3>Static Dispatch (impl Fn)</h3>\n<p>Closures are as fast as regular functions when:</p>\n<ul>\n<li>Captured data is small (e.g., primitives).</li>\n<li>Monomorphization doesn&#39;t cause code bloat.</li>\n</ul>\n<pre><code class=\"language-rust\">let add = |x, y| x + y; // Same ASM as `fn add(x: i32, y: i32) -&gt; i32`\n</code></pre>\n<h3>Example: Inlining</h3>\n<pre><code class=\"language-rust\">fn main() {\n    let x = 5;\n    let closure = || x * 2; // Inlined → no function call\n    println!(&quot;{}&quot;, closure()); // ASM: `mov eax, 10`\n}\n</code></pre>\n<h2>Key Takeaways</h2>\n<p>✅ Use impl Fn for zero-cost static dispatch.\n🚫 Avoid Box<dyn Fn> in performance-critical code.\n⚠️ Optimize large captures: Prefer borrowing or minimizing captured data.</p>\n<h2>Real-World Impact</h2>\n<ul>\n<li><strong>rayon</strong> uses closures with static dispatch for parallel iterators (no overhead).</li>\n<li><strong>GUI frameworks</strong> like iced leverage closures for event handlers efficiently.</li>\n</ul>\n<p><strong>Try This</strong>: Compare the assembly output of a closure and a function with <code>cargo rustc -- --emit asm</code>!</p>\n",
    "author": "mayo",
    "category": "rust",
    "tags": [
      "rust",
      "closures"
    ],
    "readingTime": "2 min",
    "locale": "en",
    "seo": {
      "title": "Using closures versus regular functions ?",
      "description": "Analyzing performance overhead of closures versus regular functions in Rust, covering static dispatch, heap allocation, and optimization scenarios",
      "keywords": [
        "rust",
        "closures"
      ]
    },
    "headings": [
      {
        "id": "performance-overhead",
        "text": "Performance Overhead",
        "level": 2
      },
      {
        "id": "when-closures-may-be-less-efficient",
        "text": "When Closures May Be Less Efficient",
        "level": 2
      },
      {
        "id": "heap-allocated-trait-objects-boxlessdyn-fngreater",
        "text": "Heap-Allocated Trait Objects (Box<dyn Fn>)",
        "level": 3
      },
      {
        "id": "large-captured-environments",
        "text": "Large Captured Environments",
        "level": 3
      },
      {
        "id": "excessive-monomorphization",
        "text": "Excessive Monomorphization",
        "level": 3
      },
      {
        "id": "zero-cost-abstractions-in-practice",
        "text": "Zero-Cost Abstractions in Practice",
        "level": 2
      },
      {
        "id": "static-dispatch-impl-fn",
        "text": "Static Dispatch (impl Fn)",
        "level": 3
      },
      {
        "id": "example-inlining",
        "text": "Example: Inlining",
        "level": 3
      },
      {
        "id": "key-takeaways",
        "text": "Key Takeaways",
        "level": 2
      },
      {
        "id": "real-world-impact",
        "text": "Real-World Impact",
        "level": 2
      }
    ]
  },
  {
    "id": "stateful-closures-rust",
    "slug": "stateful-closures-rust",
    "title": "Rust's Stateful Closures: Passing and Mutating Across Multiple Calls",
    "date": "2025-07-10",
    "excerpt": "Managing stateful closures in Rust for repeated function calls",
    "content": "To pass a closure to a Rust function that needs to call it multiple times while maintaining state between calls, the closure must implement the `FnMut` trait to allow mutation of its captured environment. I’ll explain how to design this, using Rust’s ownership, traits, and lifetimes, and highlight when to use simple closures versus structured approaches.\n\n## Solution: Use FnMut and Mutable Closure\n\nA closure that mutates state must implement `FnMut`, which allows multiple calls with mutable access to captured variables. The function receiving the closure takes it as `&mut impl FnMut` to retain ownership while enabling mutation.\n\n**Example**:\n```rust\nfn call_repeatedly<F: FnMut() -> i32>(f: &mut F) {\n    println!(\"First call: {}\", f());  // 1\n    println!(\"Second call: {}\", f()); // 2\n}\n\nfn main() {\n    let mut counter = 0; // State stored outside the closure\n    let mut closure = || {\n        counter += 1; // Mutates captured state → `FnMut`\n        counter\n    };\n    \n    // Pass as `&mut closure` to retain ownership\n    call_repeatedly(&mut closure);\n    // closure can still be used here\n    println!(\"After: {}\", closure()); // 3\n}\n```\n\n### Key Mechanics\n- **Mutable State**: The closure captures `counter` via a mutable borrow (`&mut i32`). The closure itself is declared `mut` to allow mutation.\n- **Function Signature**: `fn call_repeatedly<F: FnMut() -> i32>(f: &mut F)` ensures the closure can be called multiple times with mutable access.\n- **Lifetime Safety**: The closure borrows `counter`, so it cannot outlive `counter`, enforced by Rust’s borrow checker.\n\n## Alternative: Encapsulate State in a Struct\n\nFor complex state, encapsulate it in a struct with an explicit `FnMut` implementation:\n\n```rust\nstruct Counter {\n    count: i32,\n}\n\nimpl Counter {\n    fn new() -> Self {\n        Counter { count: 0 }\n    }\n    \n    fn call(&mut self) -> i32 {\n        self.count += 1;\n        self.count\n    }\n}\n\nfn main() {\n    let mut counter = Counter::new();\n    call_repeatedly(|| counter.call()); // Closure captures `counter`\n    println!(\"After: {}\", counter.call()); // Continues state\n}\n```\n\n## Why Not FnOnce or Fn?\n\n- **`FnOnce`**: Can only be called once, consuming the closure. Unsuitable for multiple calls.\n- **`Fn`**: Uses immutable borrows, preventing state mutation, so it can’t modify captured variables.\n\n## Pitfalls\n\n- **Forgetting `mut`**:\n  ```rust\n  let closure = || { /* ... */ }; // Not `mut` → compile error\n  call_repeatedly(&mut closure);\n  ```\n  The closure and parameter must be `mut` to implement `FnMut`.\n- **Dangling References**: Ensure captured variables live as long as the closure. For example:\n  ```rust\n  fn bad() -> impl FnMut() -> i32 {\n      let counter = 0;\n      || { counter += 1; counter } // ERROR: `counter` doesn’t live long enough\n  }\n  ```\n\n## Key Takeaways\n\n✅ **Use `FnMut`** for closures that mutate state across multiple calls.  \n✅ **Mark closures and parameters as `mut`** to enable mutation.  \n✅ **Prefer simple closures** for basic state; use structs for complex state management.\n\n**Real-World Example**: Stateful closures are common in event loops or async tasks (e.g., `tokio`) where a closure maintains counters or buffers across iterations.\n\n**Experiment**: Try passing a non-`mut` closure to `call_repeatedly`.  \n**Answer**: Compile error! The closure must be mutable to implement `FnMut`.",
    "contentHtml": "<p>To pass a closure to a Rust function that needs to call it multiple times while maintaining state between calls, the closure must implement the <code>FnMut</code> trait to allow mutation of its captured environment. I’ll explain how to design this, using Rust’s ownership, traits, and lifetimes, and highlight when to use simple closures versus structured approaches.</p>\n<h2>Solution: Use FnMut and Mutable Closure</h2>\n<p>A closure that mutates state must implement <code>FnMut</code>, which allows multiple calls with mutable access to captured variables. The function receiving the closure takes it as <code>&amp;mut impl FnMut</code> to retain ownership while enabling mutation.</p>\n<p><strong>Example</strong>:</p>\n<pre><code class=\"language-rust\">fn call_repeatedly&lt;F: FnMut() -&gt; i32&gt;(f: &amp;mut F) {\n    println!(&quot;First call: {}&quot;, f());  // 1\n    println!(&quot;Second call: {}&quot;, f()); // 2\n}\n\nfn main() {\n    let mut counter = 0; // State stored outside the closure\n    let mut closure = || {\n        counter += 1; // Mutates captured state → `FnMut`\n        counter\n    };\n    \n    // Pass as `&amp;mut closure` to retain ownership\n    call_repeatedly(&amp;mut closure);\n    // closure can still be used here\n    println!(&quot;After: {}&quot;, closure()); // 3\n}\n</code></pre>\n<h3>Key Mechanics</h3>\n<ul>\n<li><strong>Mutable State</strong>: The closure captures <code>counter</code> via a mutable borrow (<code>&amp;mut i32</code>). The closure itself is declared <code>mut</code> to allow mutation.</li>\n<li><strong>Function Signature</strong>: <code>fn call_repeatedly&lt;F: FnMut() -&gt; i32&gt;(f: &amp;mut F)</code> ensures the closure can be called multiple times with mutable access.</li>\n<li><strong>Lifetime Safety</strong>: The closure borrows <code>counter</code>, so it cannot outlive <code>counter</code>, enforced by Rust’s borrow checker.</li>\n</ul>\n<h2>Alternative: Encapsulate State in a Struct</h2>\n<p>For complex state, encapsulate it in a struct with an explicit <code>FnMut</code> implementation:</p>\n<pre><code class=\"language-rust\">struct Counter {\n    count: i32,\n}\n\nimpl Counter {\n    fn new() -&gt; Self {\n        Counter { count: 0 }\n    }\n    \n    fn call(&amp;mut self) -&gt; i32 {\n        self.count += 1;\n        self.count\n    }\n}\n\nfn main() {\n    let mut counter = Counter::new();\n    call_repeatedly(|| counter.call()); // Closure captures `counter`\n    println!(&quot;After: {}&quot;, counter.call()); // Continues state\n}\n</code></pre>\n<h2>Why Not FnOnce or Fn?</h2>\n<ul>\n<li><strong><code>FnOnce</code></strong>: Can only be called once, consuming the closure. Unsuitable for multiple calls.</li>\n<li><strong><code>Fn</code></strong>: Uses immutable borrows, preventing state mutation, so it can’t modify captured variables.</li>\n</ul>\n<h2>Pitfalls</h2>\n<ul>\n<li><strong>Forgetting <code>mut</code></strong>:<pre><code class=\"language-rust\">let closure = || { /* ... */ }; // Not `mut` → compile error\ncall_repeatedly(&amp;mut closure);\n</code></pre>\nThe closure and parameter must be <code>mut</code> to implement <code>FnMut</code>.</li>\n<li><strong>Dangling References</strong>: Ensure captured variables live as long as the closure. For example:<pre><code class=\"language-rust\">fn bad() -&gt; impl FnMut() -&gt; i32 {\n    let counter = 0;\n    || { counter += 1; counter } // ERROR: `counter` doesn’t live long enough\n}\n</code></pre>\n</li>\n</ul>\n<h2>Key Takeaways</h2>\n<p>✅ <strong>Use <code>FnMut</code></strong> for closures that mutate state across multiple calls.<br>✅ <strong>Mark closures and parameters as <code>mut</code></strong> to enable mutation.<br>✅ <strong>Prefer simple closures</strong> for basic state; use structs for complex state management.</p>\n<p><strong>Real-World Example</strong>: Stateful closures are common in event loops or async tasks (e.g., <code>tokio</code>) where a closure maintains counters or buffers across iterations.</p>\n<p><strong>Experiment</strong>: Try passing a non-<code>mut</code> closure to <code>call_repeatedly</code>.<br><strong>Answer</strong>: Compile error! The closure must be mutable to implement <code>FnMut</code>.</p>\n",
    "author": "mayo",
    "category": "rust",
    "tags": [
      "rust",
      "closures",
      "fnmut"
    ],
    "readingTime": "3 min",
    "locale": "en",
    "seo": {
      "title": "Rust's Stateful Closures: Passing and Mutating Across Multiple Calls",
      "description": "Managing stateful closures in Rust for repeated function calls",
      "keywords": [
        "rust",
        "closures",
        "fnmut"
      ]
    },
    "headings": [
      {
        "id": "solution-use-fnmut-and-mutable-closure",
        "text": "Solution: Use FnMut and Mutable Closure",
        "level": 2
      },
      {
        "id": "key-mechanics",
        "text": "Key Mechanics",
        "level": 3
      },
      {
        "id": "alternative-encapsulate-state-in-a-struct",
        "text": "Alternative: Encapsulate State in a Struct",
        "level": 2
      },
      {
        "id": "why-not-fnonce-or-fn",
        "text": "Why Not FnOnce or Fn?",
        "level": 2
      },
      {
        "id": "pitfalls",
        "text": "Pitfalls",
        "level": 2
      },
      {
        "id": "key-takeaways",
        "text": "Key Takeaways",
        "level": 2
      }
    ]
  },
  {
    "id": "closure-dispatch-rust",
    "slug": "closure-dispatch-rust",
    "title": "impl Fn() vs. Box<dyn Fn()>: Rust's Closure Dispatch Showdown",
    "date": "2025-07-09",
    "excerpt": "Comparing static and dynamic dispatch for closures in Rust, focusing on performance and use cases",
    "content": "Rust’s closure system offers two ways to handle function-like behavior: `impl Fn()` for static dispatch and `Box<dyn Fn()>` for dynamic dispatch. Each has distinct performance and flexibility characteristics, driven by Rust’s ownership, traits, and lifetimes. I’ll compare them and explain when to choose one over the other.\n\n## Key Differences\n\n| **Aspect** | **impl Fn() (Static Dispatch)** | **Box<dyn Fn()> (Dynamic Dispatch)** |\n|------------|--------------------------------|--------------------------------------|\n| **Dispatch Mechanism** | Monomorphized at compile time (zero-cost) | Uses vtables (runtime lookup) |\n| **Performance** | Faster (~1–2 ns, direct call) | Slower (~5–10 ns, vtable lookup) |\n| **Flexibility** | Single concrete type per instance | Can store heterogeneous closures |\n| **Memory** | Stack-allocated (unless moved) | Heap-allocated (fat pointer + heap data) |\n| **Use Case** | Fixed closure type, performance-critical | Dynamic behavior, multiple closure types |\n\n## When to Use Each\n\n### 1. impl Fn() (Static Dispatch)\n- **Use When**:\n  - The closure type is fixed and known at compile time.\n  - Performance is critical (e.g., hot loops, embedded systems).\n  - Zero-cost abstractions are desired.\n- **Why**: The compiler generates a unique function for each closure type via monomorphization, enabling inlining and no runtime overhead.\n\n**Example**:\n```rust\nfn make_adder(x: i32) -> impl Fn(i32) -> i32 {\n    move |y| x + y\n}\n\nfn main() {\n    let add_five = make_adder(5); // Type: closure(5)\n    println!(\"{}\", add_five(3)); // 8\n}\n```\n\nNo heap allocation, direct function calls, and optimal performance.\n\n### 2. Box<dyn Fn()> (Dynamic Dispatch)\n- **Use When**:\n  - You need to store different closures in the same collection (e.g., callbacks).\n  - Closure types vary at runtime (e.g., plugin systems).\n  - Flexibility outweighs performance costs.\n- **Why**: `dyn Fn()` uses a vtable for runtime method resolution, allowing heterogeneous closures at the cost of heap allocation and lookup overhead.\n\n**Example**:\n```rust\nfn create_op(is_add: bool) -> Box<dyn Fn(i32, i32) -> i32> {\n    if is_add {\n        Box::new(|x, y| x + y)\n    } else {\n        Box::new(|x, y| x * y)\n    }\n}\n\nfn main() {\n    let add = create_op(true);\n    let mul = create_op(false);\n    println!(\"{} {}\", add(2, 3), mul(2, 3)); // 5 6\n}\n```\n\nSupports dynamic behavior, ideal for event handlers or plugins.\n\n## Lifetime Considerations\n\n- **Box<dyn Fn()>**: Requires explicit lifetimes if the closure captures references:\n  ```rust\n  struct Handler<'a> {\n      callback: Box<dyn Fn() -> &'a str + 'a>,\n  }\n  ```\n- **impl Fn()**: Lifetimes are typically inferred unless references are captured, simplifying usage.\n\n## Performance Trade-offs\n\n| **Scenario** | **impl Fn()** | **Box<dyn Fn()>** |\n|--------------|---------------|-------------------|\n| **Call Speed** | ~1–2 ns (direct call) | ~5–10 ns (vtable lookup) |\n| **Memory Overhead** | None (stack-allocated) | 16–24 bytes (fat pointer + heap data) |\n| **Code Bloat** | Possible (monomorphization) | Minimal (single vtable) |\n\n## Key Takeaways\n\n✅ **Choose `impl Fn()` for**:\n- Performance-sensitive code (e.g., iterator chains).\n- Single closure type (e.g., factory functions).\n\n✅ **Choose `Box<dyn Fn()>` for**:\n- Dynamic behavior (e.g., event handlers, plugins).\n- Storing mixed closure types (e.g., `Vec<Box<dyn Fn()>>`).\n\n**Real-World Examples**:\n- `impl Fn()`: Used in iterator adapters like `map` and `filter` for zero-cost performance.\n- `Box<dyn Fn()>`: Common in GUI frameworks for event callbacks where flexibility is key.\n\n## Verification\n\nTo quantify the performance difference, benchmark with `criterion`:\n\n```rust\nuse criterion::{black_box, Criterion};\nfn bench(c: &mut Criterion) {\n    let impl_fn = |x: i32| x + 5;\n    let dyn_fn: Box<dyn Fn(i32) -> i32> = Box::new(|x| x + 5);\n    c.bench_function(\"impl_fn\", |b| b.iter(|| impl_fn(black_box(3))));\n    c.bench_function(\"dyn_fn\", |b| b.iter(|| dyn_fn(black_box(3))));\n}\n```\n\nExpect `impl Fn()` to be faster and use less memory, confirming its suitability for performance-critical code.\n\n## Conclusion\n\nUse `impl Fn()` for zero-cost, static dispatch in performance-critical scenarios with known closure types. Opt for `Box<dyn Fn()>` when flexibility is needed, such as in plugin systems or event-driven applications requiring runtime polymorphism. Rust’s ownership and trait system ensure both approaches are safe, with the choice depending on the balance of performance versus dynamic requirements.",
    "contentHtml": "<p>Rust’s closure system offers two ways to handle function-like behavior: <code>impl Fn()</code> for static dispatch and <code>Box&lt;dyn Fn()&gt;</code> for dynamic dispatch. Each has distinct performance and flexibility characteristics, driven by Rust’s ownership, traits, and lifetimes. I’ll compare them and explain when to choose one over the other.</p>\n<h2>Key Differences</h2>\n<table>\n<thead>\n<tr>\n<th><strong>Aspect</strong></th>\n<th><strong>impl Fn() (Static Dispatch)</strong></th>\n<th><strong>Box&lt;dyn Fn()&gt; (Dynamic Dispatch)</strong></th>\n</tr>\n</thead>\n<tbody><tr>\n<td><strong>Dispatch Mechanism</strong></td>\n<td>Monomorphized at compile time (zero-cost)</td>\n<td>Uses vtables (runtime lookup)</td>\n</tr>\n<tr>\n<td><strong>Performance</strong></td>\n<td>Faster (~1–2 ns, direct call)</td>\n<td>Slower (~5–10 ns, vtable lookup)</td>\n</tr>\n<tr>\n<td><strong>Flexibility</strong></td>\n<td>Single concrete type per instance</td>\n<td>Can store heterogeneous closures</td>\n</tr>\n<tr>\n<td><strong>Memory</strong></td>\n<td>Stack-allocated (unless moved)</td>\n<td>Heap-allocated (fat pointer + heap data)</td>\n</tr>\n<tr>\n<td><strong>Use Case</strong></td>\n<td>Fixed closure type, performance-critical</td>\n<td>Dynamic behavior, multiple closure types</td>\n</tr>\n</tbody></table>\n<h2>When to Use Each</h2>\n<h3>1. impl Fn() (Static Dispatch)</h3>\n<ul>\n<li><strong>Use When</strong>:<ul>\n<li>The closure type is fixed and known at compile time.</li>\n<li>Performance is critical (e.g., hot loops, embedded systems).</li>\n<li>Zero-cost abstractions are desired.</li>\n</ul>\n</li>\n<li><strong>Why</strong>: The compiler generates a unique function for each closure type via monomorphization, enabling inlining and no runtime overhead.</li>\n</ul>\n<p><strong>Example</strong>:</p>\n<pre><code class=\"language-rust\">fn make_adder(x: i32) -&gt; impl Fn(i32) -&gt; i32 {\n    move |y| x + y\n}\n\nfn main() {\n    let add_five = make_adder(5); // Type: closure(5)\n    println!(&quot;{}&quot;, add_five(3)); // 8\n}\n</code></pre>\n<p>No heap allocation, direct function calls, and optimal performance.</p>\n<h3>2. Box&lt;dyn Fn()&gt; (Dynamic Dispatch)</h3>\n<ul>\n<li><strong>Use When</strong>:<ul>\n<li>You need to store different closures in the same collection (e.g., callbacks).</li>\n<li>Closure types vary at runtime (e.g., plugin systems).</li>\n<li>Flexibility outweighs performance costs.</li>\n</ul>\n</li>\n<li><strong>Why</strong>: <code>dyn Fn()</code> uses a vtable for runtime method resolution, allowing heterogeneous closures at the cost of heap allocation and lookup overhead.</li>\n</ul>\n<p><strong>Example</strong>:</p>\n<pre><code class=\"language-rust\">fn create_op(is_add: bool) -&gt; Box&lt;dyn Fn(i32, i32) -&gt; i32&gt; {\n    if is_add {\n        Box::new(|x, y| x + y)\n    } else {\n        Box::new(|x, y| x * y)\n    }\n}\n\nfn main() {\n    let add = create_op(true);\n    let mul = create_op(false);\n    println!(&quot;{} {}&quot;, add(2, 3), mul(2, 3)); // 5 6\n}\n</code></pre>\n<p>Supports dynamic behavior, ideal for event handlers or plugins.</p>\n<h2>Lifetime Considerations</h2>\n<ul>\n<li><strong>Box&lt;dyn Fn()&gt;</strong>: Requires explicit lifetimes if the closure captures references:<pre><code class=\"language-rust\">struct Handler&lt;&#39;a&gt; {\n    callback: Box&lt;dyn Fn() -&gt; &amp;&#39;a str + &#39;a&gt;,\n}\n</code></pre>\n</li>\n<li><strong>impl Fn()</strong>: Lifetimes are typically inferred unless references are captured, simplifying usage.</li>\n</ul>\n<h2>Performance Trade-offs</h2>\n<table>\n<thead>\n<tr>\n<th><strong>Scenario</strong></th>\n<th><strong>impl Fn()</strong></th>\n<th><strong>Box&lt;dyn Fn()&gt;</strong></th>\n</tr>\n</thead>\n<tbody><tr>\n<td><strong>Call Speed</strong></td>\n<td>~1–2 ns (direct call)</td>\n<td>~5–10 ns (vtable lookup)</td>\n</tr>\n<tr>\n<td><strong>Memory Overhead</strong></td>\n<td>None (stack-allocated)</td>\n<td>16–24 bytes (fat pointer + heap data)</td>\n</tr>\n<tr>\n<td><strong>Code Bloat</strong></td>\n<td>Possible (monomorphization)</td>\n<td>Minimal (single vtable)</td>\n</tr>\n</tbody></table>\n<h2>Key Takeaways</h2>\n<p>✅ <strong>Choose <code>impl Fn()</code> for</strong>:</p>\n<ul>\n<li>Performance-sensitive code (e.g., iterator chains).</li>\n<li>Single closure type (e.g., factory functions).</li>\n</ul>\n<p>✅ <strong>Choose <code>Box&lt;dyn Fn()&gt;</code> for</strong>:</p>\n<ul>\n<li>Dynamic behavior (e.g., event handlers, plugins).</li>\n<li>Storing mixed closure types (e.g., <code>Vec&lt;Box&lt;dyn Fn()&gt;&gt;</code>).</li>\n</ul>\n<p><strong>Real-World Examples</strong>:</p>\n<ul>\n<li><code>impl Fn()</code>: Used in iterator adapters like <code>map</code> and <code>filter</code> for zero-cost performance.</li>\n<li><code>Box&lt;dyn Fn()&gt;</code>: Common in GUI frameworks for event callbacks where flexibility is key.</li>\n</ul>\n<h2>Verification</h2>\n<p>To quantify the performance difference, benchmark with <code>criterion</code>:</p>\n<pre><code class=\"language-rust\">use criterion::{black_box, Criterion};\nfn bench(c: &amp;mut Criterion) {\n    let impl_fn = |x: i32| x + 5;\n    let dyn_fn: Box&lt;dyn Fn(i32) -&gt; i32&gt; = Box::new(|x| x + 5);\n    c.bench_function(&quot;impl_fn&quot;, |b| b.iter(|| impl_fn(black_box(3))));\n    c.bench_function(&quot;dyn_fn&quot;, |b| b.iter(|| dyn_fn(black_box(3))));\n}\n</code></pre>\n<p>Expect <code>impl Fn()</code> to be faster and use less memory, confirming its suitability for performance-critical code.</p>\n<h2>Conclusion</h2>\n<p>Use <code>impl Fn()</code> for zero-cost, static dispatch in performance-critical scenarios with known closure types. Opt for <code>Box&lt;dyn Fn()&gt;</code> when flexibility is needed, such as in plugin systems or event-driven applications requiring runtime polymorphism. Rust’s ownership and trait system ensure both approaches are safe, with the choice depending on the balance of performance versus dynamic requirements.</p>\n",
    "author": "mayo",
    "category": "rust",
    "tags": [
      "rust",
      "closures"
    ],
    "readingTime": "4 min",
    "locale": "en",
    "seo": {
      "title": "impl Fn() vs. Box<dyn Fn()>: Rust's Closure Dispatch Showdown",
      "description": "Comparing static and dynamic dispatch for closures in Rust, focusing on performance and use cases",
      "keywords": [
        "rust",
        "closures"
      ]
    },
    "headings": [
      {
        "id": "key-differences",
        "text": "Key Differences",
        "level": 2
      },
      {
        "id": "when-to-use-each",
        "text": "When to Use Each",
        "level": 2
      },
      {
        "id": "1-impl-fn-static-dispatch",
        "text": "1. impl Fn() (Static Dispatch)",
        "level": 3
      },
      {
        "id": "2-boxlessdyn-fngreater-dynamic-dispatch",
        "text": "2. Box<dyn Fn()> (Dynamic Dispatch)",
        "level": 3
      },
      {
        "id": "lifetime-considerations",
        "text": "Lifetime Considerations",
        "level": 2
      },
      {
        "id": "performance-trade-offs",
        "text": "Performance Trade-offs",
        "level": 2
      },
      {
        "id": "key-takeaways",
        "text": "Key Takeaways",
        "level": 2
      },
      {
        "id": "verification",
        "text": "Verification",
        "level": 2
      },
      {
        "id": "conclusion",
        "text": "Conclusion",
        "level": 2
      }
    ]
  },
  {
    "id": "move-closures-rust",
    "slug": "move-closures-rust",
    "title": "What are move closures (move || { ... })? When are they necessary, and how do they interact with ownership?",
    "date": "2025-07-08",
    "excerpt": "Functions and closures in Rust, covering ownership, traits, lifetimes",
    "content": "A `move` closure (defined with the `move` keyword) forces the closure to take ownership of variables it captures from the environment. Unlike regular closures, which capture variables by reference (immutable or mutable) when possible, `move` closures move or copy the variables into the closure itself.\n\n## Key Mechanics\n\n### 1. Ownership Transfer\n\n- For **non-Copy** types (e.g., `String`, `Vec`), the closure takes ownership of the variable:\n  ```rust\n  let s = String::from(\"hello\");\n  let closure = move || println!(\"{}\", s); // `s` is moved into the closure\n  // println!(\"{}\", s); // ERROR: `s` was moved\n  ```\n\n- For **Copy** types (e.g., `i32`, `bool`), the closure copies the value:\n  ```rust\n  let x = 42;\n  let closure = move || println!(\"{}\", x); // `x` is copied\n  println!(\"{}\", x); // OK: `x` is still valid\n  ```\n\n### 2. Interaction with Closure Traits\n\nA `move` closure’s trait (`Fn`, `FnMut`, `FnOnce`) depends on how the captured variables are used:\n\n- **`Fn`**: Read-only access to captured variables.\n- **`FnMut`**: Mutates captured variables.\n- **`FnOnce`**: Consumes captured variables (e.g., `drop`).\n\n## When Are Move Closures Necessary?\n\n### 1. Closures Outliving Their Environment\n\nWhen a closure is used in a different scope (e.g., a thread or async task), it must own its data to avoid dangling references:\n```rust\nuse std::thread;\n\nlet data = String::from(\"thread-safe\");\nthread::spawn(move || { // `move` forces ownership of `data`\n    println!(\"{}\", data); // Safe: `data` lives in the closure\n}).join().unwrap();\n```\n\n### 2. Breaking Reference Cycles\n\nIf a closure needs to capture a value that’s also borrowed elsewhere, `move` ensures ownership is transferred:\n```rust\nlet mut vec = vec![1, 2, 3];\nlet closure = move || { // Takes ownership of `vec`\n    // vec.push(4); // ERROR: `vec` is moved (can’t mutate)\n};\n// vec.push(4); // ERROR: `vec` is moved into closure\n```\n\n### 3. Explicit Ownership Control\n\nWhen you want to avoid accidental borrows or force a copy:\n```rust\nlet x = 42;\nlet closure = || println!(\"{}\", x); // Borrows `x`\nlet move_closure = move || println!(\"{}\", x); // Copies `x` (since `i32` is `Copy`)\n```\n\n## Examples\n\n### 1. Non-Copy Type (Ownership Moved)\n```rust\nlet s = String::from(\"hello\");\nlet closure = move || println!(\"{}\", s);\nclosure(); // Works: closure owns `s`\n// closure(); // ERROR if `s` is consumed (e.g., `FnOnce`)\n```\n\n### 2. Copy Type (Value Copied)\n```rust\nlet x = 42;\nlet closure = move || x + 1; // Copies `x`\nprintln!(\"{}\", x); // OK: `x` is `Copy`\n```\n\n### 3. Mixing `move` and Mutation\n```rust\nlet mut count = 0;\nlet mut closure = move || { // `count` is copied (since `i32` is `Copy`)\n    count += 1; // Operates on the copied `count`\n    count\n};\nprintln!(\"{}\", closure()); // 1\nprintln!(\"{}\", closure()); // 2\nprintln!(\"{}\", count); // 0 (original unchanged)\n```\n\n## Pitfalls\n\n- **Unintended Moves**:\n  ```rust\n  let s = String::from(\"hello\");\n  let _ = move || println!(\"{}\", s); // `s` moved here\n  // println!(\"{}\", s); // ERROR: `s` is gone\n  ```\n\n- **Overusing `move`**:\n  Unnecessary copies/moves can hurt performance or cause compile errors.\n\n## Key Takeaways\n\n✅ **Use `move` closures when**:\n- The closure outlives its environment (e.g., threads).\n- You need explicit ownership to avoid borrow checker issues.\n\n✅ **Avoid `move` for**:\n- Local, short-lived closures that don’t escape their scope.\n- `Copy` types where borrowing is sufficient.\n\n**Try This**: What happens if you use `move` with a closure that captures a mutable reference (`&mut T`)?  \n**Answer**: The reference itself is moved (but the data it points to isn’t owned). This is rarely useful and may lead to lifetime errors!",
    "contentHtml": "<p>A <code>move</code> closure (defined with the <code>move</code> keyword) forces the closure to take ownership of variables it captures from the environment. Unlike regular closures, which capture variables by reference (immutable or mutable) when possible, <code>move</code> closures move or copy the variables into the closure itself.</p>\n<h2>Key Mechanics</h2>\n<h3>1. Ownership Transfer</h3>\n<ul>\n<li><p>For <strong>non-Copy</strong> types (e.g., <code>String</code>, <code>Vec</code>), the closure takes ownership of the variable:</p>\n<pre><code class=\"language-rust\">let s = String::from(&quot;hello&quot;);\nlet closure = move || println!(&quot;{}&quot;, s); // `s` is moved into the closure\n// println!(&quot;{}&quot;, s); // ERROR: `s` was moved\n</code></pre>\n</li>\n<li><p>For <strong>Copy</strong> types (e.g., <code>i32</code>, <code>bool</code>), the closure copies the value:</p>\n<pre><code class=\"language-rust\">let x = 42;\nlet closure = move || println!(&quot;{}&quot;, x); // `x` is copied\nprintln!(&quot;{}&quot;, x); // OK: `x` is still valid\n</code></pre>\n</li>\n</ul>\n<h3>2. Interaction with Closure Traits</h3>\n<p>A <code>move</code> closure’s trait (<code>Fn</code>, <code>FnMut</code>, <code>FnOnce</code>) depends on how the captured variables are used:</p>\n<ul>\n<li><strong><code>Fn</code></strong>: Read-only access to captured variables.</li>\n<li><strong><code>FnMut</code></strong>: Mutates captured variables.</li>\n<li><strong><code>FnOnce</code></strong>: Consumes captured variables (e.g., <code>drop</code>).</li>\n</ul>\n<h2>When Are Move Closures Necessary?</h2>\n<h3>1. Closures Outliving Their Environment</h3>\n<p>When a closure is used in a different scope (e.g., a thread or async task), it must own its data to avoid dangling references:</p>\n<pre><code class=\"language-rust\">use std::thread;\n\nlet data = String::from(&quot;thread-safe&quot;);\nthread::spawn(move || { // `move` forces ownership of `data`\n    println!(&quot;{}&quot;, data); // Safe: `data` lives in the closure\n}).join().unwrap();\n</code></pre>\n<h3>2. Breaking Reference Cycles</h3>\n<p>If a closure needs to capture a value that’s also borrowed elsewhere, <code>move</code> ensures ownership is transferred:</p>\n<pre><code class=\"language-rust\">let mut vec = vec![1, 2, 3];\nlet closure = move || { // Takes ownership of `vec`\n    // vec.push(4); // ERROR: `vec` is moved (can’t mutate)\n};\n// vec.push(4); // ERROR: `vec` is moved into closure\n</code></pre>\n<h3>3. Explicit Ownership Control</h3>\n<p>When you want to avoid accidental borrows or force a copy:</p>\n<pre><code class=\"language-rust\">let x = 42;\nlet closure = || println!(&quot;{}&quot;, x); // Borrows `x`\nlet move_closure = move || println!(&quot;{}&quot;, x); // Copies `x` (since `i32` is `Copy`)\n</code></pre>\n<h2>Examples</h2>\n<h3>1. Non-Copy Type (Ownership Moved)</h3>\n<pre><code class=\"language-rust\">let s = String::from(&quot;hello&quot;);\nlet closure = move || println!(&quot;{}&quot;, s);\nclosure(); // Works: closure owns `s`\n// closure(); // ERROR if `s` is consumed (e.g., `FnOnce`)\n</code></pre>\n<h3>2. Copy Type (Value Copied)</h3>\n<pre><code class=\"language-rust\">let x = 42;\nlet closure = move || x + 1; // Copies `x`\nprintln!(&quot;{}&quot;, x); // OK: `x` is `Copy`\n</code></pre>\n<h3>3. Mixing <code>move</code> and Mutation</h3>\n<pre><code class=\"language-rust\">let mut count = 0;\nlet mut closure = move || { // `count` is copied (since `i32` is `Copy`)\n    count += 1; // Operates on the copied `count`\n    count\n};\nprintln!(&quot;{}&quot;, closure()); // 1\nprintln!(&quot;{}&quot;, closure()); // 2\nprintln!(&quot;{}&quot;, count); // 0 (original unchanged)\n</code></pre>\n<h2>Pitfalls</h2>\n<ul>\n<li><p><strong>Unintended Moves</strong>:</p>\n<pre><code class=\"language-rust\">let s = String::from(&quot;hello&quot;);\nlet _ = move || println!(&quot;{}&quot;, s); // `s` moved here\n// println!(&quot;{}&quot;, s); // ERROR: `s` is gone\n</code></pre>\n</li>\n<li><p><strong>Overusing <code>move</code></strong>:\nUnnecessary copies/moves can hurt performance or cause compile errors.</p>\n</li>\n</ul>\n<h2>Key Takeaways</h2>\n<p>✅ <strong>Use <code>move</code> closures when</strong>:</p>\n<ul>\n<li>The closure outlives its environment (e.g., threads).</li>\n<li>You need explicit ownership to avoid borrow checker issues.</li>\n</ul>\n<p>✅ <strong>Avoid <code>move</code> for</strong>:</p>\n<ul>\n<li>Local, short-lived closures that don’t escape their scope.</li>\n<li><code>Copy</code> types where borrowing is sufficient.</li>\n</ul>\n<p><strong>Try This</strong>: What happens if you use <code>move</code> with a closure that captures a mutable reference (<code>&amp;mut T</code>)?<br><strong>Answer</strong>: The reference itself is moved (but the data it points to isn’t owned). This is rarely useful and may lead to lifetime errors!</p>\n",
    "author": "mayo",
    "category": "rust",
    "tags": [
      "rust",
      "closures"
    ],
    "readingTime": "4 min",
    "locale": "en",
    "seo": {
      "title": "What are move closures (move || { ... })? When are they necessary, and how do they interact with ownership?",
      "description": "Functions and closures in Rust, covering ownership, traits, lifetimes",
      "keywords": [
        "rust",
        "closures"
      ]
    },
    "headings": [
      {
        "id": "key-mechanics",
        "text": "Key Mechanics",
        "level": 2
      },
      {
        "id": "1-ownership-transfer",
        "text": "1. Ownership Transfer",
        "level": 3
      },
      {
        "id": "2-interaction-with-closure-traits",
        "text": "2. Interaction with Closure Traits",
        "level": 3
      },
      {
        "id": "when-are-move-closures-necessary",
        "text": "When Are Move Closures Necessary?",
        "level": 2
      },
      {
        "id": "1-closures-outliving-their-environment",
        "text": "1. Closures Outliving Their Environment",
        "level": 3
      },
      {
        "id": "2-breaking-reference-cycles",
        "text": "2. Breaking Reference Cycles",
        "level": 3
      },
      {
        "id": "3-explicit-ownership-control",
        "text": "3. Explicit Ownership Control",
        "level": 3
      },
      {
        "id": "examples",
        "text": "Examples",
        "level": 2
      },
      {
        "id": "1-non-copy-type-ownership-moved",
        "text": "1. Non-Copy Type (Ownership Moved)",
        "level": 3
      },
      {
        "id": "2-copy-type-value-copied",
        "text": "2. Copy Type (Value Copied)",
        "level": 3
      },
      {
        "id": "3-mixing-move-and-mutation",
        "text": "3. Mixing `move` and Mutation",
        "level": 3
      },
      {
        "id": "pitfalls",
        "text": "Pitfalls",
        "level": 2
      },
      {
        "id": "key-takeaways",
        "text": "Key Takeaways",
        "level": 2
      }
    ]
  },
  {
    "id": "iter-methods-rust",
    "slug": "iter-methods-rust",
    "title": "How do into_iter(), iter(), and iter_mut() differ?",
    "date": "2025-07-08",
    "excerpt": "Collections (like Vec), iterators (into_iter, collect), and related concepts",
    "content": "These three methods are fundamental for working with collections in Rust, each serving distinct ownership and mutability use cases.\n\n## 1. `into_iter()` - Ownership-Consuming Iterator\n\n- **Takes ownership** of the collection (`self`).\n- **Produces** owned values (`T`) when iterating.\n- **Destroys** the original collection (can't be used afterward).\n\n```rust\nlet vec = vec![\"a\".to_string(), \"b\".to_string()];\nfor s in vec.into_iter() {  // `vec` is moved here\n    println!(\"{}\", s);      // `s` is a String (owned)\n}\n// println!(\"{:?}\", vec);  // ERROR: `vec` was consumed\n```\n\n**When to use**:\n- When you need to transform or consume the collection permanently.\n- For chaining iterator adapters that need ownership (e.g., `.filter().collect()`).\n\n## 2. `iter()` - Immutable Borrow Iterator\n\n- **Borrows** the collection immutably (`&self`).\n- **Produces** references (`&T`).\n- **Leaves** the collection intact.\n\n```rust\nlet vec = vec![\"a\", \"b\", \"c\"];\nfor s in vec.iter() {       // Borrows `vec`\n    println!(\"{}\", s);      // `s` is &&str (reference)\n}\nprintln!(\"{:?}\", vec);      // OK: `vec` still valid\n```\n\n**When to use**:\n- When you only need read-only access to elements.\n- For operations like searching (`.find()`) or inspection.\n\n## 3. `iter_mut()` - Mutable Borrow Iterator\n\n- **Borrows** the collection mutably (`&mut self`).\n- **Produces** mutable references (`&mut T`).\n- **Allows** in-place modification.\n\n```rust\nlet mut vec = vec![1, 2, 3];\nfor num in vec.iter_mut() {  // Mutable borrow\n    *num *= 2;               // Modify in place\n}\nprintln!(\"{:?}\", vec);       // [2, 4, 6]\n```\n\n**When to use**:\n- When you need to modify elements without reallocating.\n- For bulk updates (e.g., applying transformations).\n\n## Key Differences Summary\n\n| Method        | Ownership     | Yields     | Modifies Original? | Reuse Original? |\n|---------------|---------------|------------|--------------------|-----------------|\n| `into_iter()` | Consumes      | `T`        | ❌ (destroyed)      | ❌              |\n| `iter()`      | Borrows       | `&T`       | ❌                 | ✅              |\n| `iter_mut()`  | Mut borrow    | `&mut T`   | ✅                 | ✅              |\n\n## Common Pitfalls\n\n- **Accidental moves with `into_iter()`**:\n  ```rust\n  let vec = vec![1, 2];\n  let _ = vec.into_iter();  // `vec` moved here\n  // println!(\"{:?}\", vec); // ERROR!\n  ```\n\n- **Simultaneous mutable access**:\n  ```rust\n  let mut vec = vec![1, 2];\n  let iter = vec.iter_mut();\n  // vec.push(3);           // ERROR: Cannot borrow `vec` while iterator exists\n  ```\n\n## Real-World Examples\n\n- **`iter()` for read-only processing**:\n  ```rust\n  let words = vec![\"hello\", \"world\"];\n  let lengths: Vec<_> = words.iter().map(|s| s.len()).collect();  // [5, 5]\n  ```\n\n- **`iter_mut()` for in-place updates**:\n  ```rust\n  let mut scores = vec![85, 92, 78];\n  scores.iter_mut().for_each(|s| *s += 5);  // [90, 97, 83]\n  ```\n\n- **`into_iter()` for ownership transfer**:\n  ```rust\n  let matrix = vec![vec![1, 2], vec![3, 4]];\n  let flattened: Vec<_> = matrix.into_iter().flatten().collect();  // [1, 2, 3, 4]\n  ```\n\n## Performance Notes\n\n- `iter()` and `iter_mut()` are zero-cost (just pointers).\n- `into_iter()` may involve moves (but optimized for primitives like `i32`).\n\n**Try This**: What happens if you call `iter_mut()` on a `Vec<T>` where `T` doesn’t implement `Copy`, then try to modify the elements?  \n**Answer**: It works! The iterator yields `&mut T`, allowing direct mutation (e.g., `*item = new_value`).",
    "contentHtml": "<p>These three methods are fundamental for working with collections in Rust, each serving distinct ownership and mutability use cases.</p>\n<h2>1. <code>into_iter()</code> - Ownership-Consuming Iterator</h2>\n<ul>\n<li><strong>Takes ownership</strong> of the collection (<code>self</code>).</li>\n<li><strong>Produces</strong> owned values (<code>T</code>) when iterating.</li>\n<li><strong>Destroys</strong> the original collection (can&#39;t be used afterward).</li>\n</ul>\n<pre><code class=\"language-rust\">let vec = vec![&quot;a&quot;.to_string(), &quot;b&quot;.to_string()];\nfor s in vec.into_iter() {  // `vec` is moved here\n    println!(&quot;{}&quot;, s);      // `s` is a String (owned)\n}\n// println!(&quot;{:?}&quot;, vec);  // ERROR: `vec` was consumed\n</code></pre>\n<p><strong>When to use</strong>:</p>\n<ul>\n<li>When you need to transform or consume the collection permanently.</li>\n<li>For chaining iterator adapters that need ownership (e.g., <code>.filter().collect()</code>).</li>\n</ul>\n<h2>2. <code>iter()</code> - Immutable Borrow Iterator</h2>\n<ul>\n<li><strong>Borrows</strong> the collection immutably (<code>&amp;self</code>).</li>\n<li><strong>Produces</strong> references (<code>&amp;T</code>).</li>\n<li><strong>Leaves</strong> the collection intact.</li>\n</ul>\n<pre><code class=\"language-rust\">let vec = vec![&quot;a&quot;, &quot;b&quot;, &quot;c&quot;];\nfor s in vec.iter() {       // Borrows `vec`\n    println!(&quot;{}&quot;, s);      // `s` is &amp;&amp;str (reference)\n}\nprintln!(&quot;{:?}&quot;, vec);      // OK: `vec` still valid\n</code></pre>\n<p><strong>When to use</strong>:</p>\n<ul>\n<li>When you only need read-only access to elements.</li>\n<li>For operations like searching (<code>.find()</code>) or inspection.</li>\n</ul>\n<h2>3. <code>iter_mut()</code> - Mutable Borrow Iterator</h2>\n<ul>\n<li><strong>Borrows</strong> the collection mutably (<code>&amp;mut self</code>).</li>\n<li><strong>Produces</strong> mutable references (<code>&amp;mut T</code>).</li>\n<li><strong>Allows</strong> in-place modification.</li>\n</ul>\n<pre><code class=\"language-rust\">let mut vec = vec![1, 2, 3];\nfor num in vec.iter_mut() {  // Mutable borrow\n    *num *= 2;               // Modify in place\n}\nprintln!(&quot;{:?}&quot;, vec);       // [2, 4, 6]\n</code></pre>\n<p><strong>When to use</strong>:</p>\n<ul>\n<li>When you need to modify elements without reallocating.</li>\n<li>For bulk updates (e.g., applying transformations).</li>\n</ul>\n<h2>Key Differences Summary</h2>\n<table>\n<thead>\n<tr>\n<th>Method</th>\n<th>Ownership</th>\n<th>Yields</th>\n<th>Modifies Original?</th>\n<th>Reuse Original?</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><code>into_iter()</code></td>\n<td>Consumes</td>\n<td><code>T</code></td>\n<td>❌ (destroyed)</td>\n<td>❌</td>\n</tr>\n<tr>\n<td><code>iter()</code></td>\n<td>Borrows</td>\n<td><code>&amp;T</code></td>\n<td>❌</td>\n<td>✅</td>\n</tr>\n<tr>\n<td><code>iter_mut()</code></td>\n<td>Mut borrow</td>\n<td><code>&amp;mut T</code></td>\n<td>✅</td>\n<td>✅</td>\n</tr>\n</tbody></table>\n<h2>Common Pitfalls</h2>\n<ul>\n<li><p><strong>Accidental moves with <code>into_iter()</code></strong>:</p>\n<pre><code class=\"language-rust\">let vec = vec![1, 2];\nlet _ = vec.into_iter();  // `vec` moved here\n// println!(&quot;{:?}&quot;, vec); // ERROR!\n</code></pre>\n</li>\n<li><p><strong>Simultaneous mutable access</strong>:</p>\n<pre><code class=\"language-rust\">let mut vec = vec![1, 2];\nlet iter = vec.iter_mut();\n// vec.push(3);           // ERROR: Cannot borrow `vec` while iterator exists\n</code></pre>\n</li>\n</ul>\n<h2>Real-World Examples</h2>\n<ul>\n<li><p><strong><code>iter()</code> for read-only processing</strong>:</p>\n<pre><code class=\"language-rust\">let words = vec![&quot;hello&quot;, &quot;world&quot;];\nlet lengths: Vec&lt;_&gt; = words.iter().map(|s| s.len()).collect();  // [5, 5]\n</code></pre>\n</li>\n<li><p><strong><code>iter_mut()</code> for in-place updates</strong>:</p>\n<pre><code class=\"language-rust\">let mut scores = vec![85, 92, 78];\nscores.iter_mut().for_each(|s| *s += 5);  // [90, 97, 83]\n</code></pre>\n</li>\n<li><p><strong><code>into_iter()</code> for ownership transfer</strong>:</p>\n<pre><code class=\"language-rust\">let matrix = vec![vec![1, 2], vec![3, 4]];\nlet flattened: Vec&lt;_&gt; = matrix.into_iter().flatten().collect();  // [1, 2, 3, 4]\n</code></pre>\n</li>\n</ul>\n<h2>Performance Notes</h2>\n<ul>\n<li><code>iter()</code> and <code>iter_mut()</code> are zero-cost (just pointers).</li>\n<li><code>into_iter()</code> may involve moves (but optimized for primitives like <code>i32</code>).</li>\n</ul>\n<p><strong>Try This</strong>: What happens if you call <code>iter_mut()</code> on a <code>Vec&lt;T&gt;</code> where <code>T</code> doesn’t implement <code>Copy</code>, then try to modify the elements?<br><strong>Answer</strong>: It works! The iterator yields <code>&amp;mut T</code>, allowing direct mutation (e.g., <code>*item = new_value</code>).</p>\n",
    "author": "mayo",
    "category": "rust",
    "tags": [
      "rust",
      "iterators",
      "collections"
    ],
    "readingTime": "3 min",
    "locale": "en",
    "seo": {
      "title": "How do into_iter(), iter(), and iter_mut() differ?",
      "description": "Collections (like Vec), iterators (into_iter, collect), and related concepts",
      "keywords": [
        "rust",
        "iterators",
        "collections"
      ]
    },
    "headings": [
      {
        "id": "1-intoiter-ownership-consuming-iterator",
        "text": "1. `into_iter()` - Ownership-Consuming Iterator",
        "level": 2
      },
      {
        "id": "2-iter-immutable-borrow-iterator",
        "text": "2. `iter()` - Immutable Borrow Iterator",
        "level": 2
      },
      {
        "id": "3-itermut-mutable-borrow-iterator",
        "text": "3. `iter_mut()` - Mutable Borrow Iterator",
        "level": 2
      },
      {
        "id": "key-differences-summary",
        "text": "Key Differences Summary",
        "level": 2
      },
      {
        "id": "common-pitfalls",
        "text": "Common Pitfalls",
        "level": 2
      },
      {
        "id": "real-world-examples",
        "text": "Real-World Examples",
        "level": 2
      },
      {
        "id": "performance-notes",
        "text": "Performance Notes",
        "level": 2
      }
    ]
  },
  {
    "id": "fn-traits-rust",
    "slug": "fn-traits-rust",
    "title": "What are the differences between Fn, FnMut, and FnOnce?",
    "date": "2025-07-07",
    "excerpt": "Functions and closures in Rust, covering ownership, traits, lifetimes",
    "content": "Understanding the distinction between `Fn`, `FnMut`, and `FnOnce` traits is crucial for mastering Rust's closure system, ownership, and performance characteristics.\n\n## Closure Capturing\n\nClosures in Rust capture variables from their environment in one of three ways, depending on how the variables are used:\n\n- **Immutable Borrow (`&T`)**: If the closure only reads a variable.\n- **Mutable Borrow (`&mut T`)**: If the closure modifies a variable.\n- **Ownership (`T`)**: If the closure takes ownership (e.g., via `move` or by consuming the variable).\n\nThe compiler automatically infers the least restrictive capture mode needed. The `move` keyword forces ownership capture, but the closure’s trait (`Fn`, `FnMut`, or `FnOnce`) depends on how the captured variables are used.\n\n## Closure Traits\n\nRust closures implement one or more of these traits:\n\n| Trait   | Captures Variables Via | Call Semantics | Call Count |\n|---------|------------------------|----------------|------------|\n| `Fn`    | Immutable borrow (`&T`) | `&self`        | Multiple   |\n| `FnMut` | Mutable borrow (`&mut T`) | `&mut self` | Multiple   |\n| `FnOnce`| Ownership (`T`)        | `self` (consumes closure) | Once |\n\n### Key Differences\n\n- **`Fn`**:\n  - Can be called repeatedly.\n  - Captures variables immutably.\n  - Example:\n    ```rust\n    let x = 42;\n    let closure = || println!(\"{}\", x); // Fn (captures `x` by &T)\n    ```\n\n- **`FnMut`**:\n  - Can mutate captured variables.\n  - Requires `mut` keyword if stored.\n  - Example:\n    ```rust\n    let mut x = 42;\n    let mut closure = || { x += 1; }; // FnMut (captures `x` by &mut T)\n    ```\n\n- **`FnOnce`**:\n  - Takes ownership of captured variables.\n  - Can only be called once.\n  - Example:\n    ```rust\n    let x = String::from(\"hello\");\n    let closure = || { drop(x); }; // FnOnce (moves `x` into closure)\n    ```\n\n## Trait Hierarchy\n\n- **`Fn`**: Also implements `FnMut` and `FnOnce`.\n- **`FnMut`**: Also implements `FnOnce`.\n- A closure that implements `Fn` can be used where `FnMut` or `FnOnce` is required.\n- A closure that implements `FnMut` can be used as `FnOnce`.\n\n## `move` Keyword\n\nForces the closure to take ownership of captured variables, even if they’re only read:\n```rust\nlet s = String::from(\"hello\");\nlet closure = move || println!(\"{}\", s); // `s` is moved into the closure\n```\n\n- **Trait Impact**:\n  - If the closure doesn’t mutate or consume `s`, it still implements `Fn` (since `s` is owned but not modified).\n  - If the closure consumes `s` (e.g., `drop(s)`), it becomes `FnOnce`.\n\n## Examples\n\n1. **Immutable Capture (`Fn`)**:\n   ```rust\n   let x = 5;\n   let print_x = || println!(\"{}\", x); // Fn\n   print_x(); // OK\n   print_x(); // Still valid\n   ```\n\n2. **Mutable Capture (`FnMut`)**:\n   ```rust\n   let mut x = 5;\n   let mut add_one = || x += 1; // FnMut\n   add_one(); // x = 6\n   add_one(); // x = 7\n   ```\n\n3. **Ownership Capture (`FnOnce`)**:\n   ```rust\n   let x = String::from(\"hello\");\n   let consume_x = || { drop(x); }; // FnOnce\n   consume_x(); // OK\n   // consume_x(); // ERROR: closure called after being moved\n   ```\n\n## Performance & Use Cases\n\n| Trait   | Overhead      | Use Case                        |\n|---------|---------------|---------------------------------|\n| `Fn`    | Zero-cost     | Read-only callbacks, iterators  |\n| `FnMut` | Zero-cost     | Stateful transformations       |\n| `FnOnce`| May allocate  | One-time operations (e.g., spawning threads) |\n\n## Key Takeaways\n\n✅ **`Fn`**: Read-only, reusable.  \n✅ **`FnMut`**: Mutable, reusable.  \n✅ **`FnOnce`**: Owned, single-use.  \n🚀 `move` forces ownership but doesn’t change the trait—usage determines the trait.\n\n**Try This:** What happens if a closure captures a mutable reference but doesn’t mutate it?  \n**Answer:** It still implements `FnMut` (since it *could* mutate), but you can pass it to a function expecting `FnMut`.",
    "contentHtml": "<p>Understanding the distinction between <code>Fn</code>, <code>FnMut</code>, and <code>FnOnce</code> traits is crucial for mastering Rust&#39;s closure system, ownership, and performance characteristics.</p>\n<h2>Closure Capturing</h2>\n<p>Closures in Rust capture variables from their environment in one of three ways, depending on how the variables are used:</p>\n<ul>\n<li><strong>Immutable Borrow (<code>&amp;T</code>)</strong>: If the closure only reads a variable.</li>\n<li><strong>Mutable Borrow (<code>&amp;mut T</code>)</strong>: If the closure modifies a variable.</li>\n<li><strong>Ownership (<code>T</code>)</strong>: If the closure takes ownership (e.g., via <code>move</code> or by consuming the variable).</li>\n</ul>\n<p>The compiler automatically infers the least restrictive capture mode needed. The <code>move</code> keyword forces ownership capture, but the closure’s trait (<code>Fn</code>, <code>FnMut</code>, or <code>FnOnce</code>) depends on how the captured variables are used.</p>\n<h2>Closure Traits</h2>\n<p>Rust closures implement one or more of these traits:</p>\n<table>\n<thead>\n<tr>\n<th>Trait</th>\n<th>Captures Variables Via</th>\n<th>Call Semantics</th>\n<th>Call Count</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><code>Fn</code></td>\n<td>Immutable borrow (<code>&amp;T</code>)</td>\n<td><code>&amp;self</code></td>\n<td>Multiple</td>\n</tr>\n<tr>\n<td><code>FnMut</code></td>\n<td>Mutable borrow (<code>&amp;mut T</code>)</td>\n<td><code>&amp;mut self</code></td>\n<td>Multiple</td>\n</tr>\n<tr>\n<td><code>FnOnce</code></td>\n<td>Ownership (<code>T</code>)</td>\n<td><code>self</code> (consumes closure)</td>\n<td>Once</td>\n</tr>\n</tbody></table>\n<h3>Key Differences</h3>\n<ul>\n<li><p><strong><code>Fn</code></strong>:</p>\n<ul>\n<li>Can be called repeatedly.</li>\n<li>Captures variables immutably.</li>\n<li>Example:<pre><code class=\"language-rust\">let x = 42;\nlet closure = || println!(&quot;{}&quot;, x); // Fn (captures `x` by &amp;T)\n</code></pre>\n</li>\n</ul>\n</li>\n<li><p><strong><code>FnMut</code></strong>:</p>\n<ul>\n<li>Can mutate captured variables.</li>\n<li>Requires <code>mut</code> keyword if stored.</li>\n<li>Example:<pre><code class=\"language-rust\">let mut x = 42;\nlet mut closure = || { x += 1; }; // FnMut (captures `x` by &amp;mut T)\n</code></pre>\n</li>\n</ul>\n</li>\n<li><p><strong><code>FnOnce</code></strong>:</p>\n<ul>\n<li>Takes ownership of captured variables.</li>\n<li>Can only be called once.</li>\n<li>Example:<pre><code class=\"language-rust\">let x = String::from(&quot;hello&quot;);\nlet closure = || { drop(x); }; // FnOnce (moves `x` into closure)\n</code></pre>\n</li>\n</ul>\n</li>\n</ul>\n<h2>Trait Hierarchy</h2>\n<ul>\n<li><strong><code>Fn</code></strong>: Also implements <code>FnMut</code> and <code>FnOnce</code>.</li>\n<li><strong><code>FnMut</code></strong>: Also implements <code>FnOnce</code>.</li>\n<li>A closure that implements <code>Fn</code> can be used where <code>FnMut</code> or <code>FnOnce</code> is required.</li>\n<li>A closure that implements <code>FnMut</code> can be used as <code>FnOnce</code>.</li>\n</ul>\n<h2><code>move</code> Keyword</h2>\n<p>Forces the closure to take ownership of captured variables, even if they’re only read:</p>\n<pre><code class=\"language-rust\">let s = String::from(&quot;hello&quot;);\nlet closure = move || println!(&quot;{}&quot;, s); // `s` is moved into the closure\n</code></pre>\n<ul>\n<li><strong>Trait Impact</strong>:<ul>\n<li>If the closure doesn’t mutate or consume <code>s</code>, it still implements <code>Fn</code> (since <code>s</code> is owned but not modified).</li>\n<li>If the closure consumes <code>s</code> (e.g., <code>drop(s)</code>), it becomes <code>FnOnce</code>.</li>\n</ul>\n</li>\n</ul>\n<h2>Examples</h2>\n<ol>\n<li><p><strong>Immutable Capture (<code>Fn</code>)</strong>:</p>\n<pre><code class=\"language-rust\">let x = 5;\nlet print_x = || println!(&quot;{}&quot;, x); // Fn\nprint_x(); // OK\nprint_x(); // Still valid\n</code></pre>\n</li>\n<li><p><strong>Mutable Capture (<code>FnMut</code>)</strong>:</p>\n<pre><code class=\"language-rust\">let mut x = 5;\nlet mut add_one = || x += 1; // FnMut\nadd_one(); // x = 6\nadd_one(); // x = 7\n</code></pre>\n</li>\n<li><p><strong>Ownership Capture (<code>FnOnce</code>)</strong>:</p>\n<pre><code class=\"language-rust\">let x = String::from(&quot;hello&quot;);\nlet consume_x = || { drop(x); }; // FnOnce\nconsume_x(); // OK\n// consume_x(); // ERROR: closure called after being moved\n</code></pre>\n</li>\n</ol>\n<h2>Performance &amp; Use Cases</h2>\n<table>\n<thead>\n<tr>\n<th>Trait</th>\n<th>Overhead</th>\n<th>Use Case</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><code>Fn</code></td>\n<td>Zero-cost</td>\n<td>Read-only callbacks, iterators</td>\n</tr>\n<tr>\n<td><code>FnMut</code></td>\n<td>Zero-cost</td>\n<td>Stateful transformations</td>\n</tr>\n<tr>\n<td><code>FnOnce</code></td>\n<td>May allocate</td>\n<td>One-time operations (e.g., spawning threads)</td>\n</tr>\n</tbody></table>\n<h2>Key Takeaways</h2>\n<p>✅ <strong><code>Fn</code></strong>: Read-only, reusable.<br>✅ <strong><code>FnMut</code></strong>: Mutable, reusable.<br>✅ <strong><code>FnOnce</code></strong>: Owned, single-use.<br>🚀 <code>move</code> forces ownership but doesn’t change the trait—usage determines the trait.</p>\n<p><strong>Try This:</strong> What happens if a closure captures a mutable reference but doesn’t mutate it?<br><strong>Answer:</strong> It still implements <code>FnMut</code> (since it <em>could</em> mutate), but you can pass it to a function expecting <code>FnMut</code>.</p>\n",
    "author": "mayo",
    "category": "rust",
    "tags": [
      "rust",
      "closures"
    ],
    "readingTime": "3 min",
    "locale": "en",
    "seo": {
      "title": "What are the differences between Fn, FnMut, and FnOnce?",
      "description": "Functions and closures in Rust, covering ownership, traits, lifetimes",
      "keywords": [
        "rust",
        "closures"
      ]
    },
    "headings": [
      {
        "id": "closure-capturing",
        "text": "Closure Capturing",
        "level": 2
      },
      {
        "id": "closure-traits",
        "text": "Closure Traits",
        "level": 2
      },
      {
        "id": "key-differences",
        "text": "Key Differences",
        "level": 3
      },
      {
        "id": "trait-hierarchy",
        "text": "Trait Hierarchy",
        "level": 2
      },
      {
        "id": "move-keyword",
        "text": "`move` Keyword",
        "level": 2
      },
      {
        "id": "examples",
        "text": "Examples",
        "level": 2
      },
      {
        "id": "performance-and-use-cases",
        "text": "Performance & Use Cases",
        "level": 2
      },
      {
        "id": "key-takeaways",
        "text": "Key Takeaways",
        "level": 2
      }
    ]
  },
  {
    "id": "closure-parameter-rust",
    "slug": "closure-parameter-rust",
    "title": "How do you specify a closure as a function parameter or return type?",
    "date": "2025-07-07",
    "excerpt": "Functions and closures in Rust, covering ownership, traits, lifetimes",
    "content": "Closures in Rust are anonymous types, so you must use trait bounds (`Fn`, `FnMut`, `FnOnce`) to define their signatures. Here’s how to work with them as parameters and return types.\n\n## Closure as a Function Parameter\n\nUse generic type parameters with trait bounds to accept closures.\n\n### Example: `Fn` (Immutable Borrow)\n\n```rust\n// Accepts a closure that takes `i32` and returns `i32` (read-only).\nfn apply<F: Fn(i32) -> i32>(f: F, x: i32) -> i32 {\n    f(x)\n}\n\nfn main() {\n    let add_five = |x| x + 5; // Implements `Fn`\n    println!(\"{}\", apply(add_five, 10)); // 15\n}\n```\n\n### Example: `FnMut` (Mutable Borrow)\n\n```rust\n// Accepts a closure that mutates its environment.\nfn apply_mut<F: FnMut(i32) -> i32>(mut f: F, x: i32) -> i32 {\n    f(x)\n}\n\nfn main() {\n    let mut count = 0;\n    let mut increment_and_add = |x| {\n        count += 1; // Mutates `count` → `FnMut`\n        x + count\n    };\n    println!(\"{}\", apply_mut(increment_and_add, 10)); // 11\n}\n```\n\n## Closure as a Return Type\n\nUse `impl Trait` for static dispatch (zero-cost) or `Box<dyn Trait>` for dynamic dispatch (flexible).\n\n### Example: Return `impl Fn` (Static Dispatch)\n\n```rust\n// Returns a closure that adds a fixed value (immutable capture).\nfn make_adder(a: i32) -> impl Fn(i32) -> i32 {\n    move |b| a + b // `move` forces ownership (still `Fn` since `a` is read-only)\n}\n\nfn main() {\n    let add_ten = make_adder(10);\n    println!(\"{}\", add_ten(5)); // 15\n}\n```\n\n### Example: Return `Box<dyn Fn>` (Dynamic Dispatch)\n\n```rust\n// Returns a trait object for heterogeneous closures.\nfn create_closure(is_add: bool) -> Box<dyn Fn(i32) -> i32> {\n    if is_add {\n        Box::new(|x| x + 1) // Heap-allocated closure\n    } else {\n        Box::new(|x| x - 1)\n    }\n}\n\nfn main() {\n    let add = create_closure(true);\n    let sub = create_closure(false);\n    println!(\"{} {}\", add(5), sub(5)); // 6 4\n}\n```\n\n## Key Differences\n\n| Approach            | `impl Fn` (Static)         | `Box<dyn Fn>` (Dynamic)    |\n|---------------------|----------------------------|----------------------------|\n| **Dispatch**        | Monomorphized (zero-cost)  | Vtable lookup (runtime cost) |\n| **Use Case**        | Single closure type        | Multiple closure types     |\n| **Memory**          | Stack-allocated            | Heap-allocated (trait object) |\n| **Flexibility**     | Less (fixed type)          | More (any `dyn Fn` closure) |\n\n## When to Use Each\n\n- **`impl Fn`**:\n  - When returning a single type of closure (e.g., from a factory function).\n  - For performance-critical code (no heap allocation).\n\n- **`Box<dyn Fn>`**:\n  - When returning different closure types (e.g., conditionally).\n  - For dynamic behavior (e.g., plugin systems, callbacks).\n\n## Pitfalls\n\n- **`FnMut` in Structs**: Store mutable closures with `FnMut` and annotate `mut`:\n  ```rust\n  struct Processor<F: FnMut(i32) -> i32> {\n      op: F,\n  }\n  ```\n\n- **Lifetimes**: Closures capturing references may require explicit lifetimes:\n  ```rust\n  fn capture_ref<'a>(s: &'a str) -> impl Fn() -> &'a str {\n      move || s // Closure captures `s` with lifetime `'a`\n  }\n  ```\n\n## Key Takeaways\n\n✅ **Parameter**: Use generics (`F: Fn(...)`) for flexibility and performance.  \n✅ **Return Type**:  \n- `impl Fn` for static dispatch (fast, fixed type).  \n- `Box<dyn Fn>` for dynamic dispatch (flexible, multiple types).  \n🚀 Prefer `impl Fn` unless you need runtime polymorphism.\n\n**Try This**: What happens if you return a `FnOnce` closure?  \n**Answer**: It’s allowed, but the caller can only invoke it once!",
    "contentHtml": "<p>Closures in Rust are anonymous types, so you must use trait bounds (<code>Fn</code>, <code>FnMut</code>, <code>FnOnce</code>) to define their signatures. Here’s how to work with them as parameters and return types.</p>\n<h2>Closure as a Function Parameter</h2>\n<p>Use generic type parameters with trait bounds to accept closures.</p>\n<h3>Example: <code>Fn</code> (Immutable Borrow)</h3>\n<pre><code class=\"language-rust\">// Accepts a closure that takes `i32` and returns `i32` (read-only).\nfn apply&lt;F: Fn(i32) -&gt; i32&gt;(f: F, x: i32) -&gt; i32 {\n    f(x)\n}\n\nfn main() {\n    let add_five = |x| x + 5; // Implements `Fn`\n    println!(&quot;{}&quot;, apply(add_five, 10)); // 15\n}\n</code></pre>\n<h3>Example: <code>FnMut</code> (Mutable Borrow)</h3>\n<pre><code class=\"language-rust\">// Accepts a closure that mutates its environment.\nfn apply_mut&lt;F: FnMut(i32) -&gt; i32&gt;(mut f: F, x: i32) -&gt; i32 {\n    f(x)\n}\n\nfn main() {\n    let mut count = 0;\n    let mut increment_and_add = |x| {\n        count += 1; // Mutates `count` → `FnMut`\n        x + count\n    };\n    println!(&quot;{}&quot;, apply_mut(increment_and_add, 10)); // 11\n}\n</code></pre>\n<h2>Closure as a Return Type</h2>\n<p>Use <code>impl Trait</code> for static dispatch (zero-cost) or <code>Box&lt;dyn Trait&gt;</code> for dynamic dispatch (flexible).</p>\n<h3>Example: Return <code>impl Fn</code> (Static Dispatch)</h3>\n<pre><code class=\"language-rust\">// Returns a closure that adds a fixed value (immutable capture).\nfn make_adder(a: i32) -&gt; impl Fn(i32) -&gt; i32 {\n    move |b| a + b // `move` forces ownership (still `Fn` since `a` is read-only)\n}\n\nfn main() {\n    let add_ten = make_adder(10);\n    println!(&quot;{}&quot;, add_ten(5)); // 15\n}\n</code></pre>\n<h3>Example: Return <code>Box&lt;dyn Fn&gt;</code> (Dynamic Dispatch)</h3>\n<pre><code class=\"language-rust\">// Returns a trait object for heterogeneous closures.\nfn create_closure(is_add: bool) -&gt; Box&lt;dyn Fn(i32) -&gt; i32&gt; {\n    if is_add {\n        Box::new(|x| x + 1) // Heap-allocated closure\n    } else {\n        Box::new(|x| x - 1)\n    }\n}\n\nfn main() {\n    let add = create_closure(true);\n    let sub = create_closure(false);\n    println!(&quot;{} {}&quot;, add(5), sub(5)); // 6 4\n}\n</code></pre>\n<h2>Key Differences</h2>\n<table>\n<thead>\n<tr>\n<th>Approach</th>\n<th><code>impl Fn</code> (Static)</th>\n<th><code>Box&lt;dyn Fn&gt;</code> (Dynamic)</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><strong>Dispatch</strong></td>\n<td>Monomorphized (zero-cost)</td>\n<td>Vtable lookup (runtime cost)</td>\n</tr>\n<tr>\n<td><strong>Use Case</strong></td>\n<td>Single closure type</td>\n<td>Multiple closure types</td>\n</tr>\n<tr>\n<td><strong>Memory</strong></td>\n<td>Stack-allocated</td>\n<td>Heap-allocated (trait object)</td>\n</tr>\n<tr>\n<td><strong>Flexibility</strong></td>\n<td>Less (fixed type)</td>\n<td>More (any <code>dyn Fn</code> closure)</td>\n</tr>\n</tbody></table>\n<h2>When to Use Each</h2>\n<ul>\n<li><p><strong><code>impl Fn</code></strong>:</p>\n<ul>\n<li>When returning a single type of closure (e.g., from a factory function).</li>\n<li>For performance-critical code (no heap allocation).</li>\n</ul>\n</li>\n<li><p><strong><code>Box&lt;dyn Fn&gt;</code></strong>:</p>\n<ul>\n<li>When returning different closure types (e.g., conditionally).</li>\n<li>For dynamic behavior (e.g., plugin systems, callbacks).</li>\n</ul>\n</li>\n</ul>\n<h2>Pitfalls</h2>\n<ul>\n<li><p><strong><code>FnMut</code> in Structs</strong>: Store mutable closures with <code>FnMut</code> and annotate <code>mut</code>:</p>\n<pre><code class=\"language-rust\">struct Processor&lt;F: FnMut(i32) -&gt; i32&gt; {\n    op: F,\n}\n</code></pre>\n</li>\n<li><p><strong>Lifetimes</strong>: Closures capturing references may require explicit lifetimes:</p>\n<pre><code class=\"language-rust\">fn capture_ref&lt;&#39;a&gt;(s: &amp;&#39;a str) -&gt; impl Fn() -&gt; &amp;&#39;a str {\n    move || s // Closure captures `s` with lifetime `&#39;a`\n}\n</code></pre>\n</li>\n</ul>\n<h2>Key Takeaways</h2>\n<p>✅ <strong>Parameter</strong>: Use generics (<code>F: Fn(...)</code>) for flexibility and performance.<br>✅ <strong>Return Type</strong>:  </p>\n<ul>\n<li><code>impl Fn</code> for static dispatch (fast, fixed type).  </li>\n<li><code>Box&lt;dyn Fn&gt;</code> for dynamic dispatch (flexible, multiple types).<br>🚀 Prefer <code>impl Fn</code> unless you need runtime polymorphism.</li>\n</ul>\n<p><strong>Try This</strong>: What happens if you return a <code>FnOnce</code> closure?<br><strong>Answer</strong>: It’s allowed, but the caller can only invoke it once!</p>\n",
    "author": "mayo",
    "category": "rust",
    "tags": [
      "rust",
      "closures"
    ],
    "readingTime": "3 min",
    "locale": "en",
    "seo": {
      "title": "How do you specify a closure as a function parameter or return type?",
      "description": "Functions and closures in Rust, covering ownership, traits, lifetimes",
      "keywords": [
        "rust",
        "closures"
      ]
    },
    "headings": [
      {
        "id": "closure-as-a-function-parameter",
        "text": "Closure as a Function Parameter",
        "level": 2
      },
      {
        "id": "example-fn-immutable-borrow",
        "text": "Example: `Fn` (Immutable Borrow)",
        "level": 3
      },
      {
        "id": "example-fnmut-mutable-borrow",
        "text": "Example: `FnMut` (Mutable Borrow)",
        "level": 3
      },
      {
        "id": "closure-as-a-return-type",
        "text": "Closure as a Return Type",
        "level": 2
      },
      {
        "id": "example-return-impl-fn-static-dispatch",
        "text": "Example: Return `impl Fn` (Static Dispatch)",
        "level": 3
      },
      {
        "id": "example-return-boxlessdyn-fngreater-dynamic-dispatch",
        "text": "Example: Return `Box<dyn Fn>` (Dynamic Dispatch)",
        "level": 3
      },
      {
        "id": "key-differences",
        "text": "Key Differences",
        "level": 2
      },
      {
        "id": "when-to-use-each",
        "text": "When to Use Each",
        "level": 2
      },
      {
        "id": "pitfalls",
        "text": "Pitfalls",
        "level": 2
      },
      {
        "id": "key-takeaways",
        "text": "Key Takeaways",
        "level": 2
      }
    ]
  },
  {
    "id": "rust-traits-vs-interfaces",
    "slug": "rust-traits-vs-interfaces",
    "title": "Rust Traits vs. Java/C# Interfaces: Shared Behavior Done Right",
    "date": "2025-07-04",
    "excerpt": "Discussion on Rust traits vs Java/C# interfaces, covering dispatch mechanisms, compile-time behavior, and performance optimizations.",
    "content": "Rust traits and interfaces both define shared behavior, but differ fundamentally in design and execution, especially in performance-critical contexts.\n\n## Key Differences\n\n| Aspect | Rust Traits | Java/C# Interfaces |\n|--------|-------------|-------------------|\n| **Dispatch** | Static dispatch (generics) by default, opt-in dynamic (`dyn`) | Runtime polymorphism via vtables |\n| **Implementation** | Explicit via `impl Trait for Type` | Implicit (C#) or explicit (Java) |\n| **Compile-time** | Resolved at compile time via monomorphization | Runtime constructs with JIT optimization |\n| **Inheritance** | No inheritance; composition via supertraits | Interface inheritance with runtime checks |\n| **Performance** | Zero-cost abstraction, inlining enabled | 1-2 cycle dispatch cost, limited inlining |\n\n## Implementation and Dispatch\n\n**Rust Traits**: Support static dispatch via generics where the compiler monomorphizes code for each type, inlining calls for zero runtime overhead. Dynamic dispatch (`dyn Trait`) uses vtables but is opt-in.\n\n**Java/C# Interfaces**: Rely on runtime polymorphism via vtables, incurring dispatch costs and preventing inlining across type boundaries.\n\n## Example: Performance-Critical Networking Stack\n\nDefine a `PacketHandler` trait for efficient packet processing across different protocols:\n\n```rust\ntrait PacketHandler {\n    fn process(&mut self, data: &[u8]) -> usize; // Bytes processed\n    fn reset(&mut self); // Reset state\n}\n\nstruct TcpHandler { state: u32 }\nstruct UdpHandler { count: u16 }\n\nimpl PacketHandler for TcpHandler {\n    fn process(&mut self, data: &[u8]) -> usize {\n        self.state = data.iter().fold(self.state, |acc, &x| acc.wrapping_add(x as u32));\n        data.len()\n    }\n    fn reset(&mut self) { self.state = 0; }\n}\n\nimpl PacketHandler for UdpHandler {\n    fn process(&mut self, data: &[u8]) -> usize {\n        self.count = self.count.wrapping_add(1);\n        data.len()\n    }\n    fn reset(&mut self) { self.count = 0; }\n}\n\nfn process_packets<H: PacketHandler>(handler: &mut H, packets: &[&[u8]]) -> usize {\n    let mut total = 0;\n    for packet in packets {\n        total += handler.process(packet);\n    }\n    total\n}\n```\n\nUsage:\n```rust\nlet mut tcp = TcpHandler { state: 0 };\nlet packets = vec![&[1, 2, 3], &[4, 5, 6]];\nlet bytes = process_packets(&mut tcp, &packets); // Static dispatch\n```\n\n## How It Enhances Performance and Safety\n\n### Performance\n\n- **Static Dispatch**: `process_packets` monomorphizes for `TcpHandler` and `UdpHandler`, generating separate, inlined code paths. No vtable lookups, saving cycles in hot loops\n- **Inlining**: Compiler can inline `process` calls, fusing them with the loop, reducing branches and enabling SIMD optimizations\n- **Zero-Cost**: Trait abstraction adds no runtime overhead—equivalent to hand-writing `process_tcp` and `process_udp`\n\n### Safety\n\n- **Type Safety**: Trait bound `H: PacketHandler` ensures only compatible types are passed, checked at compile time—no runtime casts like Java's `instanceof`\n- **Encapsulation**: Each handler manages its state (`state` or `count`), with Rust's ownership enforcing mutation rules\n\n## Contrast with Java/C#\n\nJava equivalent:\n```java\ninterface PacketHandler {\n    int process(byte[] data);\n    void reset();\n}\n\nclass TcpHandler implements PacketHandler {\n    // vtable-based dispatch, no inlining across types\n}\n```\n\nEvery `process` call goes through a vtable, preventing loop fusion and adding indirection. Rust's static dispatch avoids this—critical for networking stacks handling millions of packets per second.\n\n## Advanced Considerations\n\n- **Associated Types**: Enable type-level constraints without runtime overhead\n- **Default Implementations**: Reduce boilerplate while maintaining zero-cost\n- **Supertraits**: Compose behavior without inheritance complexity\n- **Dynamic Dispatch**: Use `Box<dyn PacketHandler>` when type erasure is needed\n\n## Key Takeaways\n\n✅ **Rust traits**: Compile-time resolution, zero-cost abstraction, static dispatch by default  \n✅ **Java/C# interfaces**: Runtime polymorphism, vtable overhead, dynamic by nature  \n🚀 Use traits for performance-critical code where static dispatch eliminates overhead\n\n**Try This:** What happens if you use `&dyn PacketHandler` instead of generics?  \n**Answer:** You get dynamic dispatch with vtable overhead—measure the performance difference in your hot paths!",
    "contentHtml": "<p>Rust traits and interfaces both define shared behavior, but differ fundamentally in design and execution, especially in performance-critical contexts.</p>\n<h2>Key Differences</h2>\n<table>\n<thead>\n<tr>\n<th>Aspect</th>\n<th>Rust Traits</th>\n<th>Java/C# Interfaces</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><strong>Dispatch</strong></td>\n<td>Static dispatch (generics) by default, opt-in dynamic (<code>dyn</code>)</td>\n<td>Runtime polymorphism via vtables</td>\n</tr>\n<tr>\n<td><strong>Implementation</strong></td>\n<td>Explicit via <code>impl Trait for Type</code></td>\n<td>Implicit (C#) or explicit (Java)</td>\n</tr>\n<tr>\n<td><strong>Compile-time</strong></td>\n<td>Resolved at compile time via monomorphization</td>\n<td>Runtime constructs with JIT optimization</td>\n</tr>\n<tr>\n<td><strong>Inheritance</strong></td>\n<td>No inheritance; composition via supertraits</td>\n<td>Interface inheritance with runtime checks</td>\n</tr>\n<tr>\n<td><strong>Performance</strong></td>\n<td>Zero-cost abstraction, inlining enabled</td>\n<td>1-2 cycle dispatch cost, limited inlining</td>\n</tr>\n</tbody></table>\n<h2>Implementation and Dispatch</h2>\n<p><strong>Rust Traits</strong>: Support static dispatch via generics where the compiler monomorphizes code for each type, inlining calls for zero runtime overhead. Dynamic dispatch (<code>dyn Trait</code>) uses vtables but is opt-in.</p>\n<p><strong>Java/C# Interfaces</strong>: Rely on runtime polymorphism via vtables, incurring dispatch costs and preventing inlining across type boundaries.</p>\n<h2>Example: Performance-Critical Networking Stack</h2>\n<p>Define a <code>PacketHandler</code> trait for efficient packet processing across different protocols:</p>\n<pre><code class=\"language-rust\">trait PacketHandler {\n    fn process(&amp;mut self, data: &amp;[u8]) -&gt; usize; // Bytes processed\n    fn reset(&amp;mut self); // Reset state\n}\n\nstruct TcpHandler { state: u32 }\nstruct UdpHandler { count: u16 }\n\nimpl PacketHandler for TcpHandler {\n    fn process(&amp;mut self, data: &amp;[u8]) -&gt; usize {\n        self.state = data.iter().fold(self.state, |acc, &amp;x| acc.wrapping_add(x as u32));\n        data.len()\n    }\n    fn reset(&amp;mut self) { self.state = 0; }\n}\n\nimpl PacketHandler for UdpHandler {\n    fn process(&amp;mut self, data: &amp;[u8]) -&gt; usize {\n        self.count = self.count.wrapping_add(1);\n        data.len()\n    }\n    fn reset(&amp;mut self) { self.count = 0; }\n}\n\nfn process_packets&lt;H: PacketHandler&gt;(handler: &amp;mut H, packets: &amp;[&amp;[u8]]) -&gt; usize {\n    let mut total = 0;\n    for packet in packets {\n        total += handler.process(packet);\n    }\n    total\n}\n</code></pre>\n<p>Usage:</p>\n<pre><code class=\"language-rust\">let mut tcp = TcpHandler { state: 0 };\nlet packets = vec![&amp;[1, 2, 3], &amp;[4, 5, 6]];\nlet bytes = process_packets(&amp;mut tcp, &amp;packets); // Static dispatch\n</code></pre>\n<h2>How It Enhances Performance and Safety</h2>\n<h3>Performance</h3>\n<ul>\n<li><strong>Static Dispatch</strong>: <code>process_packets</code> monomorphizes for <code>TcpHandler</code> and <code>UdpHandler</code>, generating separate, inlined code paths. No vtable lookups, saving cycles in hot loops</li>\n<li><strong>Inlining</strong>: Compiler can inline <code>process</code> calls, fusing them with the loop, reducing branches and enabling SIMD optimizations</li>\n<li><strong>Zero-Cost</strong>: Trait abstraction adds no runtime overhead—equivalent to hand-writing <code>process_tcp</code> and <code>process_udp</code></li>\n</ul>\n<h3>Safety</h3>\n<ul>\n<li><strong>Type Safety</strong>: Trait bound <code>H: PacketHandler</code> ensures only compatible types are passed, checked at compile time—no runtime casts like Java&#39;s <code>instanceof</code></li>\n<li><strong>Encapsulation</strong>: Each handler manages its state (<code>state</code> or <code>count</code>), with Rust&#39;s ownership enforcing mutation rules</li>\n</ul>\n<h2>Contrast with Java/C#</h2>\n<p>Java equivalent:</p>\n<pre><code class=\"language-java\">interface PacketHandler {\n    int process(byte[] data);\n    void reset();\n}\n\nclass TcpHandler implements PacketHandler {\n    // vtable-based dispatch, no inlining across types\n}\n</code></pre>\n<p>Every <code>process</code> call goes through a vtable, preventing loop fusion and adding indirection. Rust&#39;s static dispatch avoids this—critical for networking stacks handling millions of packets per second.</p>\n<h2>Advanced Considerations</h2>\n<ul>\n<li><strong>Associated Types</strong>: Enable type-level constraints without runtime overhead</li>\n<li><strong>Default Implementations</strong>: Reduce boilerplate while maintaining zero-cost</li>\n<li><strong>Supertraits</strong>: Compose behavior without inheritance complexity</li>\n<li><strong>Dynamic Dispatch</strong>: Use <code>Box&lt;dyn PacketHandler&gt;</code> when type erasure is needed</li>\n</ul>\n<h2>Key Takeaways</h2>\n<p>✅ <strong>Rust traits</strong>: Compile-time resolution, zero-cost abstraction, static dispatch by default<br>✅ <strong>Java/C# interfaces</strong>: Runtime polymorphism, vtable overhead, dynamic by nature<br>🚀 Use traits for performance-critical code where static dispatch eliminates overhead</p>\n<p><strong>Try This:</strong> What happens if you use <code>&amp;dyn PacketHandler</code> instead of generics?<br><strong>Answer:</strong> You get dynamic dispatch with vtable overhead—measure the performance difference in your hot paths!</p>\n",
    "author": "mayo",
    "category": "rust",
    "tags": [
      "rust",
      "traits"
    ],
    "readingTime": "4 min",
    "locale": "en",
    "seo": {
      "title": "Rust Traits vs. Java/C# Interfaces: Shared Behavior Done Right",
      "description": "Discussion on Rust traits vs Java/C# interfaces, covering dispatch mechanisms, compile-time behavior, and performance optimizations.",
      "keywords": [
        "rust",
        "traits"
      ]
    },
    "headings": [
      {
        "id": "key-differences",
        "text": "Key Differences",
        "level": 2
      },
      {
        "id": "implementation-and-dispatch",
        "text": "Implementation and Dispatch",
        "level": 2
      },
      {
        "id": "example-performance-critical-networking-stack",
        "text": "Example: Performance-Critical Networking Stack",
        "level": 2
      },
      {
        "id": "how-it-enhances-performance-and-safety",
        "text": "How It Enhances Performance and Safety",
        "level": 2
      },
      {
        "id": "performance",
        "text": "Performance",
        "level": 3
      },
      {
        "id": "safety",
        "text": "Safety",
        "level": 3
      },
      {
        "id": "contrast-with-javac",
        "text": "Contrast with Java/C#",
        "level": 2
      },
      {
        "id": "advanced-considerations",
        "text": "Advanced Considerations",
        "level": 2
      },
      {
        "id": "key-takeaways",
        "text": "Key Takeaways",
        "level": 2
      }
    ]
  },
  {
    "id": "string-vs-str-rust",
    "slug": "string-vs-str-rust",
    "title": "String vs. &str – Which to Use and When?",
    "date": "2025-07-03",
    "excerpt": "String vs str in Rust, covering memory management, ownership, and when to use each type.",
    "content": "Understanding the distinction between `String` and `str` is fundamental to effective memory management and ownership in Rust.\n\n## Key Differences\n\n| `String` | `str` (usually `&str`) |\n|----------|------------------------|\n| Growable, heap-allocated UTF-8 string | Immutable, fixed-size view into UTF-8 string |\n| Owned type (manages its memory) | Borrowed type (does not own memory) |\n| Mutable (can modify content) | Immutable view |\n| Created using `String::from(\"...\")` or `\"...\".to_string()` | From string literals (`\"hello\"`) or borrowed from `String` (`&my_string`) |\n\n## Memory Layout\n\n**`String`**: Stores data on the heap with three components:\n- Pointer to heap buffer\n- Length (current size)\n- Capacity (allocated size)\n\n**`&str`**: A \"fat pointer\" containing:\n- Pointer to string data (heap, stack, or static memory)\n- Length of the slice\n\n## When to Use Each\n\nUse **`String`** when:\n- You need to modify or grow the string\n- You need ownership (e.g., returning from a function)\n- Building strings dynamically\n\n```rust\nlet mut owned = String::from(\"hello\");\nowned.push_str(\" world\");  // Mutation requires String\n```\n\nUse **`&str`** when:\n- You only need a read-only view of a string\n- Working with function parameters (avoids unnecessary allocations)\n- Handling string literals (stored in read-only memory)\n\n```rust\nfn process_str(s: &str) -> usize {\n    s.len()  // Read-only access\n}\n```\n\n## Example: Ownership vs Borrowing\n\n```rust\nfn process_string(s: String) { /* takes ownership */ }\nfn process_str(s: &str)      { /* borrows */ }\n\nfn main() {\n    let heap_str = String::from(\"hello\");\n    let static_str = \"world\";\n    \n    process_string(heap_str);  // Ownership moved\n    process_str(static_str);   // Borrowed\n    \n    // heap_str no longer accessible here\n    // static_str still accessible\n}\n```\n\n## Performance Considerations\n\n**Function Parameters**:\n```rust\n// Inefficient - forces allocation\nfn bad(s: String) -> usize { s.len() }\n\n// Efficient - accepts both String and &str\nfn good(s: &str) -> usize { s.len() }\n\n// Usage\nlet owned = String::from(\"test\");\ngood(&owned);  // Deref coercion: String -> &str\ngood(\"literal\");  // Direct &str\n```\n\n**Memory Allocation**:\n- `String` allocates on heap, requires deallocation\n- `&str` to literals points to program binary (zero allocation)\n- `&str` from `String` shares existing allocation\n\n## Common Patterns\n\n**Return Owned Data**:\n```rust\nfn build_message(name: &str) -> String {\n    format!(\"Hello, {}!\", name)  // Returns owned String\n}\n```\n\n**Accept Flexible Input**:\n```rust\nfn analyze(text: &str) -> Analysis {\n    // Works with both String and &str inputs\n    text.chars().count()\n}\n```\n\n**Avoid Unnecessary Clones**:\n```rust\n// Bad - unnecessary allocation\nfn process_bad(s: &str) -> String {\n    s.to_string()  // Only if you actually need owned data\n}\n\n// Good - work with borrowed data when possible\nfn process_good(s: &str) -> &str {\n    s.trim()  // Returns slice of original\n}\n```\n\n## Key Takeaways\n\n✅ **`String`**: Owned, mutable, heap-allocated  \n✅ **`str`**: Borrowed, immutable, flexible (heap/stack/static)  \n🚀 Prefer `&str` for function parameters unless you need ownership or mutation\n\n**Try This:** What happens when you call `.to_string()` on a string literal vs a `String`?  \n**Answer:** Literal creates new heap allocation; `String` creates a clone of existing heap data—both allocate, but the source differs!",
    "contentHtml": "<p>Understanding the distinction between <code>String</code> and <code>str</code> is fundamental to effective memory management and ownership in Rust.</p>\n<h2>Key Differences</h2>\n<table>\n<thead>\n<tr>\n<th><code>String</code></th>\n<th><code>str</code> (usually <code>&amp;str</code>)</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Growable, heap-allocated UTF-8 string</td>\n<td>Immutable, fixed-size view into UTF-8 string</td>\n</tr>\n<tr>\n<td>Owned type (manages its memory)</td>\n<td>Borrowed type (does not own memory)</td>\n</tr>\n<tr>\n<td>Mutable (can modify content)</td>\n<td>Immutable view</td>\n</tr>\n<tr>\n<td>Created using <code>String::from(&quot;...&quot;)</code> or <code>&quot;...&quot;.to_string()</code></td>\n<td>From string literals (<code>&quot;hello&quot;</code>) or borrowed from <code>String</code> (<code>&amp;my_string</code>)</td>\n</tr>\n</tbody></table>\n<h2>Memory Layout</h2>\n<p><strong><code>String</code></strong>: Stores data on the heap with three components:</p>\n<ul>\n<li>Pointer to heap buffer</li>\n<li>Length (current size)</li>\n<li>Capacity (allocated size)</li>\n</ul>\n<p><strong><code>&amp;str</code></strong>: A &quot;fat pointer&quot; containing:</p>\n<ul>\n<li>Pointer to string data (heap, stack, or static memory)</li>\n<li>Length of the slice</li>\n</ul>\n<h2>When to Use Each</h2>\n<p>Use <strong><code>String</code></strong> when:</p>\n<ul>\n<li>You need to modify or grow the string</li>\n<li>You need ownership (e.g., returning from a function)</li>\n<li>Building strings dynamically</li>\n</ul>\n<pre><code class=\"language-rust\">let mut owned = String::from(&quot;hello&quot;);\nowned.push_str(&quot; world&quot;);  // Mutation requires String\n</code></pre>\n<p>Use <strong><code>&amp;str</code></strong> when:</p>\n<ul>\n<li>You only need a read-only view of a string</li>\n<li>Working with function parameters (avoids unnecessary allocations)</li>\n<li>Handling string literals (stored in read-only memory)</li>\n</ul>\n<pre><code class=\"language-rust\">fn process_str(s: &amp;str) -&gt; usize {\n    s.len()  // Read-only access\n}\n</code></pre>\n<h2>Example: Ownership vs Borrowing</h2>\n<pre><code class=\"language-rust\">fn process_string(s: String) { /* takes ownership */ }\nfn process_str(s: &amp;str)      { /* borrows */ }\n\nfn main() {\n    let heap_str = String::from(&quot;hello&quot;);\n    let static_str = &quot;world&quot;;\n    \n    process_string(heap_str);  // Ownership moved\n    process_str(static_str);   // Borrowed\n    \n    // heap_str no longer accessible here\n    // static_str still accessible\n}\n</code></pre>\n<h2>Performance Considerations</h2>\n<p><strong>Function Parameters</strong>:</p>\n<pre><code class=\"language-rust\">// Inefficient - forces allocation\nfn bad(s: String) -&gt; usize { s.len() }\n\n// Efficient - accepts both String and &amp;str\nfn good(s: &amp;str) -&gt; usize { s.len() }\n\n// Usage\nlet owned = String::from(&quot;test&quot;);\ngood(&amp;owned);  // Deref coercion: String -&gt; &amp;str\ngood(&quot;literal&quot;);  // Direct &amp;str\n</code></pre>\n<p><strong>Memory Allocation</strong>:</p>\n<ul>\n<li><code>String</code> allocates on heap, requires deallocation</li>\n<li><code>&amp;str</code> to literals points to program binary (zero allocation)</li>\n<li><code>&amp;str</code> from <code>String</code> shares existing allocation</li>\n</ul>\n<h2>Common Patterns</h2>\n<p><strong>Return Owned Data</strong>:</p>\n<pre><code class=\"language-rust\">fn build_message(name: &amp;str) -&gt; String {\n    format!(&quot;Hello, {}!&quot;, name)  // Returns owned String\n}\n</code></pre>\n<p><strong>Accept Flexible Input</strong>:</p>\n<pre><code class=\"language-rust\">fn analyze(text: &amp;str) -&gt; Analysis {\n    // Works with both String and &amp;str inputs\n    text.chars().count()\n}\n</code></pre>\n<p><strong>Avoid Unnecessary Clones</strong>:</p>\n<pre><code class=\"language-rust\">// Bad - unnecessary allocation\nfn process_bad(s: &amp;str) -&gt; String {\n    s.to_string()  // Only if you actually need owned data\n}\n\n// Good - work with borrowed data when possible\nfn process_good(s: &amp;str) -&gt; &amp;str {\n    s.trim()  // Returns slice of original\n}\n</code></pre>\n<h2>Key Takeaways</h2>\n<p>✅ <strong><code>String</code></strong>: Owned, mutable, heap-allocated<br>✅ <strong><code>str</code></strong>: Borrowed, immutable, flexible (heap/stack/static)<br>🚀 Prefer <code>&amp;str</code> for function parameters unless you need ownership or mutation</p>\n<p><strong>Try This:</strong> What happens when you call <code>.to_string()</code> on a string literal vs a <code>String</code>?<br><strong>Answer:</strong> Literal creates new heap allocation; <code>String</code> creates a clone of existing heap data—both allocate, but the source differs!</p>\n",
    "author": "mayo",
    "category": "rust",
    "tags": [
      "rust",
      "string"
    ],
    "readingTime": "3 min",
    "locale": "en",
    "seo": {
      "title": "String vs. &str – Which to Use and When?",
      "description": "String vs str in Rust, covering memory management, ownership, and when to use each type.",
      "keywords": [
        "rust",
        "string"
      ]
    },
    "headings": [
      {
        "id": "key-differences",
        "text": "Key Differences",
        "level": 2
      },
      {
        "id": "memory-layout",
        "text": "Memory Layout",
        "level": 2
      },
      {
        "id": "when-to-use-each",
        "text": "When to Use Each",
        "level": 2
      },
      {
        "id": "example-ownership-vs-borrowing",
        "text": "Example: Ownership vs Borrowing",
        "level": 2
      },
      {
        "id": "performance-considerations",
        "text": "Performance Considerations",
        "level": 2
      },
      {
        "id": "common-patterns",
        "text": "Common Patterns",
        "level": 2
      },
      {
        "id": "key-takeaways",
        "text": "Key Takeaways",
        "level": 2
      }
    ]
  },
  {
    "id": "function-vs-closure-rust",
    "slug": "function-vs-closure-rust",
    "title": "Functions or Closures in Rust? Know the Difference!",
    "date": "2025-06-30",
    "excerpt": "Functions vs closures in Rust, covering ownership, traits, lifetimes, and performance implications.",
    "content": "Understanding the distinction between functions and closures is fundamental to mastering Rust's ownership system and performance characteristics.\n\n## Key Differences\n\n| Functions | Closures |\n|-----------|----------|\n| Defined at compile time with `fn` | Anonymous, created at runtime |\n| Static dispatch (no runtime overhead) | May involve dynamic dispatch (trait objects) |\n| Cannot capture environment variables | Can capture variables from enclosing scope |\n| Always have a known type | Type is unique and inferred (each closure has its own type) |\n\n## Underlying Mechanics\n\n### Closures Are Structs + Traits\n\nRust models closures as structs that:\n- Store captured variables (as fields)\n- Implement one of the closure traits (`Fn`, `FnMut`, or `FnOnce`)\n\nFor example, this closure:\n```rust\nlet x = 42;\nlet closure = |y| x + y;\n```\n\nIt expands to something like:\n```rust\nstruct AnonymousClosure {\n    x: i32,  // Captured variable\n}\n\nimpl FnOnce<(i32,)> for AnonymousClosure {\n    type Output = i32;\n    fn call_once(self, y: i32) -> i32 {\n        self.x + y\n    }\n}\n```\n\n### Dynamic Dispatch (Vtables)\n\nWhen closures are trait objects (e.g., `Box<dyn Fn(i32) -> i32>`), Rust uses vtables for dynamic dispatch:\n- **Vtable**: A lookup table storing function pointers, enabling runtime polymorphism\n- **Overhead**: Indirect function calls (~2–3x slower than static dispatch)\n\n## When to Use Each\n\nUse **Functions** when:\n- You need zero-cost abstractions (e.g., mathematical operations)\n- No environment capture is required\n\n```rust\nfn add(a: i32, b: i32) -> i32 { a + b }\n```\n\nUse **Closures** when:\n- You need to capture state from the environment\n- Writing short, ad-hoc logic (e.g., callbacks, iterators)\n\n```rust\nlet threshold = 10;\nlet filter = |x: i32| x > threshold;  // Captures `threshold`\n```\n\n## Performance Considerations\n\n| Scenario | Static Dispatch (Closures) | Dynamic Dispatch (dyn Fn) |\n|----------|----------------------------|----------------------------|\n| Speed | Fast (inlined) | Slower (vtable lookup) |\n| Memory | No overhead | Vtable + fat pointer |\n| Use Case | Hot loops, embedded | Heterogeneous callbacks |\n\n## Example: Static vs. Dynamic Dispatch\n\n```rust\n// Static dispatch (compile-time)\nfn static_call<F: Fn(i32) -> i32>(f: F, x: i32) -> i32 {\n    f(x)  // Inlined\n}\n\n// Dynamic dispatch (runtime)\nfn dynamic_call(f: &dyn Fn(i32) -> i32, x: i32) -> i32 {\n    f(x)  // Vtable lookup\n}\n```\n\n## Key Takeaways\n\n✅ **Functions**: Predictable performance, no captures  \n✅ **Closures**: Flexible, capture environment, but may involve vtables  \n🚀 Prefer static dispatch (`impl Fn`) unless you need trait objects\n\n**Try This:** What happens if a closure captures a mutable reference and is called twice?  \n**Answer:** The borrow checker ensures exclusive access—it won't compile unless the first call completes!",
    "contentHtml": "<p>Understanding the distinction between functions and closures is fundamental to mastering Rust&#39;s ownership system and performance characteristics.</p>\n<h2>Key Differences</h2>\n<table>\n<thead>\n<tr>\n<th>Functions</th>\n<th>Closures</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Defined at compile time with <code>fn</code></td>\n<td>Anonymous, created at runtime</td>\n</tr>\n<tr>\n<td>Static dispatch (no runtime overhead)</td>\n<td>May involve dynamic dispatch (trait objects)</td>\n</tr>\n<tr>\n<td>Cannot capture environment variables</td>\n<td>Can capture variables from enclosing scope</td>\n</tr>\n<tr>\n<td>Always have a known type</td>\n<td>Type is unique and inferred (each closure has its own type)</td>\n</tr>\n</tbody></table>\n<h2>Underlying Mechanics</h2>\n<h3>Closures Are Structs + Traits</h3>\n<p>Rust models closures as structs that:</p>\n<ul>\n<li>Store captured variables (as fields)</li>\n<li>Implement one of the closure traits (<code>Fn</code>, <code>FnMut</code>, or <code>FnOnce</code>)</li>\n</ul>\n<p>For example, this closure:</p>\n<pre><code class=\"language-rust\">let x = 42;\nlet closure = |y| x + y;\n</code></pre>\n<p>It expands to something like:</p>\n<pre><code class=\"language-rust\">struct AnonymousClosure {\n    x: i32,  // Captured variable\n}\n\nimpl FnOnce&lt;(i32,)&gt; for AnonymousClosure {\n    type Output = i32;\n    fn call_once(self, y: i32) -&gt; i32 {\n        self.x + y\n    }\n}\n</code></pre>\n<h3>Dynamic Dispatch (Vtables)</h3>\n<p>When closures are trait objects (e.g., <code>Box&lt;dyn Fn(i32) -&gt; i32&gt;</code>), Rust uses vtables for dynamic dispatch:</p>\n<ul>\n<li><strong>Vtable</strong>: A lookup table storing function pointers, enabling runtime polymorphism</li>\n<li><strong>Overhead</strong>: Indirect function calls (~2–3x slower than static dispatch)</li>\n</ul>\n<h2>When to Use Each</h2>\n<p>Use <strong>Functions</strong> when:</p>\n<ul>\n<li>You need zero-cost abstractions (e.g., mathematical operations)</li>\n<li>No environment capture is required</li>\n</ul>\n<pre><code class=\"language-rust\">fn add(a: i32, b: i32) -&gt; i32 { a + b }\n</code></pre>\n<p>Use <strong>Closures</strong> when:</p>\n<ul>\n<li>You need to capture state from the environment</li>\n<li>Writing short, ad-hoc logic (e.g., callbacks, iterators)</li>\n</ul>\n<pre><code class=\"language-rust\">let threshold = 10;\nlet filter = |x: i32| x &gt; threshold;  // Captures `threshold`\n</code></pre>\n<h2>Performance Considerations</h2>\n<table>\n<thead>\n<tr>\n<th>Scenario</th>\n<th>Static Dispatch (Closures)</th>\n<th>Dynamic Dispatch (dyn Fn)</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Speed</td>\n<td>Fast (inlined)</td>\n<td>Slower (vtable lookup)</td>\n</tr>\n<tr>\n<td>Memory</td>\n<td>No overhead</td>\n<td>Vtable + fat pointer</td>\n</tr>\n<tr>\n<td>Use Case</td>\n<td>Hot loops, embedded</td>\n<td>Heterogeneous callbacks</td>\n</tr>\n</tbody></table>\n<h2>Example: Static vs. Dynamic Dispatch</h2>\n<pre><code class=\"language-rust\">// Static dispatch (compile-time)\nfn static_call&lt;F: Fn(i32) -&gt; i32&gt;(f: F, x: i32) -&gt; i32 {\n    f(x)  // Inlined\n}\n\n// Dynamic dispatch (runtime)\nfn dynamic_call(f: &amp;dyn Fn(i32) -&gt; i32, x: i32) -&gt; i32 {\n    f(x)  // Vtable lookup\n}\n</code></pre>\n<h2>Key Takeaways</h2>\n<p>✅ <strong>Functions</strong>: Predictable performance, no captures<br>✅ <strong>Closures</strong>: Flexible, capture environment, but may involve vtables<br>🚀 Prefer static dispatch (<code>impl Fn</code>) unless you need trait objects</p>\n<p><strong>Try This:</strong> What happens if a closure captures a mutable reference and is called twice?<br><strong>Answer:</strong> The borrow checker ensures exclusive access—it won&#39;t compile unless the first call completes!</p>\n",
    "author": "mayo",
    "category": "rust",
    "tags": [
      "rust",
      "closures"
    ],
    "readingTime": "3 min",
    "locale": "en",
    "seo": {
      "title": "Functions or Closures in Rust? Know the Difference!",
      "description": "Functions vs closures in Rust, covering ownership, traits, lifetimes, and performance implications.",
      "keywords": [
        "rust",
        "closures"
      ]
    },
    "headings": [
      {
        "id": "key-differences",
        "text": "Key Differences",
        "level": 2
      },
      {
        "id": "underlying-mechanics",
        "text": "Underlying Mechanics",
        "level": 2
      },
      {
        "id": "closures-are-structs-traits",
        "text": "Closures Are Structs + Traits",
        "level": 3
      },
      {
        "id": "dynamic-dispatch-vtables",
        "text": "Dynamic Dispatch (Vtables)",
        "level": 3
      },
      {
        "id": "when-to-use-each",
        "text": "When to Use Each",
        "level": 2
      },
      {
        "id": "performance-considerations",
        "text": "Performance Considerations",
        "level": 2
      },
      {
        "id": "example-static-vs-dynamic-dispatch",
        "text": "Example: Static vs. Dynamic Dispatch",
        "level": 2
      },
      {
        "id": "key-takeaways",
        "text": "Key Takeaways",
        "level": 2
      }
    ]
  },
  {
    "id": "memory-layout-optimization-rust",
    "slug": "memory-layout-optimization-rust",
    "title": "Rust's repr: Optimize Struct Memory for Cache Efficiency",
    "date": "2025-06-26",
    "excerpt": "Low-level memory optimization in Rust, covering repr attributes, cache efficiency, and performance trade-offs",
    "content": "The `repr` attribute controls struct memory layout, which is critical for low-level optimization in high-throughput systems where cache locality drives performance.\n\n## How They Work\n\n**`repr(C)`**: Enforces C-compatible layout with fields ordered sequentially as declared, adding padding to align each field to its natural alignment (e.g., `u32` aligns to 4 bytes). Ensures predictable interoperability and typically aligns well with CPU cache lines (often 64 bytes).\n\n**`repr(packed)`**: Removes all padding, packing fields tightly together regardless of alignment. Minimizes memory usage but can lead to unaligned memory accesses, which are slower on most architectures.\n\n## Optimization for Cache Locality\n\nWith `repr(C)`, the compiler adds padding to align fields, increasing struct size but ensuring efficient, aligned access:\n\n```rust\n#[repr(C)]\nstruct Data {\n    flag: bool,   // 1 byte + 3 bytes padding (on 32-bit alignment)\n    value: u32,   // 4 bytes\n    counter: u64, // 8 bytes\n}\n// Size: 16 bytes (due to padding for alignment)\n```\n\nHere, `repr(C)` ensures `value` and `counter` are aligned—great for loops accessing `value` repeatedly. Aligned reads are fast and cache-friendly, but padding after `flag` wastes space.\n\nWith `repr(packed)`:\n\n```rust\n#[repr(packed)]\nstruct PackedData {\n    flag: bool,   // 1 byte\n    value: u32,   // 4 bytes, unaligned\n    counter: u64, // 8 bytes, unaligned\n}\n// Size: 13 bytes (no padding)\n```\n\nThis shrinks size to 13 bytes, ideal for tight memory constraints, but unaligned accesses to `value` and `counter` incur significant performance penalties.\n\n## Trade-Offs\n\n| Aspect | `repr(C)` | `repr(packed)` |\n|--------|-----------|----------------|\n| **Performance** | Fast aligned access, cache-efficient | Slower unaligned access penalties |\n| **Memory Usage** | Larger due to padding | Minimal footprint |\n| **Portability** | Safe across platforms | Risk of UB or panics on strict architectures |\n\n- **Performance**: `repr(C)` wins for speed—aligned access is faster and cache-efficient\n- **Memory Usage**: `repr(packed)` reduces footprint, critical for large arrays or tight constraints\n- **Portability**: `repr(C)` is safer; `repr(packed)` risks undefined behavior with unsafe dereferencing\n\n## Example Scenario\n\nReal-time packet parser in a network server processing millions of packets per second:\n\n```rust\n#[repr(C)]\nstruct Packet {\n    header: u8,   // 1 byte + 3 padding\n    id: u32,      // 4 bytes\n    payload: u64, // 8 bytes\n}\n```\n\nWith `repr(C)`, size is 16 bytes, and `id`/`payload` are aligned, speeding up field access in tight loops checking `id`. Cache locality is decent since the struct fits in a 64-byte cache line.\n\nIf using `repr(packed)` (13 bytes), I'd save 3 bytes per packet, but unaligned `id` and `payload` accesses could halve throughput due to penalties—unacceptable for this workload.\n\n**Choice**: `repr(C)` for performance-critical code. Consider reordering fields (`payload`, `id`, `header`) to group hot fields together.\n\n**Alternative scenario**: Serializing thousands of tiny structs to disk with infrequent access—`repr(packed)` might make sense to minimize storage, accepting slower deserialization.\n\n## Advanced Considerations\n\n- Use profiling tools like `perf` to confirm cache miss reductions\n- Consider `#[repr(C, packed)]` for C-compatible but packed layout\n- Field reordering can optimize cache line usage without changing `repr`\n- Test trade-offs on target hardware, especially ARM vs x86_64\n\n## Key Takeaways\n\n✅ **`repr(C)`**: Choose for performance-critical code where cache efficiency matters  \n✅ **`repr(packed)`**: Use for memory-constrained scenarios with infrequent access  \n🚀 Profile cache performance before and after to validate optimizations\n\n**Try This:** What happens if you access a field in a `repr(packed)` struct through a raw pointer?  \n**Answer:** Unaligned access through raw pointers can cause panics on strict architectures or performance penalties—always measure on your target platform!",
    "contentHtml": "<p>The <code>repr</code> attribute controls struct memory layout, which is critical for low-level optimization in high-throughput systems where cache locality drives performance.</p>\n<h2>How They Work</h2>\n<p><strong><code>repr(C)</code></strong>: Enforces C-compatible layout with fields ordered sequentially as declared, adding padding to align each field to its natural alignment (e.g., <code>u32</code> aligns to 4 bytes). Ensures predictable interoperability and typically aligns well with CPU cache lines (often 64 bytes).</p>\n<p><strong><code>repr(packed)</code></strong>: Removes all padding, packing fields tightly together regardless of alignment. Minimizes memory usage but can lead to unaligned memory accesses, which are slower on most architectures.</p>\n<h2>Optimization for Cache Locality</h2>\n<p>With <code>repr(C)</code>, the compiler adds padding to align fields, increasing struct size but ensuring efficient, aligned access:</p>\n<pre><code class=\"language-rust\">#[repr(C)]\nstruct Data {\n    flag: bool,   // 1 byte + 3 bytes padding (on 32-bit alignment)\n    value: u32,   // 4 bytes\n    counter: u64, // 8 bytes\n}\n// Size: 16 bytes (due to padding for alignment)\n</code></pre>\n<p>Here, <code>repr(C)</code> ensures <code>value</code> and <code>counter</code> are aligned—great for loops accessing <code>value</code> repeatedly. Aligned reads are fast and cache-friendly, but padding after <code>flag</code> wastes space.</p>\n<p>With <code>repr(packed)</code>:</p>\n<pre><code class=\"language-rust\">#[repr(packed)]\nstruct PackedData {\n    flag: bool,   // 1 byte\n    value: u32,   // 4 bytes, unaligned\n    counter: u64, // 8 bytes, unaligned\n}\n// Size: 13 bytes (no padding)\n</code></pre>\n<p>This shrinks size to 13 bytes, ideal for tight memory constraints, but unaligned accesses to <code>value</code> and <code>counter</code> incur significant performance penalties.</p>\n<h2>Trade-Offs</h2>\n<table>\n<thead>\n<tr>\n<th>Aspect</th>\n<th><code>repr(C)</code></th>\n<th><code>repr(packed)</code></th>\n</tr>\n</thead>\n<tbody><tr>\n<td><strong>Performance</strong></td>\n<td>Fast aligned access, cache-efficient</td>\n<td>Slower unaligned access penalties</td>\n</tr>\n<tr>\n<td><strong>Memory Usage</strong></td>\n<td>Larger due to padding</td>\n<td>Minimal footprint</td>\n</tr>\n<tr>\n<td><strong>Portability</strong></td>\n<td>Safe across platforms</td>\n<td>Risk of UB or panics on strict architectures</td>\n</tr>\n</tbody></table>\n<ul>\n<li><strong>Performance</strong>: <code>repr(C)</code> wins for speed—aligned access is faster and cache-efficient</li>\n<li><strong>Memory Usage</strong>: <code>repr(packed)</code> reduces footprint, critical for large arrays or tight constraints</li>\n<li><strong>Portability</strong>: <code>repr(C)</code> is safer; <code>repr(packed)</code> risks undefined behavior with unsafe dereferencing</li>\n</ul>\n<h2>Example Scenario</h2>\n<p>Real-time packet parser in a network server processing millions of packets per second:</p>\n<pre><code class=\"language-rust\">#[repr(C)]\nstruct Packet {\n    header: u8,   // 1 byte + 3 padding\n    id: u32,      // 4 bytes\n    payload: u64, // 8 bytes\n}\n</code></pre>\n<p>With <code>repr(C)</code>, size is 16 bytes, and <code>id</code>/<code>payload</code> are aligned, speeding up field access in tight loops checking <code>id</code>. Cache locality is decent since the struct fits in a 64-byte cache line.</p>\n<p>If using <code>repr(packed)</code> (13 bytes), I&#39;d save 3 bytes per packet, but unaligned <code>id</code> and <code>payload</code> accesses could halve throughput due to penalties—unacceptable for this workload.</p>\n<p><strong>Choice</strong>: <code>repr(C)</code> for performance-critical code. Consider reordering fields (<code>payload</code>, <code>id</code>, <code>header</code>) to group hot fields together.</p>\n<p><strong>Alternative scenario</strong>: Serializing thousands of tiny structs to disk with infrequent access—<code>repr(packed)</code> might make sense to minimize storage, accepting slower deserialization.</p>\n<h2>Advanced Considerations</h2>\n<ul>\n<li>Use profiling tools like <code>perf</code> to confirm cache miss reductions</li>\n<li>Consider <code>#[repr(C, packed)]</code> for C-compatible but packed layout</li>\n<li>Field reordering can optimize cache line usage without changing <code>repr</code></li>\n<li>Test trade-offs on target hardware, especially ARM vs x86_64</li>\n</ul>\n<h2>Key Takeaways</h2>\n<p>✅ <strong><code>repr(C)</code></strong>: Choose for performance-critical code where cache efficiency matters<br>✅ <strong><code>repr(packed)</code></strong>: Use for memory-constrained scenarios with infrequent access<br>🚀 Profile cache performance before and after to validate optimizations</p>\n<p><strong>Try This:</strong> What happens if you access a field in a <code>repr(packed)</code> struct through a raw pointer?<br><strong>Answer:</strong> Unaligned access through raw pointers can cause panics on strict architectures or performance penalties—always measure on your target platform!</p>\n",
    "author": "mayo",
    "category": "rust",
    "tags": [
      "rust",
      "cache"
    ],
    "readingTime": "3 min",
    "locale": "en",
    "seo": {
      "title": "Rust's repr: Optimize Struct Memory for Cache Efficiency",
      "description": "Low-level memory optimization in Rust, covering repr attributes, cache efficiency, and performance trade-offs",
      "keywords": [
        "rust",
        "cache"
      ]
    },
    "headings": [
      {
        "id": "how-they-work",
        "text": "How They Work",
        "level": 2
      },
      {
        "id": "optimization-for-cache-locality",
        "text": "Optimization for Cache Locality",
        "level": 2
      },
      {
        "id": "trade-offs",
        "text": "Trade-Offs",
        "level": 2
      },
      {
        "id": "example-scenario",
        "text": "Example Scenario",
        "level": 2
      },
      {
        "id": "advanced-considerations",
        "text": "Advanced Considerations",
        "level": 2
      },
      {
        "id": "key-takeaways",
        "text": "Key Takeaways",
        "level": 2
      }
    ]
  },
  {
    "id": "vec-new-vs-with-capacity",
    "slug": "vec-new-vs-with-capacity",
    "title": "Rust Vec::new() vs. with_capacity(): When to Use Each",
    "date": "2025-06-25",
    "excerpt": "Vec allocation strategies in Rust, comparing Vec::new() and Vec::with_capacity() for optimal performance.",
    "content": "Understanding Vec allocation strategies is crucial for writing performant Rust code, especially when dealing with collections and iterators.\n\n## Key Differences\n\n| `Vec::new()` | `Vec::with_capacity(n)` |\n|--------------|-------------------------|\n| Creates an empty Vec with no pre-allocated space | Creates an empty Vec with space for n elements |\n| Initial capacity is 0 (allocates on first push) | Initial capacity is exactly n (no early allocations) |\n| Grows dynamically (may reallocate multiple times) | Avoids reallocation until len() > n |\n\n## When to Use Each\n\nUse `Vec::new()` when:\n- The number of elements is unknown or small\n- You want simplicity (e.g., short-lived vectors)\n\n```rust\nlet mut v = Vec::new(); // Good for ad-hoc usage\nv.push(1);\n```\n\nUse `Vec::with_capacity(n)` when:\n- You know the exact or maximum number of elements upfront\n- Optimizing for performance (avoids reallocations)\n\n```rust\nlet mut v = Vec::with_capacity(1000); // Pre-allocate for 1000 items\nfor i in 0..1000 {\n    v.push(i); // No reallocation happens\n}\n```\n\n## Performance Impact\n\n`Vec::new()` may trigger multiple reallocations as it grows (e.g., starts at 0, then 4, 8, 16, ...).\n`Vec::with_capacity(n)` guarantees one allocation upfront (if n is correct).\n\n## Example Benchmark\n\n```rust\nuse std::time::Instant;\n\nfn main() {\n    let start = Instant::now();\n    let mut v1 = Vec::new();\n    for i in 0..1_000_000 {\n        v1.push(i); // Reallocates ~20 times\n    }\n    println!(\"Vec::new(): {:?}\", start.elapsed());\n\n    let start = Instant::now();\n    let mut v2 = Vec::with_capacity(1_000_000);\n    for i in 0..1_000_000 {\n        v2.push(i); // No reallocations\n    }\n    println!(\"Vec::with_capacity(): {:?}\", start.elapsed());\n}\n```\n\nOutput (typical):\n```\nVec::new(): 1.2ms\nVec::with_capacity(): 0.3ms  // 4x faster\n```\n\n## Advanced Notes\n\n- `shrink_to_fit()`: Reduces excess capacity (e.g., after removing elements)\n- `vec![]` macro: Uses with_capacity implicitly for literals (e.g., vec![1, 2, 3])\n\n## Key Takeaways\n\n- ✅ Default to `Vec::new()` for simplicity.  \n- ✅ Use `with_capacity(n)` when:\n- You know the size upfront\n- Performance is critical (e.g., hot loops)\n\n**Try This:** What happens if you push beyond the pre-allocated capacity?  \n**Answer:** The Vec grows automatically (like `Vec::new()`), but only after exceeding n.",
    "contentHtml": "<p>Understanding Vec allocation strategies is crucial for writing performant Rust code, especially when dealing with collections and iterators.</p>\n<h2>Key Differences</h2>\n<table>\n<thead>\n<tr>\n<th><code>Vec::new()</code></th>\n<th><code>Vec::with_capacity(n)</code></th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Creates an empty Vec with no pre-allocated space</td>\n<td>Creates an empty Vec with space for n elements</td>\n</tr>\n<tr>\n<td>Initial capacity is 0 (allocates on first push)</td>\n<td>Initial capacity is exactly n (no early allocations)</td>\n</tr>\n<tr>\n<td>Grows dynamically (may reallocate multiple times)</td>\n<td>Avoids reallocation until len() &gt; n</td>\n</tr>\n</tbody></table>\n<h2>When to Use Each</h2>\n<p>Use <code>Vec::new()</code> when:</p>\n<ul>\n<li>The number of elements is unknown or small</li>\n<li>You want simplicity (e.g., short-lived vectors)</li>\n</ul>\n<pre><code class=\"language-rust\">let mut v = Vec::new(); // Good for ad-hoc usage\nv.push(1);\n</code></pre>\n<p>Use <code>Vec::with_capacity(n)</code> when:</p>\n<ul>\n<li>You know the exact or maximum number of elements upfront</li>\n<li>Optimizing for performance (avoids reallocations)</li>\n</ul>\n<pre><code class=\"language-rust\">let mut v = Vec::with_capacity(1000); // Pre-allocate for 1000 items\nfor i in 0..1000 {\n    v.push(i); // No reallocation happens\n}\n</code></pre>\n<h2>Performance Impact</h2>\n<p><code>Vec::new()</code> may trigger multiple reallocations as it grows (e.g., starts at 0, then 4, 8, 16, ...).\n<code>Vec::with_capacity(n)</code> guarantees one allocation upfront (if n is correct).</p>\n<h2>Example Benchmark</h2>\n<pre><code class=\"language-rust\">use std::time::Instant;\n\nfn main() {\n    let start = Instant::now();\n    let mut v1 = Vec::new();\n    for i in 0..1_000_000 {\n        v1.push(i); // Reallocates ~20 times\n    }\n    println!(&quot;Vec::new(): {:?}&quot;, start.elapsed());\n\n    let start = Instant::now();\n    let mut v2 = Vec::with_capacity(1_000_000);\n    for i in 0..1_000_000 {\n        v2.push(i); // No reallocations\n    }\n    println!(&quot;Vec::with_capacity(): {:?}&quot;, start.elapsed());\n}\n</code></pre>\n<p>Output (typical):</p>\n<pre><code>Vec::new(): 1.2ms\nVec::with_capacity(): 0.3ms  // 4x faster\n</code></pre>\n<h2>Advanced Notes</h2>\n<ul>\n<li><code>shrink_to_fit()</code>: Reduces excess capacity (e.g., after removing elements)</li>\n<li><code>vec![]</code> macro: Uses with_capacity implicitly for literals (e.g., vec![1, 2, 3])</li>\n</ul>\n<h2>Key Takeaways</h2>\n<ul>\n<li>✅ Default to <code>Vec::new()</code> for simplicity.  </li>\n<li>✅ Use <code>with_capacity(n)</code> when:</li>\n<li>You know the size upfront</li>\n<li>Performance is critical (e.g., hot loops)</li>\n</ul>\n<p><strong>Try This:</strong> What happens if you push beyond the pre-allocated capacity?<br><strong>Answer:</strong> The Vec grows automatically (like <code>Vec::new()</code>), but only after exceeding n.</p>\n",
    "author": "mayo",
    "category": "rust",
    "tags": [
      "rust",
      "collections",
      "iterators"
    ],
    "readingTime": "2 min",
    "locale": "en",
    "seo": {
      "title": "Rust Vec::new() vs. with_capacity(): When to Use Each",
      "description": "Vec allocation strategies in Rust, comparing Vec::new() and Vec::with_capacity() for optimal performance.",
      "keywords": [
        "rust",
        "collections",
        "iterators"
      ]
    },
    "headings": [
      {
        "id": "key-differences",
        "text": "Key Differences",
        "level": 2
      },
      {
        "id": "when-to-use-each",
        "text": "When to Use Each",
        "level": 2
      },
      {
        "id": "performance-impact",
        "text": "Performance Impact",
        "level": 2
      },
      {
        "id": "example-benchmark",
        "text": "Example Benchmark",
        "level": 2
      },
      {
        "id": "advanced-notes",
        "text": "Advanced Notes",
        "level": 2
      },
      {
        "id": "key-takeaways",
        "text": "Key Takeaways",
        "level": 2
      }
    ]
  },
  {
    "id": "getting-started-with-rust",
    "slug": "getting-started-with-rust",
    "title": "Getting Started with Rust: A Guide for Beginners",
    "date": "2025-04-15",
    "excerpt": "Introduction to Rust for beginners, covering installation, basic syntax, and your first project.",
    "content": "Rust has been gaining significant traction among developers for its focus on performance, memory safety, and concurrency. If you're new to Rust, this guide will help you get started with the basics.\n\n## Setting Up Your Environment\n\nFirst, you'll need to install Rust on your system. The easiest way is to use rustup, the Rust toolchain installer:\n\n```bash\ncurl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh\n```\n\nThis command will download a script and start the installation process. Follow the instructions on screen to complete the installation.\n\n## Your First Rust Program\n\nLet's create a simple \"Hello, World!\" program. Create a new file called `hello.rs` with the following content:\n\n```rust\nfn main() {\n    println!(\"Hello, World!\");\n}\n```\n\nTo compile and run this program, use the following commands:\n\n```bash\nrustc hello.rs\n./hello\n```\n\n## Understanding Cargo\n\nCargo is Rust's build system and package manager. It handles many tasks such as building your code, downloading libraries, and building those libraries.\n\nTo create a new project with Cargo:\n\n```bash\ncargo new hello_cargo\ncd hello_cargo\n```\n\nThis creates a new directory called `hello_cargo` with the following structure:\n\n```\nhello_cargo/\n├── Cargo.toml\n└── src/\n    └── main.rs\n```\n\nThe `Cargo.toml` file contains metadata about your project and its dependencies. The `src/main.rs` file contains your application code.\n\nTo build and run your project:\n\n```bash\ncargo build   # Compile the project\ncargo run     # Compile and run the project\n```\n\n## Key Concepts in Rust\n\n### Variables and Mutability\n\nBy default, variables in Rust are immutable:\n\n```rust\nlet x = 5;\n// x = 6; // This would cause an error\n```\n\nTo make a variable mutable, use the `mut` keyword:\n\n```rust\nlet mut y = 5;\ny = 6; // This works fine\n```\n\n### Ownership\n\nOwnership is Rust's most unique feature and enables memory safety without garbage collection. The main rules are:\n\n1. Each value in Rust has a variable that's its owner.\n2. There can only be one owner at a time.\n3. When the owner goes out of scope, the value will be dropped.\n\n```rust\nfn main() {\n    let s1 = String::from(\"hello\");\n    let s2 = s1; // s1 is moved to s2, s1 is no longer valid\n    \n    // println!(\"{}\", s1); // This would cause an error\n    println!(\"{}\", s2); // This works fine\n}\n```\n\n## Next Steps\n\nNow that you have the basics, try building a small project to practice your skills. The Rust documentation is an excellent resource for learning more:\n\n- [The Rust Book](https://doc.rust-lang.org/book/)\n- [Rust by Example](https://doc.rust-lang.org/rust-by-example/)\n\nHappy coding with Rust!",
    "contentHtml": "<p>Rust has been gaining significant traction among developers for its focus on performance, memory safety, and concurrency. If you&#39;re new to Rust, this guide will help you get started with the basics.</p>\n<h2>Setting Up Your Environment</h2>\n<p>First, you&#39;ll need to install Rust on your system. The easiest way is to use rustup, the Rust toolchain installer:</p>\n<pre><code class=\"language-bash\">curl --proto &#39;=https&#39; --tlsv1.2 -sSf https://sh.rustup.rs | sh\n</code></pre>\n<p>This command will download a script and start the installation process. Follow the instructions on screen to complete the installation.</p>\n<h2>Your First Rust Program</h2>\n<p>Let&#39;s create a simple &quot;Hello, World!&quot; program. Create a new file called <code>hello.rs</code> with the following content:</p>\n<pre><code class=\"language-rust\">fn main() {\n    println!(&quot;Hello, World!&quot;);\n}\n</code></pre>\n<p>To compile and run this program, use the following commands:</p>\n<pre><code class=\"language-bash\">rustc hello.rs\n./hello\n</code></pre>\n<h2>Understanding Cargo</h2>\n<p>Cargo is Rust&#39;s build system and package manager. It handles many tasks such as building your code, downloading libraries, and building those libraries.</p>\n<p>To create a new project with Cargo:</p>\n<pre><code class=\"language-bash\">cargo new hello_cargo\ncd hello_cargo\n</code></pre>\n<p>This creates a new directory called <code>hello_cargo</code> with the following structure:</p>\n<pre><code>hello_cargo/\n├── Cargo.toml\n└── src/\n    └── main.rs\n</code></pre>\n<p>The <code>Cargo.toml</code> file contains metadata about your project and its dependencies. The <code>src/main.rs</code> file contains your application code.</p>\n<p>To build and run your project:</p>\n<pre><code class=\"language-bash\">cargo build   # Compile the project\ncargo run     # Compile and run the project\n</code></pre>\n<h2>Key Concepts in Rust</h2>\n<h3>Variables and Mutability</h3>\n<p>By default, variables in Rust are immutable:</p>\n<pre><code class=\"language-rust\">let x = 5;\n// x = 6; // This would cause an error\n</code></pre>\n<p>To make a variable mutable, use the <code>mut</code> keyword:</p>\n<pre><code class=\"language-rust\">let mut y = 5;\ny = 6; // This works fine\n</code></pre>\n<h3>Ownership</h3>\n<p>Ownership is Rust&#39;s most unique feature and enables memory safety without garbage collection. The main rules are:</p>\n<ol>\n<li>Each value in Rust has a variable that&#39;s its owner.</li>\n<li>There can only be one owner at a time.</li>\n<li>When the owner goes out of scope, the value will be dropped.</li>\n</ol>\n<pre><code class=\"language-rust\">fn main() {\n    let s1 = String::from(&quot;hello&quot;);\n    let s2 = s1; // s1 is moved to s2, s1 is no longer valid\n    \n    // println!(&quot;{}&quot;, s1); // This would cause an error\n    println!(&quot;{}&quot;, s2); // This works fine\n}\n</code></pre>\n<h2>Next Steps</h2>\n<p>Now that you have the basics, try building a small project to practice your skills. The Rust documentation is an excellent resource for learning more:</p>\n<ul>\n<li><a href=\"https://doc.rust-lang.org/book/\">The Rust Book</a></li>\n<li><a href=\"https://doc.rust-lang.org/rust-by-example/\">Rust by Example</a></li>\n</ul>\n<p>Happy coding with Rust!</p>\n",
    "author": "Mayorana",
    "category": "rust",
    "tags": [
      "rust",
      "beginners"
    ],
    "readingTime": "3 min",
    "locale": "en",
    "seo": {
      "title": "Getting Started with Rust: A Guide for Beginners",
      "description": "Introduction to Rust for beginners, covering installation, basic syntax, and your first project.",
      "keywords": [
        "rust",
        "beginners"
      ]
    },
    "headings": [
      {
        "id": "setting-up-your-environment",
        "text": "Setting Up Your Environment",
        "level": 2
      },
      {
        "id": "your-first-rust-program",
        "text": "Your First Rust Program",
        "level": 2
      },
      {
        "id": "understanding-cargo",
        "text": "Understanding Cargo",
        "level": 2
      },
      {
        "id": "key-concepts-in-rust",
        "text": "Key Concepts in Rust",
        "level": 2
      },
      {
        "id": "variables-and-mutability",
        "text": "Variables and Mutability",
        "level": 3
      },
      {
        "id": "ownership",
        "text": "Ownership",
        "level": 3
      },
      {
        "id": "next-steps",
        "text": "Next Steps",
        "level": 2
      }
    ]
  }
]